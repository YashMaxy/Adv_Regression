{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attack-workflow-regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ebb03d575bf40da8fba35ad59611a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9789188de68b4172ad061134bf560346",
              "IPY_MODEL_86dcc6f2470546eb965d3db0f38568f7",
              "IPY_MODEL_8d9048b606e643f7958e14a00cc5d296"
            ],
            "layout": "IPY_MODEL_9c24a912322e4bf29f4f6125d68fb8a8"
          }
        },
        "9789188de68b4172ad061134bf560346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e0590b7f4347abaa5642d61f79d952",
            "placeholder": "​",
            "style": "IPY_MODEL_1d89a12aac21409c851f2d4f9dd723aa",
            "value": "100%"
          }
        },
        "86dcc6f2470546eb965d3db0f38568f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0629aa5fd14a4496a809a7599a5db8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b07f9bd38a544872a08cfab581419828",
            "value": 1
          }
        },
        "8d9048b606e643f7958e14a00cc5d296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e9679dcc9b43f7aa7e474beecbdedf",
            "placeholder": "​",
            "style": "IPY_MODEL_46ee60183ac6451b89814d5ae7fd4e1b",
            "value": " 1/1 [00:00&lt;00:00,  4.46ba/s]"
          }
        },
        "9c24a912322e4bf29f4f6125d68fb8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e0590b7f4347abaa5642d61f79d952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d89a12aac21409c851f2d4f9dd723aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe0629aa5fd14a4496a809a7599a5db8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b07f9bd38a544872a08cfab581419828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80e9679dcc9b43f7aa7e474beecbdedf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ee60183ac6451b89814d5ae7fd4e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24790a362e574889bcb3371b3833590e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f567ebc682b34829a1ae599f24c2a061",
              "IPY_MODEL_79f8f1411cfd4d359f769b1d5c163817",
              "IPY_MODEL_58593e7fc38245c494dc123179200503"
            ],
            "layout": "IPY_MODEL_fe2251675341486d8c598f26ae3e72ee"
          }
        },
        "f567ebc682b34829a1ae599f24c2a061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a4b05b89cec469996240b798807a6a1",
            "placeholder": "​",
            "style": "IPY_MODEL_4aeb2c4dc2f342c8a825d20cb65a1450",
            "value": "100%"
          }
        },
        "79f8f1411cfd4d359f769b1d5c163817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_433c2f2f66224e9fa741b7eb0a0ff8f1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ec8d5758e0f4e8fb8f616f80da0d93f",
            "value": 1
          }
        },
        "58593e7fc38245c494dc123179200503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7340a9112b4d9c9dd9332427ae09c9",
            "placeholder": "​",
            "style": "IPY_MODEL_0642fb0d421b47879d906621c242c776",
            "value": " 1/1 [00:00&lt;00:00,  9.56ba/s]"
          }
        },
        "fe2251675341486d8c598f26ae3e72ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a4b05b89cec469996240b798807a6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aeb2c4dc2f342c8a825d20cb65a1450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "433c2f2f66224e9fa741b7eb0a0ff8f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ec8d5758e0f4e8fb8f616f80da0d93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e7340a9112b4d9c9dd9332427ae09c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0642fb0d421b47879d906621c242c776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14e4c913852349328743befde69ef839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7914c53bde1f450c909d6e43046660c1",
              "IPY_MODEL_6a6404754a7643a08d741564df811fc6",
              "IPY_MODEL_bb8ea84d0c064e2ea9a28a1ce75e34d8"
            ],
            "layout": "IPY_MODEL_bb2fd8b40fa04321bb70d0187b96bfe8"
          }
        },
        "7914c53bde1f450c909d6e43046660c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2bb2f8552044cc2ac212916633fc0cd",
            "placeholder": "​",
            "style": "IPY_MODEL_3bdea0d2c8974fc3ad82b6419ab46e6f",
            "value": "100%"
          }
        },
        "6a6404754a7643a08d741564df811fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da5d6b8d7f824f948166fc8753bff543",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa38c56c9d48486f9077c2687bba98f6",
            "value": 1
          }
        },
        "bb8ea84d0c064e2ea9a28a1ce75e34d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1ad10423ac942678ecf01020c6aee3a",
            "placeholder": "​",
            "style": "IPY_MODEL_4b9638b556504ea2b7091dca8eedb37f",
            "value": " 1/1 [00:00&lt;00:00, 12.50ba/s]"
          }
        },
        "bb2fd8b40fa04321bb70d0187b96bfe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bb2f8552044cc2ac212916633fc0cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bdea0d2c8974fc3ad82b6419ab46e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da5d6b8d7f824f948166fc8753bff543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa38c56c9d48486f9077c2687bba98f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1ad10423ac942678ecf01020c6aee3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9638b556504ea2b7091dca8eedb37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashMaxy/Adv_Regression/blob/main/attack_workflow_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0aBBYiFfkVw",
        "outputId": "115fd028-cb03-4bf0-d443-5723aead2bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 415 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 401 kB 54.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 769 kB 66.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 290 kB 77.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41.4 MB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 60 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 454.3 MB 17 kB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 73.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 78.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 44.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 57.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 141 kB 77.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 58.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 51.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 46.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 32.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 44.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 49.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 47.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 61.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 74.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 45.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 52.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 57.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 53.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 43.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 50.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 75.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 41.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 52.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 49.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 53.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 56.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 49.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 39.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 47.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 54.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 788 kB 75.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 981 kB 66.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 72.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 702 kB/s \n",
            "\u001b[?25h  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 5.1 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.20.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.20.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.20.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.20.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.95)\n",
            "Collecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.53)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=e383b85625d4aefaaff52b271630c4d518c4eccf217897e2371675e622ad53b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: huggingface-hub, sentence-transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.0.19\n",
            "    Uninstalling huggingface-hub-0.0.19:\n",
            "      Successfully uninstalled huggingface-hub-0.0.19\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 1.15.0 requires huggingface-hub<0.1.0,>=0.0.19, but you have huggingface-hub 0.8.1 which is incompatible.\u001b[0m\n",
            "Successfully installed huggingface-hub-0.8.1 sentence-transformers-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install textattack[tensorflow] --q\n",
        "!pip install numpy==1.20.0 --q\n",
        "!pip install transformers --q\n",
        "!pip install datasets --q\n",
        "!pip install sentence_transformers --q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'model_name' : 'bert-base-uncased',\n",
        "    'num_class' : 1,\n",
        "    'dataset' : 'sid-157',\n",
        "    'log_dir' : '/content/log',\n",
        "    'epochs' : 20,\n",
        "    'output_dir' : '/content/checkpoint',\n",
        "    'batch_size' : 16,\n",
        "    'warmup_steps' : 500,\n",
        "    'warmup_decay' : 0.01,\n",
        "    'model_dir' : '/content/model'\n",
        "}"
      ],
      "metadata": {
        "id": "cpx7Nhdgj1mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "j4RyDd7wR30t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from datasets import Dataset, load_dataset, load_metric\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from tqdm import tqdm\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, EvalPrediction, HfArgumentParser,\n",
        "                          PretrainedConfig, Trainer, TrainingArguments,\n",
        "                          default_data_collator, set_seed)\n",
        "from transformers.trainer_utils import is_main_process\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "import copy\n",
        "import glob\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, porter\n",
        "from scipy import special\n",
        "from scipy.stats import pearsonr\n",
        "from transformers import AdamW, EarlyStoppingCallback\n",
        "\n",
        "\n",
        "def clear_punctuation(row: str) -> str:\n",
        "    punctuations = \"!()-[]{};:\\,<>./?\"\n",
        "    no_punct = \"\"\n",
        "    for char in row:\n",
        "        if char not in punctuations:\n",
        "            # print(\"not in\",char)\n",
        "            no_punct = no_punct + char\n",
        "        elif char in punctuations:\n",
        "            # print(\"in\",char)\n",
        "            no_punct += \" \"\n",
        "    return no_punct.lower() + \" \"\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = porter.PorterStemmer()\n",
        "\n",
        "\n",
        "def nltk_process_sentence(sentence):\n",
        "    \"\"\"remove stop words, stem and lemmatize.\"\"\"\n",
        "    _stem = [stemmer.stem(i) for i in sentence.split()]\n",
        "    _lemma = [lemmatizer.lemmatize(i, pos=\"v\") for i in sentence.split()]\n",
        "    _stop_words = [i for i in _lemma if i not in stopwords.words(\"english\")]\n",
        "\n",
        "    output = \" \".join(_stop_words)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "class create_data:\n",
        "    def __init__(\n",
        "        self,\n",
        "        data,\n",
        "        sid,\n",
        "        model_name,\n",
        "        rescale=False,\n",
        "        no_punct=False,\n",
        "        rescale_type=0,\n",
        "        prepend_prompt=False,\n",
        "    ):\n",
        "\n",
        "        # sklearn data scaler for normalizing the dataframe\n",
        "        self.scaler = MinMaxScaler()\n",
        "        stratify_cols = [\"content_rating\"]\n",
        "        self.pretrained_model_name = model_name\n",
        "        self.sid_data = data[data[\"sID\"] == sid]\n",
        "        self.sid_data[\"content_rating\"] = self.sid_data[\"content_rating\"].astype(float)\n",
        "        self.prepend_prompt = prepend_prompt\n",
        "\n",
        "        print(f\"Total data points: {len(self.sid_data)}\")\n",
        "\n",
        "        # nltk modules for stemming and lemmatization\n",
        "        # self.lemmatizer = WordNetLemmatizer()\n",
        "        # self.stemmer = porter.PorterStemmer()\n",
        "\n",
        "        # Rescale the data, if needed\n",
        "        # If rescale_type is 1, change all values below 1 to 1.\n",
        "        # If rescale_type is 4, change all values ablve 4 to 4.\n",
        "        if rescale:\n",
        "            # content_ratings = []\n",
        "            if rescale_type == 1:\n",
        "                self.sid_data[self.sid_data[\"content_rating\"] < 1] = 1.0\n",
        "\n",
        "            elif rescale_type == 4:\n",
        "                self.sid_data[self.sid_data[\"content_rating\"] > 4] = 4.0\n",
        "\n",
        "            else:\n",
        "                self.sid_data[self.sid_data[\"content_rating\"] < 1] = 1.0\n",
        "                self.sid_data[self.sid_data[\"content_rating\"] > 4] = 4.0\n",
        "\n",
        "            # self.sid_data['content_rating'] = content_ratings\n",
        "\n",
        "        # Clear punctuation, if needed\n",
        "        if no_punct:\n",
        "            self.sid_data[\"transcript\"] = self.sid_data[\"transcript\"].apply(\n",
        "                clear_punctuation\n",
        "            )\n",
        "\n",
        "        # scale the data based on the min-max value\n",
        "        self.sid_data[\"content_rating\"] = [\n",
        "            float(int(x + 0.5)) for x in self.sid_data[\"content_rating\"].tolist()\n",
        "        ]\n",
        "        self.scaler.fit(self.sid_data[[\"content_rating\"]])\n",
        "        self.sid_data[\"content_rating_scaled\"] = self.scaler.transform(\n",
        "            self.sid_data[[\"content_rating\"]]\n",
        "        )\n",
        "        # print(self.sid_data[\"content_rating_scaled\"])\n",
        "        self.sid_data[\"stratify\"] = self.sid_data[stratify_cols].apply(\n",
        "            lambda x: \"_\".join(x.dropna().astype(str)), axis=1\n",
        "        )\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.pretrained_model_name)\n",
        "\n",
        "        # self.arti_data = pd.read_excel('data/ucf_training_data_Arti.xlsx')\n",
        "        # self.arti_data = self.arti_data[self.arti_data['type']=='arti']\n",
        "        # self.arti_data = self.arti_data[self.arti_data['sID']==sid]\n",
        "        # self.arti_data[\"content_rating_scaled\"] = self.scaler.transform(self.arti_data[[\"content_rating\"]])\n",
        "\n",
        "    def nltk_preprocess(self, sentences, run=False):\n",
        "        \"\"\"remove stop words, stem and lemmatize.\"\"\"\n",
        "        # print(f\"Number of sentences: {len(sentences)}\")\n",
        "\n",
        "        if run:\n",
        "            output = []\n",
        "\n",
        "            for sentence in sentences:\n",
        "                _stem = [self.stemmer.stem(i) for i in sentence.split()]\n",
        "                _lemma = [\n",
        "                    self.lemmatizer.lemmatize(i, pos=\"v\") for i in sentence.split()\n",
        "                ]\n",
        "                _stop_words = [i for i in _lemma if i not in stopwords.words(\"english\")]\n",
        "\n",
        "                output.append(\" \".join(_stop_words))\n",
        "\n",
        "            return output\n",
        "\n",
        "        return sentences\n",
        "\n",
        "    def preprocess_function(self, examples, use_bare=False):\n",
        "        \"\"\"\n",
        "        Prepo\n",
        "        \"\"\"\n",
        "        # Tokenize the texts\n",
        "        args = examples[\"transcript\"]\n",
        "        if self.prepend_prompt:\n",
        "            sid_prompt = examples[\"prompt\"]\n",
        "\n",
        "        if use_bare:\n",
        "            args = self.nltk_preprocess(args)\n",
        "\n",
        "        # If true, prepend the question to the response with a\n",
        "        # [SEP] token in  between\n",
        "        if self.prepend_prompt:\n",
        "            print(\"Prepending the question prompt to each answer\")\n",
        "            result = self.tokenizer(sid_prompt, args, padding=True, truncation=True)\n",
        "        else:\n",
        "            result = self.tokenizer(args, padding=True, truncation=True)\n",
        "\n",
        "        result[\"input_ids\"] = np.array(result[\"input_ids\"], dtype=\"int64\")\n",
        "        result[\"attention_mask\"] = np.array(result[\"attention_mask\"], dtype=\"int64\")\n",
        "        # result[\"label\"] = [i for i in examples[\"content_rating_scaled\"]]\n",
        "        result[\"label\"] = [i for i in examples[\"content_rating\"]]\n",
        "        # print(result.keys())\n",
        "        return result\n",
        "\n",
        "    def create_k_fold(self, fold=5):\n",
        "        folds = StratifiedKFold(\n",
        "            n_splits=fold,\n",
        "            shuffle=True,\n",
        "            random_state=42,\n",
        "        )\n",
        "        splits = dict()\n",
        "        for fold, (trn, val) in enumerate(\n",
        "            folds.split(self.sid_data, self.sid_data[\"stratify\"])\n",
        "        ):\n",
        "            splits[fold] = dict()\n",
        "            splits[fold][\"train_data\"] = self.sid_data.iloc[trn, :]\n",
        "            splits[fold][\"valid_data\"] = self.sid_data.iloc[val, :]\n",
        "\n",
        "        return splits\n",
        "\n",
        "    def n_splits(self, fold):\n",
        "        splits = dict()\n",
        "        for i in range(fold):\n",
        "            splits[i] = dict()\n",
        "\n",
        "            train_set, test_set = train_test_split(\n",
        "                self.sid_data,\n",
        "                test_size=0.2,\n",
        "                stratify=self.sid_data[\"stratify\"],\n",
        "                random_state=None,\n",
        "            )\n",
        "            splits[i][\"train_data\"] = train_set\n",
        "            splits[i][\"valid_data\"] = test_set\n",
        "\n",
        "        return splits\n",
        "\n",
        "    def training_set(self):\n",
        "        splits = dict()\n",
        "        for i in range(1):\n",
        "            splits[i] = dict()\n",
        "\n",
        "        splits[i][\"train_data\"] = self.sid_data\n",
        "        # For the validation set, randomly sample 100 points from the training set\n",
        "        # Note: Ignore the correlation values when training the model\n",
        "        splits[i][\"valid_data\"] = self.sid_data.sample(100)\n",
        "\n",
        "        return splits\n",
        "\n",
        "    def return_k_fold(self, fold, splits):\n",
        "        \"\"\"\n",
        "        Given the fold number and the dataset split, return the\n",
        "        training, testing and other dataset folds.\n",
        "        \"\"\"\n",
        "        train_set = splits[fold][\"train_data\"]\n",
        "        test_set = splits[fold][\"valid_data\"]\n",
        "        test_set_bare = copy.deepcopy(test_set)\n",
        "        test_set_bare[\"transcript\"] = test_set_bare[\"transcript\"].apply(\n",
        "            lambda x: nltk_process_sentence(x)\n",
        "        )\n",
        "\n",
        "        print(Counter(train_set[\"content_rating\"]))\n",
        "        print(Counter(test_set[\"content_rating\"]))\n",
        "        print(Counter(test_set_bare[\"content_rating\"]))\n",
        "\n",
        "        # test_set['transcript'] = test_set['transcript'].str.replace('business risk','risk')\n",
        "        # train_set,test_set = train_test_split(self.sid_data,test_size=0.2,stratify = self.sid_data[\"content_rating\"],random_state=None)\n",
        "\n",
        "        training_set = Dataset.from_pandas(train_set)\n",
        "        testing_set = Dataset.from_pandas(test_set)\n",
        "        testing_set_bare = Dataset.from_pandas(test_set_bare)\n",
        "        # arti_set = Dataset.from_pandas(self.arti_data)\n",
        "        columns_to_return = [\"input_ids\", \"label\", \"attention_mask\"]\n",
        "\n",
        "        training_loader = training_set.map(\n",
        "            self.preprocess_function, batched=True, load_from_cache_file=False\n",
        "        )\n",
        "        training_loader.set_format(type=\"torch\", columns=columns_to_return)\n",
        "\n",
        "        # Load the test dataset\n",
        "        testing_loader = testing_set.map(\n",
        "            self.preprocess_function, batched=True, load_from_cache_file=False\n",
        "        )\n",
        "        testing_loader.set_format(type=\"torch\", columns=columns_to_return)\n",
        "\n",
        "        # Load the test dataset with the nltk pre-processing\n",
        "        testing_loader_bare = testing_set_bare.map(\n",
        "            # self.preprocess_function, fn_kwargs={\"use_bare\": True}, batched=True,load_from_cache_file=False\n",
        "            self.preprocess_function,\n",
        "            batched=True,\n",
        "            load_from_cache_file=False,\n",
        "        )\n",
        "        testing_loader_bare.set_format(type=\"torch\", columns=columns_to_return)\n",
        "\n",
        "        # arti_loader = arti_set.map(self.preprocess_function, batched=True,load_from_cache_file=False)\n",
        "        # columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
        "        # arti_loader.set_format(type='torch', columns=columns_to_return)\n",
        "\n",
        "        # return training_loader,testing_loader,test_set,train_set, arti_loader, self.arti_data\n",
        "        return (\n",
        "            training_loader,\n",
        "            testing_loader,\n",
        "            testing_loader_bare,\n",
        "            train_set,\n",
        "            test_set,\n",
        "            test_set_bare,\n",
        "        )\n",
        "\n",
        "    def rescale_data(self, original):\n",
        "        return original\n",
        "        # return self.scaler.inverse_transform(original)\n",
        "\n",
        "\n",
        "def correlation(logits, labels):\n",
        "    # class_ids =torch.tensor( [0,1,2,3,4])\n",
        "    # preds = torch.nn.functional.softmax(torch.tensor(logits), dim=1)\n",
        "    # predicted_values = torch.mul(preds, class_ids).sum(axis=1)\n",
        "    return pearsonr(logits, labels)[0]\n",
        "\n",
        "\n",
        "def dump_correlation(pred, true_l):\n",
        "\n",
        "    output = pearsonr(pred, true_l)[0]\n",
        "    # print(pred)\n",
        "    return output\n",
        "\n",
        "\n",
        "def dump_result(output_folder, model_name, sids, path):\n",
        "    for sid in [sids]:\n",
        "        result_data = pd.DataFrame()\n",
        "        print(sid)\n",
        "        domain_adapt = []\n",
        "        distil_lst = []\n",
        "        for fold in range(5):\n",
        "            # epochs_39 = pd.read_csv(\"epochs_39_output/\"+ \"output\" + \"_epochs_39\"+\"_fold_\"+str(fold)+ \"_sid_\"+str(sid)+\".csv\")\n",
        "            distill = pd.read_csv(\n",
        "                path\n",
        "                + \"/test_output\"\n",
        "                + \"_\"\n",
        "                + model_name.split(\"/\")[0]\n",
        "                + \"_fold_\"\n",
        "                + str(fold)\n",
        "                + \"_sid_\"\n",
        "                + str(sid)\n",
        "                + \".csv\"\n",
        "            )\n",
        "            result_data = result_data.append(distill)\n",
        "            distil_lst.append(\n",
        "                dump_correlation(\n",
        "                    distill[\"predictions\"].tolist(),\n",
        "                    distill[\"content_rating_scaled\"].tolist(),\n",
        "                )\n",
        "            )\n",
        "            # domain_adapt.append(dump_correlation(epochs_39['predictions'].tolist(),epochs_39['content_rating'].tolist()))\n",
        "        print(model_name, sum(distil_lst) / len(distil_lst), distil_lst)\n",
        "        if model_name == \"distilbert-base-uncased\":\n",
        "            result_data.to_csv(\n",
        "                \"predictions/distillbert/\" + str(sid) + \".csv\", index=False\n",
        "            )\n",
        "        else:\n",
        "            result_data.to_csv(\n",
        "                \"predictions/domainAdapt/\" + str(sid) + \".csv\", index=False\n",
        "            )\n",
        "    return sum(distil_lst) / len(distil_lst), result_data\n",
        "\n",
        "\n",
        "def get_pwl_score(score, thres):\n",
        "\n",
        "    try:\n",
        "        co = 1\n",
        "        threshold_list = thres\n",
        "        levels_pwl = len(threshold_list) - 2\n",
        "        level_scores = []\n",
        "        level_scores.append(0)\n",
        "\n",
        "        for i in range(0, levels_pwl + 1):\n",
        "            previous_level_score = level_scores[-1]\n",
        "            if i == 0 or i == (levels_pwl):\n",
        "                added_component = 100.0 / (levels_pwl * 2)\n",
        "            else:\n",
        "                added_component = 100.0 / (levels_pwl)\n",
        "            new_level_score = previous_level_score + added_component\n",
        "            level_scores.append(new_level_score)\n",
        "\n",
        "        # min score is 5\n",
        "        # max score is 95\n",
        "        level_scores[0] = 5.0\n",
        "        level_scores[-1] = 95.0\n",
        "        if co == 1:\n",
        "            # print(\"level_scores\",level_scores)\n",
        "            # print(\"level_pwl\",levels_pwl)\n",
        "            co = co + 1\n",
        "\n",
        "        pwl_score = -1\n",
        "        pwl_disc_score = -1\n",
        "        # print(threshold_list)\n",
        "\n",
        "        for i in range(1, levels_pwl + 2):\n",
        "            if score <= threshold_list[i]:\n",
        "                pwl_score = level_scores[i - 1] + (score - threshold_list[i - 1]) * (\n",
        "                    level_scores[i] - level_scores[i - 1]\n",
        "                ) / (threshold_list[i] - threshold_list[i - 1])\n",
        "                pwl_disc_score = i - 1\n",
        "                break\n",
        "\n",
        "        if pwl_score == -1:\n",
        "            pwl_score = 95\n",
        "            pwl_disc_score = levels_pwl\n",
        "\n",
        "        pwl_score = min(95, pwl_score)\n",
        "        pwl_score = max(5, pwl_score)\n",
        "        return pwl_score\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def get_thresholds(predicted_scores_train, train_scores):\n",
        "\n",
        "    all_train_scores_disc = [int(score + 0.5) for score in train_scores]\n",
        "\n",
        "    all_train_scores_sort_disc = copy.deepcopy(all_train_scores_disc)\n",
        "    predicted_scores_train_sort = copy.deepcopy(predicted_scores_train)\n",
        "    predicted_scores_train_dis = copy.deepcopy(predicted_scores_train)\n",
        "\n",
        "    # sort all discrete scores\n",
        "    all_train_scores_sort_disc.sort()\n",
        "    predicted_scores_train_sort.sort()\n",
        "\n",
        "    # counter will give frequency of each label.\n",
        "    counts = Counter(all_train_scores_sort_disc)\n",
        "    print(\"Counts : \", counts)\n",
        "\n",
        "    # using counter, get index of all label. As all is sorted.\n",
        "    l_0_idx = counts[0]\n",
        "    l_1_idx = counts[1] + counts[0]\n",
        "    l_2_idx = counts[2] + counts[1] + counts[0]\n",
        "    l_3_idx = counts[3] + counts[2] + counts[1] + counts[0]\n",
        "    l_4_idx = counts[4] + counts[3] + counts[2] + counts[1] + counts[0]\n",
        "    l_5_idx = counts[5] + counts[4] + counts[3] + counts[2] + counts[1] + counts[0]\n",
        "\n",
        "    # print(\"index : \",[l_0_idx,l_1_idx,l_2_idx,l_3_idx,l_4_idx,l_5_idx])\n",
        "\n",
        "    # assign threshold based on the discrete sorted scores and actual label counter\n",
        "    l_m = predicted_scores_train_sort[0]\n",
        "    l_0 = predicted_scores_train_sort[l_0_idx - 1]\n",
        "    if l_0_idx == 0:\n",
        "        l_0 = 0.05\n",
        "    l_1 = predicted_scores_train_sort[l_1_idx - 1]\n",
        "    l_2 = predicted_scores_train_sort[l_2_idx - 1]\n",
        "    l_3 = predicted_scores_train_sort[l_3_idx - 1]\n",
        "    l_4 = predicted_scores_train_sort[l_4_idx - 1]\n",
        "    l_5 = predicted_scores_train_sort[l_5_idx - 1]\n",
        "\n",
        "    # return [l_m, l_0, l_1, l_2, l_3, l_4, l_5]\n",
        "    return [l_0, l_1, l_2, l_3, l_4, l_5]\n",
        "\n",
        "\n",
        "def float_to_buckets(predicted_labels, thresholds):\n",
        "    bucketed_labels = []\n",
        "    for label in predicted_labels:\n",
        "        if label < thresholds[0]:\n",
        "            bucketed_labels.append(0)\n",
        "        elif label < thresholds[1]:\n",
        "            bucketed_labels.append(1)\n",
        "        elif label < thresholds[2]:\n",
        "            bucketed_labels.append(2)\n",
        "        elif label < thresholds[3]:\n",
        "            bucketed_labels.append(3)\n",
        "        elif label < thresholds[4]:\n",
        "            bucketed_labels.append(4)\n",
        "        else:\n",
        "            bucketed_labels.append(5)\n",
        "\n",
        "    return bucketed_labels\n",
        "\n",
        "\n",
        "def make_directory(dir_path):\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "\n",
        "\n",
        "def combine_dfs(folder):\n",
        "    csv_files = glob.glob(os.path.join(folder, \"distilbert*.csv\"))\n",
        "    df = []\n",
        "    for filename in csv_files:\n",
        "        df.append(pd.read_csv(filename))\n",
        "\n",
        "    df = pd.concat(df)\n",
        "\n",
        "    df.to_csv(os.path.join(folder, \"combined.csv\"))\n"
      ],
      "metadata": {
        "id": "zJO4df_vhi4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87146c9-8d05-4056-b41a-549fb3179fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "X78Zbq6uR7qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          EarlyStoppingCallback, Trainer, TrainingArguments)\n",
        "import torch.nn as nn\n",
        "\n",
        "# from utils import *\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "siod_data = {\n",
        "    \"197\": pd.read_excel(\n",
        "        \"/content/sID 197 Final Ratings (432+50) 10 May 2022.xlsx\",\n",
        "        engine=\"openpyxl\",\n",
        "    ),\n",
        "    \"763\": pd.read_excel(\n",
        "        \"/content/sID 763 Final Rating (107+426) Shared with AI team.xlsx\",\n",
        "        engine=\"openpyxl\",\n",
        "    ),\n",
        "    \"481\": pd.read_excel(\n",
        "        \"/content/sID 481 Final Calibration Sheet (56+441 audios).xlsx\",\n",
        "        engine=\"openpyxl\",\n",
        "    ),\n",
        "    # \"all\": pd.read_excel(\"./data/ucf_data_sampleID.xlsx\", engine=\"openpyxl\"),\n",
        "}\n",
        "\n",
        "prompts = {\n",
        "    \"197\": \"You are responsible for selecting and purchasing equipment to help make your company's manufacturing process more efficient. There are several well-known brands with good reputations available, along with a number of lesser known brands. How would you decide which equipment to purchase? What general factors would you consider and how would each impact your decision?\",\n",
        "    \"763\": \"You are helping an event planner with an important event that involves coordinating several teams working together to setup the hired equipment, deliver the event, and tidy up afterwards. To ensure the event runs smoothly, you have been asked to prepare for anything that could go wrong. What types of problems, both internal and external to your team, could come up that would affect how well the event goes? List as many specific factors as you can.\",\n",
        "    \"481\": \"You have noticed a costly mistake that affected an important customer and quickly realize that the mistake was the result of a decision you made, but no one else knows this. You can fix the mistake without anyone noticing but this would mean that antoher client might be impacted in the future. There would be no way that anyone else to identify you made the mistake.  How would you handle this situation?\",\n",
        "}\n",
        "\n",
        "# Read the data\n",
        "def read_and_clean_dataframe(sid):\n",
        "\n",
        "    data = siod_data[str(sid)]\n",
        "    print(data.columns)\n",
        "\n",
        "    prompt = \"blank\"\n",
        "    print(len(prompt.split()))\n",
        "    \n",
        "    data.rename(\n",
        "        columns={\"Transcripts\": \"transcript\", \"Final Ratings\": \"content_rating\"},\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    data[\"sID\"] = sid\n",
        "    # data = data[[\"sampleId\", \"transcript\", \"content_rating\", \"sID\"]]\n",
        "    data[\"prompt\"] = prompts[str(sid)]\n",
        "    data = data[[\"sampleId\", \"transcript\", \"content_rating\", \"sID\", \"prompt\"]]\n",
        "\n",
        "    print(data.columns)\n",
        "\n",
        "    data = data[data[\"transcript\"] != 0]\n",
        "    data = data[data[\"content_rating\"] != -1]\n",
        "    data.groupby(\"sID\").count()\n",
        "    data = data[data[\"content_rating\"].notna()]\n",
        "\n",
        "    print(data.transcript.iloc[0])\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# Training loop\n",
        "\n",
        "training_config = {\n",
        "    \"stage\": 2,\n",
        "    # \"training_ids\": [197, 481, 763],\n",
        "    \"training_ids\": [763],\n",
        "    # \"training_ids\": [163, 171, 7107165, 7107167, 615],\n",
        "    \"finetune\": True,\n",
        "    \"folds\": 5,\n",
        "    \"split_n\": 1,\n",
        "    \"lr\": 6e-3,\n",
        "    \"use_class_weighting\": True,\n",
        "    \"a_min\": 0.0,\n",
        "    \"a_max\": 3.0,\n",
        "}\n",
        "\n",
        "assert training_config[\"stage\"] in [1, 2, 3], \"Stage has to be 1, 2 or 3!\"\n",
        "\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "output_folder = model_name.replace(\"-\", \"_\")\n",
        "make_directory(output_folder)\n",
        "\n",
        "for sid in training_config[\"training_ids\"]:\n",
        "\n",
        "    result = {}\n",
        "    lst = []\n",
        "    correlation_values = []\n",
        "\n",
        "    data = read_and_clean_dataframe(sid)\n",
        "\n",
        "    train_path = os.path.join(output_folder, str(sid), \"train\")\n",
        "    test_path = os.path.join(output_folder, str(sid), \"test\")\n",
        "    test_path_bare = os.path.join(output_folder, str(sid), \"test_bare\")\n",
        "\n",
        "    make_directory(train_path)\n",
        "    make_directory(test_path)\n",
        "    make_directory(test_path_bare)\n",
        "\n",
        "    # Create the data class\n",
        "    class_data = create_data(\n",
        "        data=data,\n",
        "        sid=sid,\n",
        "        model_name=model_name,\n",
        "        rescale=False,\n",
        "        no_punct=False,\n",
        "        rescale_type=6,\n",
        "        prepend_prompt=False,\n",
        "    )\n",
        "\n",
        "    if training_config[\"stage\"] == 1:\n",
        "        splits = class_data.create_k_fold(training_config[\"folds\"])\n",
        "        iterations = training_config[\"folds\"]\n",
        "\n",
        "    elif training_config[\"stage\"] == 2:\n",
        "        splits = class_data.n_splits(training_config[\"split_n\"])\n",
        "        iterations = training_config[\"split_n\"]\n",
        "\n",
        "    elif training_config[\"stage\"] == 3:\n",
        "        splits = class_data.training_set()\n",
        "        iterations = 1\n",
        "\n",
        "    for fold in range(iterations):\n",
        "\n",
        "        config = AutoConfig.from_pretrained(model_name, num_labels=1)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_name, config=config\n",
        "        )\n",
        "\n",
        "        (\n",
        "            training_loader,\n",
        "            testing_loader,\n",
        "            testing_loader_bare,\n",
        "            train_set,\n",
        "            test_set,\n",
        "            test_set_bare,\n",
        "        ) = class_data.return_k_fold(fold, splits)\n",
        "\n",
        "        print(len(training_loader), len(testing_loader), len(testing_loader_bare))\n",
        "\n",
        "        classes = [0,1,2,3,4,5]\n",
        "        print(f\"classes: {classes}\")\n",
        "\n",
        "        for param in model.base_model.parameters():\n",
        "            if training_config[\"finetune\"]:\n",
        "                param.requires_grad = True\n",
        "                epochs = 25\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "                epochs = 18\n",
        "\n",
        "        def compute_metrics(pred):\n",
        "            global lst\n",
        "            labels = pred.label_ids\n",
        "            preds = pred.predictions\n",
        "            labels = np.squeeze(labels)\n",
        "            preds = np.squeeze(preds)\n",
        "            corr1, _ = pearsonr(labels, preds)\n",
        "            lst.append(corr1)\n",
        "            return {\"corr\": corr1}\n",
        "\n",
        "        if training_config[\"stage\"] == 3:\n",
        "            output_dir = os.path.join(output_folder, str(sid), \"checkpoint\")\n",
        "        else:\n",
        "            output_dir = \"checkpoint\"\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            num_train_epochs=epochs,  # total number of training epochs\n",
        "            per_device_train_batch_size=8,  # batch size per device during training\n",
        "            logging_dir=\"log/\",  # directory for storing logs\n",
        "            logging_steps=1000,\n",
        "            per_device_eval_batch_size=8,\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
        "            weight_decay=0.01,\n",
        "            save_strategy=\"epoch\",\n",
        "            do_eval=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            load_best_model_at_end=True,\n",
        "            greater_is_better=False,\n",
        "        )\n",
        "\n",
        "        if training_config[\"use_class_weighting\"]:\n",
        "            weights = compute_class_weight(\n",
        "                class_weight='balanced',\n",
        "                classes=np.unique(train_set['content_rating'].tolist()),\n",
        "                y=train_set['content_rating'].tolist()\n",
        "            )\n",
        "            unique_l = np.unique(train_set['content_rating'].tolist())\n",
        "            print(f\"unique_l: {unique_l}\")\n",
        "            print(f\"old weights: {weights}\")\n",
        "            weights = np.clip(weights, a_min=training_config[\"a_min\"], a_max=training_config[\"a_max\"])\n",
        "            print(f\"new weights: {weights}\")\n",
        "\n",
        "        else:\n",
        "            weights = [1,1,1,1,1,1]\n",
        "        \n",
        "        # reduce weight of the \"0\" class\n",
        "        # weights[0] = 1.0\n",
        "            \n",
        "        class CustomTrainer(Trainer):\n",
        "            def compute_loss(self, model, inputs, return_outputs=False):\n",
        "                global weights\n",
        "                global classes\n",
        "                #global unique_l\n",
        "                labels = inputs.get(\"labels\")\n",
        "                # forward pass\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.get(\"logits\")\n",
        "                #print(\"output\")\n",
        "                # compute custom loss (suppose one has 3 labels with different weights)\n",
        "                loss_fct = nn.MSELoss()\n",
        "                model_logits = logits.view(-1).cuda()\n",
        "                model_labels = labels.view(-1).cuda()\n",
        "                #loss = loss_fct(model_logits, model_labels)\n",
        "                #return (loss, outputs) if return_outputs else loss \n",
        "            \n",
        "                global_loss = 0\n",
        "                \n",
        "                weightDict = {}\n",
        "                for i,value in zip(classes,weights):\n",
        "                        weightDict[i] = value\n",
        "                        \n",
        "                #print(\"WeightedLoss :\",weightDict)\n",
        "                #for i in [1,2,3,4]:\n",
        "                for i in classes:\n",
        "                    #print(i)\n",
        "                    indexes = (model_labels == i).nonzero(as_tuple=True)[0].cuda()\n",
        "                    #print(\"ind\",indexes)\n",
        "                    logits_for_this_rating = torch.index_select(model_logits, 0, indexes).cuda()\n",
        "                    labels_for_this_rating = torch.index_select(model_labels, 0, indexes).cuda()\n",
        "                    losses = loss_fct(logits_for_this_rating, labels_for_this_rating)\n",
        "                    \n",
        "                    #print(\"Loss:\",losses)\n",
        "                    if(torch.isnan(losses)):\n",
        "                        global_loss+= 0\n",
        "                        continue\n",
        "                    global_loss+= weightDict[i]*losses\n",
        "                    #print(\"Weighted Loss\",weightDict[i]*loss)\n",
        "                    #global_loss += loss\n",
        "                    #print(\"Loss :\",loss)\n",
        "                    #print(\"wt :\",weightDict[i.item()]*loss)\n",
        "                    #print(\"loss :\",i,\":\",weightDict[i.item()]*loss,(global_loss))\n",
        "                    #print(global_loss)\n",
        "\n",
        "                return (global_loss, outputs) if return_outputs else global_loss\n",
        "\n",
        "\n",
        "        trainer = Trainer(\n",
        "        # trainer = CustomTrainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=training_loader,\n",
        "            eval_dataset=testing_loader,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
        "            data_collator=None,\n",
        "        )\n",
        "        trainer.train()\n",
        "\n",
        "        # Generate predictions for the respective sets\n",
        "        outs = trainer.predict(testing_loader)\n",
        "        outs_bare = trainer.predict(testing_loader_bare)\n",
        "        outs_train = trainer.predict(training_loader)\n",
        "\n",
        "        test_set[\"predictions\"] = [i[0] for i in outs.predictions]\n",
        "        test_set[\"predictions_rescaled\"] = class_data.rescale_data(\n",
        "            test_set[[\"predictions\"]]\n",
        "        )\n",
        "\n",
        "        train_set[\"predictions\"] = [i[0] for i in outs_train.predictions]\n",
        "        train_set[\"predictions_rescaled\"] = class_data.rescale_data(\n",
        "            train_set[[\"predictions\"]]\n",
        "        )\n",
        "\n",
        "        test_set_bare[\"predictions\"] = [i[0] for i in outs_bare.predictions]\n",
        "        test_set_bare[\"predictions_rescaled\"] = class_data.rescale_data(\n",
        "            test_set_bare[[\"predictions\"]]\n",
        "        )\n",
        "\n",
        "        # Append the correlation values per iteration to a dataframe\n",
        "        if training_config[\"stage\"] == 2:\n",
        "            correlation_values.append(\n",
        "                {\n",
        "                    \"iteration\": fold,\n",
        "                    \"test_corr\": pearsonr(\n",
        "                        test_set[\"content_rating\"], test_set[\"predictions\"]\n",
        "                    )[0],\n",
        "                    \"train_corr\": pearsonr(\n",
        "                        train_set[\"content_rating\"], train_set[\"predictions\"]\n",
        "                    )[0],\n",
        "                }\n",
        "            )\n",
        "\n",
        "        thresholds = get_thresholds(\n",
        "            train_set[\"predictions_rescaled\"].tolist(),\n",
        "            train_set[\"content_rating\"].tolist(),\n",
        "        )\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "\n",
        "        def append_pwl_scores(output_dict, thresholds):\n",
        "            pwl = []\n",
        "            for score in output_dict[\"predictions_rescaled\"].tolist():\n",
        "                pwl.append(get_pwl_score(score, thresholds))\n",
        "            output_dict[\"pwl_score_100\"] = pwl\n",
        "            output_dict[\"actual_pwl_score_100\"] = output_dict[\"content_rating\"] * 20\n",
        "\n",
        "            return output_dict\n",
        "\n",
        "        test_set = append_pwl_scores(test_set, thresholds)\n",
        "        test_set_bare = append_pwl_scores(test_set_bare, thresholds)\n",
        "\n",
        "        # Note: Append a score of 0 for the thresholds list when\n",
        "        # processing the training set\n",
        "        thresholds[0] = 0\n",
        "        train_set = append_pwl_scores(train_set, thresholds)\n",
        "\n",
        "        # Save csv files\n",
        "        if training_config[\"stage\"] == 1:\n",
        "            test_set.to_csv(\n",
        "                os.path.join(\n",
        "                    test_path,\n",
        "                    f\"{model_name.split('/')[0]}_fold_{str(fold)}_sid_{str(sid)}.csv\",\n",
        "                )\n",
        "            )\n",
        "            test_set_bare.to_csv(\n",
        "                os.path.join(\n",
        "                    test_path_bare,\n",
        "                    f\"{model_name.split('/')[0]}_fold_{str(fold)}_sid_{str(sid)}.csv\",\n",
        "                )\n",
        "            )\n",
        "            train_set.to_csv(\n",
        "                os.path.join(\n",
        "                    train_path,\n",
        "                    f\"{model_name.split('/')[0]}_fold_{str(fold)}_sid_{str(sid)}.csv\",\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        print(f\"Epochs: {sid}\")\n",
        "\n",
        "        if training_config[\"stage\"] == 3:\n",
        "            trainer.save_model(output_dir)\n",
        "\n",
        "        # Delete all checkpoints if the model is not in the final stage\n",
        "        print(\"Removing checkpoint directory\")\n",
        "        shutil.rmtree(\"checkpoint\")\n",
        "\n",
        "    if training_config[\"stage\"] == 2:\n",
        "        correlation_values = pd.DataFrame(correlation_values)\n",
        "        correlation_values.to_csv(\n",
        "            os.path.join(output_folder, str(sid), \"correlation_values.csv\"),\n",
        "            index=False,\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ebb03d575bf40da8fba35ad59611a90",
            "9789188de68b4172ad061134bf560346",
            "86dcc6f2470546eb965d3db0f38568f7",
            "8d9048b606e643f7958e14a00cc5d296",
            "9c24a912322e4bf29f4f6125d68fb8a8",
            "a3e0590b7f4347abaa5642d61f79d952",
            "1d89a12aac21409c851f2d4f9dd723aa",
            "fe0629aa5fd14a4496a809a7599a5db8",
            "b07f9bd38a544872a08cfab581419828",
            "80e9679dcc9b43f7aa7e474beecbdedf",
            "46ee60183ac6451b89814d5ae7fd4e1b",
            "24790a362e574889bcb3371b3833590e",
            "f567ebc682b34829a1ae599f24c2a061",
            "79f8f1411cfd4d359f769b1d5c163817",
            "58593e7fc38245c494dc123179200503",
            "fe2251675341486d8c598f26ae3e72ee",
            "1a4b05b89cec469996240b798807a6a1",
            "4aeb2c4dc2f342c8a825d20cb65a1450",
            "433c2f2f66224e9fa741b7eb0a0ff8f1",
            "3ec8d5758e0f4e8fb8f616f80da0d93f",
            "3e7340a9112b4d9c9dd9332427ae09c9",
            "0642fb0d421b47879d906621c242c776",
            "14e4c913852349328743befde69ef839",
            "7914c53bde1f450c909d6e43046660c1",
            "6a6404754a7643a08d741564df811fc6",
            "bb8ea84d0c064e2ea9a28a1ce75e34d8",
            "bb2fd8b40fa04321bb70d0187b96bfe8",
            "d2bb2f8552044cc2ac212916633fc0cd",
            "3bdea0d2c8974fc3ad82b6419ab46e6f",
            "da5d6b8d7f824f948166fc8753bff543",
            "aa38c56c9d48486f9077c2687bba98f6",
            "c1ad10423ac942678ecf01020c6aee3a",
            "4b9638b556504ea2b7091dca8eedb37f"
          ]
        },
        "id": "wn-LfDw3QsN6",
        "outputId": "71f73c1b-9a02-494c-f454-c8a21933f9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['sampleId', 'Transcripts', 'Rahul Final Ratings',\n",
            "       'Vivaksha _Final Ratings', 'Shloka_Final Ratings', 'Final Ratings',\n",
            "       'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10'],\n",
            "      dtype='object')\n",
            "1\n",
            "Index(['sampleId', 'transcript', 'content_rating', 'sID', 'prompt'], dtype='object')\n",
            "I'm so I'm going to help the event planner and I'm going to list the things that could go wrong internally and externally. And so manly, and I think that what could go wrong is that the Hyder equipment doesn't come in time, and this happens a lot of events and things don't turn up and things are alert and things just go missing, so that could go wrong. You know, companies aren't very reliable sometimes and then also with equipment as well being electronics mainly and they couldn't work. They might not work, so we need maybe backups and things like lights and that could go wrong. People could drop them, they could smash anything like that and also with the tidying up afterwards would be careful with the equipment of these hired so we need to like make sure it's going all right and go smoothly. And so yeah, they're the majority of things when you just to make sure there's backups. And people are on board of everything and yeah. \n",
            "Total data points: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({3.0: 173, 1.0: 78, 4.0: 68, 2.0: 55, 5.0: 25, 0.0: 10})\n",
            "Counter({3.0: 44, 1.0: 19, 4.0: 17, 2.0: 14, 5.0: 6, 0.0: 3})\n",
            "Counter({3.0: 44, 1.0: 19, 4.0: 17, 2.0: 14, 5.0: 6, 0.0: 3})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ebb03d575bf40da8fba35ad59611a90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24790a362e574889bcb3371b3833590e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14e4c913852349328743befde69ef839"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running training *****\n",
            "  Num examples = 409\n",
            "  Num Epochs = 25\n",
            "  Instantaneous batch size per device = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "409 103 103\n",
            "classes: [0, 1, 2, 3, 4, 5]\n",
            "unique_l: [0. 1. 2. 3. 4. 5.]\n",
            "old weights: [6.81666667 0.87393162 1.23939394 0.39402697 1.00245098 2.72666667]\n",
            "new weights: [3.         0.87393162 1.23939394 0.39402697 1.00245098 2.72666667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1300\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='416' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 416/1300 02:41 < 05:44, 2.56 it/s, Epoch 8/25]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Corr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.684642</td>\n",
              "      <td>0.117830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.071562</td>\n",
              "      <td>0.646161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.668096</td>\n",
              "      <td>0.741702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.770779</td>\n",
              "      <td>0.714354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.681474</td>\n",
              "      <td>0.786441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.929545</td>\n",
              "      <td>0.730308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.851387</td>\n",
              "      <td>0.759027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.778035</td>\n",
              "      <td>0.696823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to checkpoint/checkpoint-52\n",
            "Configuration saved in checkpoint/checkpoint-52/config.json\n",
            "Model weights saved in checkpoint/checkpoint-52/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to checkpoint/checkpoint-104\n",
            "Configuration saved in checkpoint/checkpoint-104/config.json\n",
            "Model weights saved in checkpoint/checkpoint-104/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to checkpoint/checkpoint-156\n",
            "Configuration saved in checkpoint/checkpoint-156/config.json\n",
            "Model weights saved in checkpoint/checkpoint-156/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to checkpoint/checkpoint-208\n",
            "Configuration saved in checkpoint/checkpoint-208/config.json\n",
            "Model weights saved in checkpoint/checkpoint-208/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to checkpoint/checkpoint-260\n",
            "Configuration saved in checkpoint/checkpoint-260/config.json\n",
            "Model weights saved in checkpoint/checkpoint-260/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to checkpoint/checkpoint-312\n",
            "Configuration saved in checkpoint/checkpoint-312/config.json\n",
            "Model weights saved in checkpoint/checkpoint-312/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to checkpoint/checkpoint-364\n",
            "Configuration saved in checkpoint/checkpoint-364/config.json\n",
            "Model weights saved in checkpoint/checkpoint-364/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to checkpoint/checkpoint-416\n",
            "Configuration saved in checkpoint/checkpoint-416/config.json\n",
            "Model weights saved in checkpoint/checkpoint-416/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from checkpoint/checkpoint-156 (score: 0.6680962443351746).\n",
            "The following columns in the test set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='78' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 409\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts :  Counter({3: 173, 1: 78, 4: 68, 2: 55, 5: 25, 0: 10})\n",
            "thresholds: [0.8160083293914795, 1.57112717628479, 2.4066436290740967, 3.366511821746826, 3.492882013320923, 3.5841774940490723]\n",
            "Epochs: 763\n",
            "Removing checkpoint directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree(\"/content/distilbert_base_uncased/763/checkpoint\")"
      ],
      "metadata": {
        "id": "db-ZM8dGRygo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "a_TElUtsa30K",
        "outputId": "60f5dbbc-b9bc-4e21-d372-831fe1ca9c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 sampleId  \\\n",
              "332  5e89ec793c01b3685a00bb12_7700763.wav   \n",
              "5    5ae96d1878b0060001e69b8a_7700763.wav   \n",
              "511  6136e715cf2e36f0dfb894e5_7700763.wav   \n",
              "\n",
              "                                            transcript  content_rating  sID  \\\n",
              "332  So there are several things that could be cons...             3.0  763   \n",
              "5    There are many things that can go wrong, proba...             3.0  763   \n",
              "511  We need to focus firstly on delegating tasks a...             1.0  763   \n",
              "\n",
              "                                                prompt  content_rating_scaled  \\\n",
              "332  You are helping an event planner with an impor...                    0.6   \n",
              "5    You are helping an event planner with an impor...                    0.6   \n",
              "511  You are helping an event planner with an impor...                    0.2   \n",
              "\n",
              "    stratify  predictions  predictions_rescaled  pwl_score_100  \\\n",
              "332      3.0     1.979452              1.979452      24.717734   \n",
              "5        3.0     1.781934              1.781934      18.807667   \n",
              "511      1.0     0.904262              0.904262       5.876552   \n",
              "\n",
              "     actual_pwl_score_100  \n",
              "332                  60.0  \n",
              "5                    60.0  \n",
              "511                  20.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7e2c4e6-bd21-464f-a6b5-c5f379bcaf80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sampleId</th>\n",
              "      <th>transcript</th>\n",
              "      <th>content_rating</th>\n",
              "      <th>sID</th>\n",
              "      <th>prompt</th>\n",
              "      <th>content_rating_scaled</th>\n",
              "      <th>stratify</th>\n",
              "      <th>predictions</th>\n",
              "      <th>predictions_rescaled</th>\n",
              "      <th>pwl_score_100</th>\n",
              "      <th>actual_pwl_score_100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>5e89ec793c01b3685a00bb12_7700763.wav</td>\n",
              "      <td>So there are several things that could be cons...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>763</td>\n",
              "      <td>You are helping an event planner with an impor...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.979452</td>\n",
              "      <td>1.979452</td>\n",
              "      <td>24.717734</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5ae96d1878b0060001e69b8a_7700763.wav</td>\n",
              "      <td>There are many things that can go wrong, proba...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>763</td>\n",
              "      <td>You are helping an event planner with an impor...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.781934</td>\n",
              "      <td>1.781934</td>\n",
              "      <td>18.807667</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>6136e715cf2e36f0dfb894e5_7700763.wav</td>\n",
              "      <td>We need to focus firstly on delegating tasks a...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>763</td>\n",
              "      <td>You are helping an event planner with an impor...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.904262</td>\n",
              "      <td>0.904262</td>\n",
              "      <td>5.876552</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7e2c4e6-bd21-464f-a6b5-c5f379bcaf80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7e2c4e6-bd21-464f-a6b5-c5f379bcaf80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7e2c4e6-bd21-464f-a6b5-c5f379bcaf80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "# trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=training_loader,\n",
        "    eval_dataset=testing_loader,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
        "    data_collator=None,\n",
        ")\n",
        "\n",
        "print(trainer.evaluate())\n",
        "\n",
        "trainer.save_model('/content/distilbert_base_uncased/763')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "evxwUoJubNif",
        "outputId": "d370c0a2-0f6d-4257-ea9c-ddf78d550cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sampleId, prompt, sID, __index_level_0__, content_rating, stratify, transcript, content_rating_scaled.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 103\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/distilbert_base_uncased/763\n",
            "Configuration saved in /content/distilbert_base_uncased/763/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6680962443351746, 'eval_corr': 0.7417024276123362, 'eval_runtime': 1.3237, 'eval_samples_per_second': 77.812, 'eval_steps_per_second': 9.821}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/distilbert_base_uncased/763/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.to_csv('/content/distilbert_base_uncased/763/test/test_dump.csv')\n",
        "test_set_bare.to_csv('/content/distilbert_base_uncased/763/test_bare/test_set_bare_dump.csv')\n",
        "train_set.to_csv('/content/distilbert_base_uncased/763/train/train_dump.csv')"
      ],
      "metadata": {
        "id": "Rn9PKP5vSAIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack"
      ],
      "metadata": {
        "id": "nqxCuzq6YfSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "siod_data['197'][['Transcripts', 'Final Ratings']].values[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzhGaIu-YgnZ",
        "outputId": "7a18bc87-b781-4910-aba6-f05870eea209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"I'd look at all the reviews. To be perfectly honest with you, I would also look for recommendations and I probably go into a store as well just to have like I can get a good feel about stuff. But yeah, I had. Recommendations I think. \",\n",
              "       2], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = '/content/drive/MyDrive/Attack_SIOD/763/pytorch_model.bin'\n",
        "config = AutoConfig.from_pretrained(model_name, num_labels=1)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_file, config=config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "ADuoGpd8SsFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textattack import Attack\n",
        "from textattack.models.wrappers import PyTorchModelWrapper, HuggingFaceModelWrapper\n",
        "from textattack.search_methods import GreedySearch, GreedyWordSwapWIR\n",
        "from textattack.goal_functions import UntargetedClassification, ClassificationGoalFunction, GoalFunction\n",
        "from textattack.transformations import WordSwapEmbedding\n",
        "from textattack.transformations import (\n",
        "    CompositeTransformation,\n",
        "    WordInsertionMaskedLM,\n",
        "    WordMergeMaskedLM,\n",
        "    WordSwapMaskedLM,\n",
        ")\n",
        "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder, BERT\n",
        "from textattack.constraints.grammaticality import PartOfSpeech\n",
        "from textattack.constraints.pre_transformation import (\n",
        "    InputColumnModification,\n",
        "    MaxModificationRate,\n",
        "    RepeatModification,\n",
        "    StopwordModification,\n",
        ")\n",
        "from textattack.constraints.semantics import WordEmbeddingDistance\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "jeNRncLQCkpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal function"
      ],
      "metadata": {
        "id": "0V-BRZ3ny6GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\".. _goal_function:\n",
        "\n",
        "GoalFunction Class\n",
        "===========================================================\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "import lru\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from textattack.goal_function_results.goal_function_result import (\n",
        "    GoalFunctionResultStatus,\n",
        ")\n",
        "from textattack.shared import validators\n",
        "from textattack.shared.utils import ReprMixin\n",
        "\n",
        "\n",
        "class GoalFunction(ReprMixin, ABC):\n",
        "    \"\"\"Evaluates how well a perturbed attacked_text object is achieving a\n",
        "    specified goal.\n",
        "\n",
        "    Args:\n",
        "        model_wrapper (:class:`~textattack.models.wrappers.ModelWrapper`):\n",
        "            The victim model to attack.\n",
        "        maximizable(:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
        "            Whether the goal function is maximizable, as opposed to a boolean result of success or failure.\n",
        "        query_budget (:obj:`float`, `optional`, defaults to :obj:`float(\"in\")`):\n",
        "            The maximum number of model queries allowed.\n",
        "        model_cache_size (:obj:`int`, `optional`, defaults to :obj:`2**20`):\n",
        "            The maximum number of items to keep in the model results cache at once.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_wrapper,\n",
        "        maximizable=False,\n",
        "        use_cache=True,\n",
        "        query_budget=float(\"inf\"),\n",
        "        model_batch_size=32,\n",
        "        model_cache_size=2**20,\n",
        "    ):\n",
        "        validators.validate_model_goal_function_compatibility(\n",
        "            self.__class__, model_wrapper.model.__class__\n",
        "        )\n",
        "        self.model = model_wrapper\n",
        "        self.maximizable = maximizable\n",
        "        self.use_cache = use_cache\n",
        "        self.use_cache = False\n",
        "        self.query_budget = query_budget\n",
        "        self.batch_size = model_batch_size\n",
        "        if self.use_cache:\n",
        "            self._call_model_cache = lru.LRU(model_cache_size)\n",
        "        else:\n",
        "            self._call_model_cache = None\n",
        "\n",
        "\n",
        "    def clear_cache(self):\n",
        "        if self.use_cache:\n",
        "            self._call_model_cache.clear()\n",
        "\n",
        "    def init_attack_example(self, attacked_text, ground_truth_output):\n",
        "        \"\"\"Called before attacking ``attacked_text`` to 'reset' the goal\n",
        "        function and set properties for this example.\"\"\"\n",
        "        self.initial_attacked_text = attacked_text\n",
        "        self.ground_truth_output = ground_truth_output\n",
        "        self.num_queries = 0\n",
        "        result, _ = self.get_result(attacked_text, check_skip=True)\n",
        "        return result, _\n",
        "\n",
        "    def get_output(self, attacked_text):\n",
        "        \"\"\"Returns output for display based on the result of calling the\n",
        "        model.\"\"\"\n",
        "        return self._get_displayed_output(self._call_model([attacked_text])[0])\n",
        "\n",
        "    def get_result(self, attacked_text, **kwargs):\n",
        "        \"\"\"A helper method that queries ``self.get_results`` with a single\n",
        "        ``AttackedText`` object.\"\"\"\n",
        "        results, search_over = self.get_results([attacked_text], **kwargs)\n",
        "        result = results[0] if len(results) else None\n",
        "        return result, search_over\n",
        "\n",
        "    def get_results(self, attacked_text_list, check_skip=False):\n",
        "        \"\"\"For each attacked_text object in attacked_text_list, returns a\n",
        "        result consisting of whether or not the goal has been achieved, the\n",
        "        output for display purposes, and a score.\n",
        "\n",
        "        Additionally returns whether the search is over due to the query\n",
        "        budget.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        if self.query_budget < float(\"inf\"):\n",
        "            queries_left = self.query_budget - self.num_queries\n",
        "            attacked_text_list = attacked_text_list[:queries_left]\n",
        "        self.num_queries += len(attacked_text_list)\n",
        "        model_outputs = self._call_model(attacked_text_list)\n",
        "        # print(f'model_outputs = {model_outputs}')\n",
        "        for attacked_text, raw_output in zip(attacked_text_list, model_outputs):\n",
        "\n",
        "            displayed_output = self._get_displayed_output(raw_output)\n",
        "            # print(f'raw_output = {raw_output} vs displayed_output = {displayed_output}')\n",
        "            goal_status = self._get_goal_status(\n",
        "                raw_output, attacked_text, check_skip=check_skip\n",
        "            )\n",
        "            goal_function_score = self._get_score(raw_output, attacked_text)\n",
        "            results.append(\n",
        "                self._goal_function_result_type()(\n",
        "                    attacked_text,\n",
        "                    raw_output,\n",
        "                    displayed_output,\n",
        "                    goal_status,\n",
        "                    goal_function_score,\n",
        "                    self.num_queries,\n",
        "                    self.ground_truth_output,\n",
        "                )\n",
        "            )\n",
        "        # print(f'gaol-res:{results}')\n",
        "        return results, self.num_queries == self.query_budget\n",
        "\n",
        "    def _get_goal_status(self, model_output, attacked_text, check_skip=False):\n",
        "        should_skip = check_skip and self._should_skip(model_output, attacked_text)\n",
        "        if should_skip:\n",
        "            return GoalFunctionResultStatus.SKIPPED\n",
        "        if self.maximizable:\n",
        "            return GoalFunctionResultStatus.MAXIMIZING\n",
        "        if self._is_goal_complete(model_output, attacked_text):\n",
        "            return GoalFunctionResultStatus.SUCCEEDED\n",
        "        return GoalFunctionResultStatus.SEARCHING\n",
        "\n",
        "    @abstractmethod\n",
        "    def _is_goal_complete(self, model_output, attacked_text):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _should_skip(self, model_output, attacked_text):\n",
        "        return self._is_goal_complete(model_output, attacked_text)\n",
        "\n",
        "    @abstractmethod\n",
        "    def _get_score(self, model_output, attacked_text):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _get_displayed_output(self, raw_output):\n",
        "        return raw_output\n",
        "\n",
        "    @abstractmethod\n",
        "    def _goal_function_result_type(self):\n",
        "        \"\"\"Returns the class of this goal function's results.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @abstractmethod\n",
        "    def _process_model_outputs(self, inputs, outputs):\n",
        "        \"\"\"Processes and validates a list of model outputs.\n",
        "\n",
        "        This is a task-dependent operation. For example, classification\n",
        "        outputs need to make sure they have a softmax applied.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _call_model_uncached(self, attacked_text_list):\n",
        "        \"\"\"Queries model and returns outputs for a list of AttackedText\n",
        "        objects.\"\"\"\n",
        "        if not len(attacked_text_list):\n",
        "            return []\n",
        "\n",
        "        inputs = [at.tokenizer_input for at in attacked_text_list]\n",
        "        outputs = []\n",
        "        i = 0\n",
        "        while i < len(inputs):\n",
        "            batch = inputs[i : i + self.batch_size]\n",
        "            batch_preds = self.model(batch)\n",
        "\n",
        "            # Some seq-to-seq models will return a single string as a prediction\n",
        "            # for a single-string list. Wrap these in a list.\n",
        "            if isinstance(batch_preds, str):\n",
        "                batch_preds = [batch_preds]\n",
        "\n",
        "            # Get PyTorch tensors off of other devices.\n",
        "            if isinstance(batch_preds, torch.Tensor):\n",
        "                batch_preds = batch_preds.cpu()\n",
        "\n",
        "            if isinstance(batch_preds, list):\n",
        "                outputs.extend(batch_preds)\n",
        "            elif isinstance(batch_preds, np.ndarray):\n",
        "                outputs.append(torch.tensor(batch_preds))\n",
        "            else:\n",
        "                outputs.append(batch_preds)\n",
        "            i += self.batch_size\n",
        "\n",
        "        if isinstance(outputs[0], torch.Tensor):\n",
        "            outputs = torch.cat(outputs, dim=0)\n",
        "\n",
        "        assert len(inputs) == len(\n",
        "            outputs\n",
        "        ), f\"Got {len(outputs)} outputs for {len(inputs)} inputs\"\n",
        "        # print(f'gaol fun-out : {outputs}')\n",
        "\n",
        "        return self._process_model_outputs(attacked_text_list, outputs)\n",
        "\n",
        "    def _call_model(self, attacked_text_list):\n",
        "        \"\"\"Gets predictions for a list of ``AttackedText`` objects.\n",
        "\n",
        "        Gets prediction from cache if possible. If prediction is not in\n",
        "        the cache, queries model and stores prediction in cache.\n",
        "        \"\"\"\n",
        "        if not self.use_cache:\n",
        "            return self._call_model_uncached(attacked_text_list)\n",
        "        else:\n",
        "            uncached_list = []\n",
        "            for text in attacked_text_list:\n",
        "                if text in self._call_model_cache:\n",
        "                    # Re-write value in cache. This moves the key to the top of the\n",
        "                    # LRU cache and prevents the unlikely event that the text\n",
        "                    # is overwritten when we store the inputs from `uncached_list`.\n",
        "                    self._call_model_cache[text] = self._call_model_cache[text]\n",
        "                else:\n",
        "                    uncached_list.append(text)\n",
        "            uncached_list = [\n",
        "                text\n",
        "                for text in attacked_text_list\n",
        "                if text not in self._call_model_cache\n",
        "            ]\n",
        "            outputs = self._call_model_uncached(uncached_list)\n",
        "            for text, output in zip(uncached_list, outputs):\n",
        "                self._call_model_cache[text] = output\n",
        "            all_outputs = [self._call_model_cache[text] for text in attacked_text_list]\n",
        "            all_outputs = self._call_model_uncached(attacked_text_list)\n",
        "            # print(f'all_outputs : {all_outputs}')\n",
        "            return all_outputs\n",
        "\n",
        "    def extra_repr_keys(self):\n",
        "        attrs = []\n",
        "        if self.query_budget < float(\"inf\"):\n",
        "            attrs.append(\"query_budget\")\n",
        "        if self.maximizable:\n",
        "            attrs.append(\"maximizable\")\n",
        "        return attrs\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        if self.use_cache:\n",
        "            state[\"_call_model_cache\"] = self._call_model_cache.get_size()\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        self.__dict__ = state\n",
        "        if self.use_cache:\n",
        "            self._call_model_cache = lru.LRU(state[\"_call_model_cache\"])\n"
      ],
      "metadata": {
        "id": "ZTRJBy35zVDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textattack.goal_function_results import ClassificationGoalFunctionResult\n",
        "class RegressionGoalFunction(GoalFunction):\n",
        "    \"\"\"A goal function defined on a model that outputs a probability for some\n",
        "    number of classes.\"\"\"\n",
        "\n",
        "    def _process_model_outputs(self, inputs, scores):\n",
        "        \"\"\"Processes and validates a list of model outputs.\n",
        "\n",
        "        This is a task-dependent operation. For example, classification\n",
        "        outputs need to have a softmax applied.\n",
        "        \"\"\"\n",
        "        # Automatically cast a list or ndarray of predictions to a tensor.\n",
        "        # print(f'process model output input= {scores}')\n",
        "        if isinstance(scores, list) or isinstance(scores, np.ndarray):\n",
        "            scores = torch.tensor(scores)\n",
        "\n",
        "        # Ensure the returned value is now a tensor.\n",
        "        if not isinstance(scores, torch.Tensor):\n",
        "            raise TypeError(\n",
        "                \"Must have list, np.ndarray, or torch.Tensor of \"\n",
        "                f\"scores. Got type {type(scores)}\"\n",
        "            )\n",
        "\n",
        "        # Validation check on model score dimensions\n",
        "        if scores.ndim == 1:\n",
        "            # Unsqueeze prediction, if it's been squeezed by the model.\n",
        "            if len(inputs) == 1:\n",
        "                scores = scores.unsqueeze(dim=0)\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
        "                )\n",
        "        elif scores.ndim != 2:\n",
        "            # If model somehow returns too may dimensions, throw an error.\n",
        "            raise ValueError(\n",
        "                f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
        "            )\n",
        "        elif scores.shape[0] != len(inputs):\n",
        "            # If model returns an incorrect number of scores, throw an error.\n",
        "            raise ValueError(\n",
        "                f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
        "            )\n",
        "        # elif not ((scores.sum(dim=1) - 1).abs() < 1e-6).all():\n",
        "        #     # Values in each row should sum up to 1. The model should return a\n",
        "        #     # set of numbers corresponding to probabilities, which should add\n",
        "        #     # up to 1. Since they are `torch.float` values, allow a small\n",
        "        #     # error in the summation.\n",
        "        #     if scores.numel()>1:\n",
        "        #         scores = torch.nn.functional.softmax(scores, dim=1)\n",
        "        #         print('applying softmax')\n",
        "        #         if not ((scores.sum(dim=1) - 1).abs() < 1e-6).all():\n",
        "        #             raise ValueError(\"Model scores do not add up to 1.\")\n",
        "        # print(f'process model output output= {scores}')\n",
        "        return scores.cpu().float()\n",
        "\n",
        "    def _goal_function_result_type(self):\n",
        "        \"\"\"Returns the class of this goal function's results.\"\"\"\n",
        "        return ClassificationGoalFunctionResult\n",
        "\n",
        "    def extra_repr_keys(self):\n",
        "        return []\n",
        "\n",
        "\n",
        "    def _get_displayed_output(self, raw_output):\n",
        "        return raw_output#int(raw_output.argmax())"
      ],
      "metadata": {
        "id": "HfSrRXdG0D6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pandas._libs.algos import groupsort_indexer\n",
        "class TargetedRegression(RegressionGoalFunction):\n",
        "    \"\"\"An untargeted attack on classification models which attempts to minimize\n",
        "    the score of the correct label until it is no longer the predicted label.\n",
        "\n",
        "    Args:\n",
        "        target_max_score (float): If set, goal is to reduce model output to\n",
        "            below this score. Otherwise, goal is to change the overall predicted\n",
        "            class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, target_max_score=None, **kwargs):\n",
        "        self.target_max_score = target_max_score\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def _is_goal_complete(self, model_output, _):\n",
        "        if self.target_max_score:\n",
        "            return model_output[self.ground_truth_output] < self.target_max_score\n",
        "        elif (model_output.numel() == 1):\n",
        "            # print(self.ground_truth_output, model_output.item())\n",
        "            # print(self.cda)\n",
        "            return model_output.item() - self.ground_truth_output  >= 1.5\n",
        "        else:\n",
        "            return model_output.argmax() != self.ground_truth_output\n",
        "\n",
        "    def _get_score(self, model_output, _):\n",
        "        # If the model outputs a single number and the ground truth output is\n",
        "        # a float, we assume that this is a regression task.\n",
        "        if (model_output.numel() == 1) :\n",
        "            # print(model_output.item(), self.ground_truth_output)\n",
        "            return model_output.item() - self.ground_truth_output \n",
        "        else:\n",
        "            return 1 - model_output[self.ground_truth_output]"
      ],
      "metadata": {
        "id": "EBgtpsySb0pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack.py"
      ],
      "metadata": {
        "id": "_GDiYkMT12Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Attack Class\n",
        "============\n",
        "\"\"\"\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import List, Union\n",
        "\n",
        "import lru\n",
        "import torch\n",
        "\n",
        "import textattack\n",
        "from textattack.attack_results import (\n",
        "    FailedAttackResult,\n",
        "    MaximizedAttackResult,\n",
        "    SkippedAttackResult,\n",
        "    SuccessfulAttackResult,\n",
        ")\n",
        "from textattack.constraints import Constraint, PreTransformationConstraint\n",
        "from textattack.goal_function_results import GoalFunctionResultStatus\n",
        "# from textattack.goal_functions import GoalFunction\n",
        "from textattack.models.wrappers import ModelWrapper\n",
        "from textattack.search_methods import SearchMethod\n",
        "from textattack.shared import AttackedText, utils\n",
        "from textattack.transformations import CompositeTransformation, Transformation\n",
        "\n",
        "\n",
        "class Attack:\n",
        "    \"\"\"An attack generates adversarial examples on text.\n",
        "\n",
        "    An attack is comprised of a goal function, constraints, transformation, and a search method. Use :meth:`attack` method to attack one sample at a time.\n",
        "\n",
        "    Args:\n",
        "        goal_function (:class:`~textattack.goal_functions.GoalFunction`):\n",
        "            A function for determining how well a perturbation is doing at achieving the attack's goal.\n",
        "        constraints (list of :class:`~textattack.constraints.Constraint` or :class:`~textattack.constraints.PreTransformationConstraint`):\n",
        "            A list of constraints to add to the attack, defining which perturbations are valid.\n",
        "        transformation (:class:`~textattack.transformations.Transformation`):\n",
        "            The transformation applied at each step of the attack.\n",
        "        search_method (:class:`~textattack.search_methods.SearchMethod`):\n",
        "            The method for exploring the search space of possible perturbations\n",
        "        transformation_cache_size (:obj:`int`, `optional`, defaults to :obj:`2**15`):\n",
        "            The number of items to keep in the transformations cache\n",
        "        constraint_cache_size (:obj:`int`, `optional`, defaults to :obj:`2**15`):\n",
        "            The number of items to keep in the constraints cache\n",
        "\n",
        "    Example::\n",
        "\n",
        "        >>> import textattack\n",
        "        >>> import transformers\n",
        "\n",
        "        >>> # Load model, tokenizer, and model_wrapper\n",
        "        >>> model = transformers.AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
        "        >>> tokenizer = transformers.AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
        "        >>> model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(model, tokenizer)\n",
        "\n",
        "        >>> # Construct our four components for `Attack`\n",
        "        >>> from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n",
        "        >>> from textattack.constraints.semantics import WordEmbeddingDistance\n",
        "\n",
        "        >>> goal_function = textattack.goal_functions.UntargetedClassification(model_wrapper)\n",
        "        >>> constraints = [\n",
        "        ...     RepeatModification(),\n",
        "        ...     StopwordModification()\n",
        "        ...     WordEmbeddingDistance(min_cos_sim=0.9)\n",
        "        ... ]\n",
        "        >>> transformation = WordSwapEmbedding(max_candidates=50)\n",
        "        >>> search_method = GreedyWordSwapWIR(wir_method=\"delete\")\n",
        "\n",
        "        >>> # Construct the actual attack\n",
        "        >>> attack = Attack(goal_function, constraints, transformation, search_method)\n",
        "\n",
        "        >>> input_text = \"I really enjoyed the new movie that came out last month.\"\n",
        "        >>> label = 1 #Positive\n",
        "        >>> attack_result = attack.attack(input_text, label)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        goal_function: GoalFunction,\n",
        "        constraints: List[Union[Constraint, PreTransformationConstraint]],\n",
        "        transformation: Transformation,\n",
        "        search_method: SearchMethod,\n",
        "        transformation_cache_size=2**15,\n",
        "        constraint_cache_size=2**15,\n",
        "    ):\n",
        "        \"\"\"Initialize an attack object.\n",
        "\n",
        "        Attacks can be run multiple times.\n",
        "        \"\"\"\n",
        "        assert isinstance(\n",
        "            goal_function, GoalFunction\n",
        "        ), f\"`goal_function` must be of type `textattack.goal_functions.GoalFunction`, but got type `{type(goal_function)}`.\"\n",
        "        assert isinstance(\n",
        "            constraints, list\n",
        "        ), \"`constraints` must be a list of `textattack.constraints.Constraint` or `textattack.constraints.PreTransformationConstraint`.\"\n",
        "        for c in constraints:\n",
        "            assert isinstance(\n",
        "                c, (Constraint, PreTransformationConstraint)\n",
        "            ), \"`constraints` must be a list of `textattack.constraints.Constraint` or `textattack.constraints.PreTransformationConstraint`.\"\n",
        "        assert isinstance(\n",
        "            transformation, Transformation\n",
        "        ), f\"`transformation` must be of type `textattack.transformations.Transformation`, but got type `{type(transformation)}`.\"\n",
        "        assert isinstance(\n",
        "            search_method, SearchMethod\n",
        "        ), f\"`search_method` must be of type `textattack.search_methods.SearchMethod`, but got type `{type(search_method)}`.\"\n",
        "\n",
        "        self.goal_function = goal_function\n",
        "        self.search_method = search_method\n",
        "        self.transformation = transformation\n",
        "        self.is_black_box = (\n",
        "            getattr(transformation, \"is_black_box\", True) and search_method.is_black_box\n",
        "        )\n",
        "\n",
        "        if not self.search_method.check_transformation_compatibility(\n",
        "            self.transformation\n",
        "        ):\n",
        "            raise ValueError(\n",
        "                f\"SearchMethod {self.search_method} incompatible with transformation {self.transformation}\"\n",
        "            )\n",
        "\n",
        "        self.constraints = []\n",
        "        self.pre_transformation_constraints = []\n",
        "        for constraint in constraints:\n",
        "            if isinstance(\n",
        "                constraint,\n",
        "                textattack.constraints.PreTransformationConstraint,\n",
        "            ):\n",
        "                self.pre_transformation_constraints.append(constraint)\n",
        "            else:\n",
        "                self.constraints.append(constraint)\n",
        "\n",
        "        # Check if we can use transformation cache for our transformation.\n",
        "        if not self.transformation.deterministic:\n",
        "            self.use_transformation_cache = False\n",
        "        elif isinstance(self.transformation, CompositeTransformation):\n",
        "            self.use_transformation_cache = True\n",
        "            for t in self.transformation.transformations:\n",
        "                if not t.deterministic:\n",
        "                    self.use_transformation_cache = False\n",
        "                    break\n",
        "        else:\n",
        "            self.use_transformation_cache = True\n",
        "        self.transformation_cache_size = transformation_cache_size\n",
        "        self.transformation_cache = lru.LRU(transformation_cache_size)\n",
        "\n",
        "        self.constraint_cache_size = constraint_cache_size\n",
        "        self.constraints_cache = lru.LRU(constraint_cache_size)\n",
        "\n",
        "        # Give search method access to functions for getting transformations and evaluating them\n",
        "        self.search_method.get_transformations = self.get_transformations\n",
        "        # Give search method access to self.goal_function for model query count, etc.\n",
        "        self.search_method.goal_function = self.goal_function\n",
        "        # The search method only needs access to the first argument. The second is only used\n",
        "        # by the attack class when checking whether to skip the sample\n",
        "        self.search_method.get_goal_results = self.goal_function.get_results\n",
        "\n",
        "        self.search_method.filter_transformations = self.filter_transformations\n",
        "\n",
        "    def clear_cache(self, recursive=True):\n",
        "        self.constraints_cache.clear()\n",
        "        if self.use_transformation_cache:\n",
        "            self.transformation_cache.clear()\n",
        "        if recursive:\n",
        "            self.goal_function.clear_cache()\n",
        "            for constraint in self.constraints:\n",
        "                if hasattr(constraint, \"clear_cache\"):\n",
        "                    constraint.clear_cache()\n",
        "\n",
        "    def cpu_(self):\n",
        "        \"\"\"Move any `torch.nn.Module` models that are part of Attack to CPU.\"\"\"\n",
        "        visited = set()\n",
        "\n",
        "        def to_cpu(obj):\n",
        "            visited.add(id(obj))\n",
        "            if isinstance(obj, torch.nn.Module):\n",
        "                obj.cpu()\n",
        "            elif isinstance(\n",
        "                obj,\n",
        "                (\n",
        "                    Attack,\n",
        "                    GoalFunction,\n",
        "                    Transformation,\n",
        "                    SearchMethod,\n",
        "                    Constraint,\n",
        "                    PreTransformationConstraint,\n",
        "                    ModelWrapper,\n",
        "                ),\n",
        "            ):\n",
        "                for key in obj.__dict__:\n",
        "                    s_obj = obj.__dict__[key]\n",
        "                    if id(s_obj) not in visited:\n",
        "                        to_cpu(s_obj)\n",
        "            elif isinstance(obj, (list, tuple)):\n",
        "                for item in obj:\n",
        "                    if id(item) not in visited and isinstance(\n",
        "                        item, (Transformation, Constraint, PreTransformationConstraint)\n",
        "                    ):\n",
        "                        to_cpu(item)\n",
        "\n",
        "        to_cpu(self)\n",
        "\n",
        "    def cuda_(self):\n",
        "        \"\"\"Move any `torch.nn.Module` models that are part of Attack to GPU.\"\"\"\n",
        "        visited = set()\n",
        "\n",
        "        def to_cuda(obj):\n",
        "            visited.add(id(obj))\n",
        "            if isinstance(obj, torch.nn.Module):\n",
        "                obj.to(textattack.shared.utils.device)\n",
        "            elif isinstance(\n",
        "                obj,\n",
        "                (\n",
        "                    Attack,\n",
        "                    GoalFunction,\n",
        "                    Transformation,\n",
        "                    SearchMethod,\n",
        "                    Constraint,\n",
        "                    PreTransformationConstraint,\n",
        "                    ModelWrapper,\n",
        "                ),\n",
        "            ):\n",
        "                for key in obj.__dict__:\n",
        "                    s_obj = obj.__dict__[key]\n",
        "                    if id(s_obj) not in visited:\n",
        "                        to_cuda(s_obj)\n",
        "            elif isinstance(obj, (list, tuple)):\n",
        "                for item in obj:\n",
        "                    if id(item) not in visited and isinstance(\n",
        "                        item, (Transformation, Constraint, PreTransformationConstraint)\n",
        "                    ):\n",
        "                        to_cuda(item)\n",
        "\n",
        "        to_cuda(self)\n",
        "\n",
        "    def _get_transformations_uncached(self, current_text, original_text=None, **kwargs):\n",
        "        \"\"\"Applies ``self.transformation`` to ``text``, then filters the list\n",
        "        of possible transformations through the applicable constraints.\n",
        "\n",
        "        Args:\n",
        "            current_text: The current ``AttackedText`` on which to perform the transformations.\n",
        "            original_text: The original ``AttackedText`` from which the attack started.\n",
        "        Returns:\n",
        "            A filtered list of transformations where each transformation matches the constraints\n",
        "        \"\"\"\n",
        "        transformed_texts = self.transformation(\n",
        "            current_text,\n",
        "            pre_transformation_constraints=self.pre_transformation_constraints,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        return transformed_texts\n",
        "\n",
        "    def get_transformations(self, current_text, original_text=None, **kwargs):\n",
        "        \"\"\"Applies ``self.transformation`` to ``text``, then filters the list\n",
        "        of possible transformations through the applicable constraints.\n",
        "\n",
        "        Args:\n",
        "            current_text: The current ``AttackedText`` on which to perform the transformations.\n",
        "            original_text: The original ``AttackedText`` from which the attack started.\n",
        "        Returns:\n",
        "            A filtered list of transformations where each transformation matches the constraints\n",
        "        \"\"\"\n",
        "        if not self.transformation:\n",
        "            raise RuntimeError(\n",
        "                \"Cannot call `get_transformations` without a transformation.\"\n",
        "            )\n",
        "\n",
        "        if self.use_transformation_cache:\n",
        "            cache_key = tuple([current_text] + sorted(kwargs.items()))\n",
        "            if utils.hashable(cache_key) and cache_key in self.transformation_cache:\n",
        "                # promote transformed_text to the top of the LRU cache\n",
        "                self.transformation_cache[cache_key] = self.transformation_cache[\n",
        "                    cache_key\n",
        "                ]\n",
        "                transformed_texts = list(self.transformation_cache[cache_key])\n",
        "            else:\n",
        "                transformed_texts = self._get_transformations_uncached(\n",
        "                    current_text, original_text, **kwargs\n",
        "                )\n",
        "                if utils.hashable(cache_key):\n",
        "                    self.transformation_cache[cache_key] = tuple(transformed_texts)\n",
        "        else:\n",
        "            transformed_texts = self._get_transformations_uncached(\n",
        "                current_text, original_text, **kwargs\n",
        "            )\n",
        "\n",
        "        return self.filter_transformations(\n",
        "            transformed_texts, current_text, original_text\n",
        "        )\n",
        "\n",
        "    def _filter_transformations_uncached(\n",
        "        self, transformed_texts, current_text, original_text=None\n",
        "    ):\n",
        "        \"\"\"Filters a list of potential transformed texts based on\n",
        "        ``self.constraints``\n",
        "\n",
        "        Args:\n",
        "            transformed_texts: A list of candidate transformed ``AttackedText`` to filter.\n",
        "            current_text: The current ``AttackedText`` on which the transformation was applied.\n",
        "            original_text: The original ``AttackedText`` from which the attack started.\n",
        "        \"\"\"\n",
        "        filtered_texts = transformed_texts[:]\n",
        "        for C in self.constraints:\n",
        "            if len(filtered_texts) == 0:\n",
        "                break\n",
        "            if C.compare_against_original:\n",
        "                if not original_text:\n",
        "                    raise ValueError(\n",
        "                        f\"Missing `original_text` argument when constraint {type(C)} is set to compare against `original_text`\"\n",
        "                    )\n",
        "\n",
        "                filtered_texts = C.call_many(filtered_texts, original_text)\n",
        "            else:\n",
        "                filtered_texts = C.call_many(filtered_texts, current_text)\n",
        "        # Default to false for all original transformations.\n",
        "        for original_transformed_text in transformed_texts:\n",
        "            self.constraints_cache[(current_text, original_transformed_text)] = False\n",
        "        # Set unfiltered transformations to True in the cache.\n",
        "        for filtered_text in filtered_texts:\n",
        "            self.constraints_cache[(current_text, filtered_text)] = True\n",
        "        return filtered_texts\n",
        "\n",
        "    def filter_transformations(\n",
        "        self, transformed_texts, current_text, original_text=None\n",
        "    ):\n",
        "        \"\"\"Filters a list of potential transformed texts based on\n",
        "        ``self.constraints`` Utilizes an LRU cache to attempt to avoid\n",
        "        recomputing common transformations.\n",
        "\n",
        "        Args:\n",
        "            transformed_texts: A list of candidate transformed ``AttackedText`` to filter.\n",
        "            current_text: The current ``AttackedText`` on which the transformation was applied.\n",
        "            original_text: The original ``AttackedText`` from which the attack started.\n",
        "        \"\"\"\n",
        "        # Remove any occurences of current_text in transformed_texts\n",
        "        transformed_texts = [\n",
        "            t for t in transformed_texts if t.text != current_text.text\n",
        "        ]\n",
        "        # Populate cache with transformed_texts\n",
        "        uncached_texts = []\n",
        "        filtered_texts = []\n",
        "        for transformed_text in transformed_texts:\n",
        "            if (current_text, transformed_text) not in self.constraints_cache:\n",
        "                uncached_texts.append(transformed_text)\n",
        "            else:\n",
        "                # promote transformed_text to the top of the LRU cache\n",
        "                self.constraints_cache[\n",
        "                    (current_text, transformed_text)\n",
        "                ] = self.constraints_cache[(current_text, transformed_text)]\n",
        "                if self.constraints_cache[(current_text, transformed_text)]:\n",
        "                    filtered_texts.append(transformed_text)\n",
        "        filtered_texts += self._filter_transformations_uncached(\n",
        "            uncached_texts, current_text, original_text=original_text\n",
        "        )\n",
        "        # Sort transformations to ensure order is preserved between runs\n",
        "        filtered_texts.sort(key=lambda t: t.text)\n",
        "        return filtered_texts\n",
        "\n",
        "    def _attack(self, initial_result):\n",
        "        \"\"\"Calls the ``SearchMethod`` to perturb the ``AttackedText`` stored in\n",
        "        ``initial_result``.\n",
        "\n",
        "        Args:\n",
        "            initial_result: The initial ``GoalFunctionResult`` from which to perturb.\n",
        "\n",
        "        Returns:\n",
        "            A ``SuccessfulAttackResult``, ``FailedAttackResult``,\n",
        "                or ``MaximizedAttackResult``.\n",
        "        \"\"\"\n",
        "        final_result = self.search_method(initial_result)\n",
        "        self.clear_cache()\n",
        "        if final_result.goal_status == GoalFunctionResultStatus.SUCCEEDED:\n",
        "            result = SuccessfulAttackResult(\n",
        "                initial_result,\n",
        "                final_result,\n",
        "            )\n",
        "            print(initial_result, final_result)\n",
        "        elif final_result.goal_status == GoalFunctionResultStatus.SEARCHING:\n",
        "            result = FailedAttackResult(\n",
        "                initial_result,\n",
        "                final_result,\n",
        "            )\n",
        "        elif final_result.goal_status == GoalFunctionResultStatus.MAXIMIZING:\n",
        "            result = MaximizedAttackResult(\n",
        "                initial_result,\n",
        "                final_result,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unrecognized goal status {final_result.goal_status}\")\n",
        "        return result\n",
        "\n",
        "    def attack(self, example, ground_truth_output):\n",
        "        \"\"\"Attack a single example.\n",
        "\n",
        "        Args:\n",
        "            example (:obj:`str`, :obj:`OrderedDict[str, str]` or :class:`~textattack.shared.AttackedText`):\n",
        "                Example to attack. It can be a single string or an `OrderedDict` where\n",
        "                keys represent the input fields (e.g. \"premise\", \"hypothesis\") and the values are the actual input textx.\n",
        "                Also accepts :class:`~textattack.shared.AttackedText` that wraps around the input.\n",
        "            ground_truth_output(:obj:`int`, :obj:`float` or :obj:`str`):\n",
        "                Ground truth output of `example`.\n",
        "                For classification tasks, it should be an integer representing the ground truth label.\n",
        "                For regression tasks (e.g. STS), it should be the target value.\n",
        "                For seq2seq tasks (e.g. translation), it should be the target string.\n",
        "        Returns:\n",
        "            :class:`~textattack.attack_results.AttackResult` that represents the result of the attack.\n",
        "        \"\"\"\n",
        "        assert isinstance(\n",
        "            example, (str, OrderedDict, AttackedText)\n",
        "        ), \"`example` must either be `str`, `collections.OrderedDict`, `textattack.shared.AttackedText`.\"\n",
        "        if isinstance(example, (str, OrderedDict)):\n",
        "            example = AttackedText(example)\n",
        "\n",
        "        assert isinstance(\n",
        "            ground_truth_output, (int, str, float)\n",
        "        ), \"`ground_truth_output` must either be `str` or `int`.\"\n",
        "        goal_function_result, _ = self.goal_function.init_attack_example(\n",
        "            example, ground_truth_output\n",
        "        )\n",
        "        if goal_function_result.goal_status == GoalFunctionResultStatus.SKIPPED:\n",
        "            return SkippedAttackResult(goal_function_result)\n",
        "        else:\n",
        "            result = self._attack(goal_function_result)\n",
        "            return result\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Prints attack parameters in a human-readable string.\n",
        "\n",
        "        Inspired by the readability of printing PyTorch nn.Modules:\n",
        "        https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py\n",
        "        \"\"\"\n",
        "        main_str = \"Attack\" + \"(\"\n",
        "        lines = []\n",
        "\n",
        "        lines.append(utils.add_indent(f\"(search_method): {self.search_method}\", 2))\n",
        "        # self.goal_function\n",
        "        lines.append(utils.add_indent(f\"(goal_function):  {self.goal_function}\", 2))\n",
        "        # self.transformation\n",
        "        lines.append(utils.add_indent(f\"(transformation):  {self.transformation}\", 2))\n",
        "        # self.constraints\n",
        "        constraints_lines = []\n",
        "        constraints = self.constraints + self.pre_transformation_constraints\n",
        "        if len(constraints):\n",
        "            for i, constraint in enumerate(constraints):\n",
        "                constraints_lines.append(utils.add_indent(f\"({i}): {constraint}\", 2))\n",
        "            constraints_str = utils.add_indent(\"\\n\" + \"\\n\".join(constraints_lines), 2)\n",
        "        else:\n",
        "            constraints_str = \"None\"\n",
        "        lines.append(utils.add_indent(f\"(constraints): {constraints_str}\", 2))\n",
        "        # self.is_black_box\n",
        "        lines.append(utils.add_indent(f\"(is_black_box):  {self.is_black_box}\", 2))\n",
        "        main_str += \"\\n  \" + \"\\n  \".join(lines) + \"\\n\"\n",
        "        main_str += \")\"\n",
        "        return main_str\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"transformation_cache\"] = None\n",
        "        state[\"constraints_cache\"] = None\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        self.__dict__ = state\n",
        "        self.transformation_cache = lru.LRU(self.transformation_cache_size)\n",
        "        self.constraints_cache = lru.LRU(self.constraint_cache_size)\n",
        "\n",
        "    __str__ = __repr__\n"
      ],
      "metadata": {
        "id": "ZAseGNvF14hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recipe"
      ],
      "metadata": {
        "id": "n5DmUwm50A8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r__IuamhTSF1",
        "outputId": "7c46afd7-93b0-408f-ceaf-9104e66e66f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HuggingFaceWrapper(PyTorchModelWrapper):\n",
        "    \"\"\"Loads a HuggingFace ``transformers`` model and tokenizer.\"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer):\n",
        "        # assert isinstance(\n",
        "        #     model, transformers.PreTrainedModel\n",
        "        # ), f\"`model` must be of type `transformers.PreTrainedModel`, but got type {type(model)}.\"\n",
        "        # assert isinstance(\n",
        "        #     tokenizer,\n",
        "        #     (transformers.PreTrainedTokenizer, transformers.PreTrainedTokenizerFast),\n",
        "        # ), f\"`tokenizer` must of type `transformers.PreTrainedTokenizer` or `transformers.PreTrainedTokenizerFast`, but got type {type(tokenizer)}.\"\n",
        "\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, text_input_list):\n",
        "        \"\"\"Passes inputs to HuggingFace models as keyword arguments.\n",
        "\n",
        "        (Regular PyTorch ``nn.Module`` models typically take inputs as\n",
        "        positional arguments.)\n",
        "        \"\"\"\n",
        "        # Default max length is set to be int(1e30), so we force 512 to enable batching.\n",
        "        max_length = (\n",
        "            512\n",
        "            if self.tokenizer.model_max_length == int(1e30)\n",
        "            else self.tokenizer.model_max_length\n",
        "        )\n",
        "        inputs_dict = self.tokenizer(\n",
        "            text_input_list,\n",
        "            add_special_tokens=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        \n",
        "        model_device = next(self.model.parameters()).device\n",
        "        inputs_dict.to(model_device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            outputs = self.model(**inputs_dict)\n",
        "\n",
        "        if isinstance(outputs[0], str):\n",
        "            # HuggingFace sequence-to-sequence models return a list of\n",
        "            # string predictions as output. In this case, return the full\n",
        "            # list of outputs.\n",
        "            return outputs\n",
        "        else:\n",
        "            # HuggingFace classification models return a tuple as output\n",
        "            # where the first item in the tuple corresponds to the list of\n",
        "            # scores for each input.\n",
        "            # print(outputs[0])\n",
        "            return outputs[0]\n",
        "\n",
        "    def get_grad(self, text_input):\n",
        "        \"\"\"Get gradient of loss with respect to input tokens.\n",
        "\n",
        "        Args:\n",
        "            text_input (str): input string\n",
        "        Returns:\n",
        "            Dict of ids, tokens, and gradient as numpy array.\n",
        "        \"\"\"\n",
        "        if isinstance(self.model, textattack.models.helpers.T5ForTextToText):\n",
        "            raise NotImplementedError(\n",
        "                \"`get_grads` for T5FotTextToText has not been implemented yet.\"\n",
        "            )\n",
        "\n",
        "        self.model.train()\n",
        "        embedding_layer = self.model.get_input_embeddings()\n",
        "        original_state = embedding_layer.weight.requires_grad\n",
        "        embedding_layer.weight.requires_grad = True\n",
        "\n",
        "        emb_grads = []\n",
        "\n",
        "        def grad_hook(module, grad_in, grad_out):\n",
        "            emb_grads.append(grad_out[0])\n",
        "\n",
        "        emb_hook = embedding_layer.register_backward_hook(grad_hook)\n",
        "\n",
        "        self.model.zero_grad()\n",
        "        model_device = next(self.model.parameters()).device\n",
        "        input_dict = self.tokenizer(\n",
        "            [text_input],\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "        )\n",
        "        input_dict.to(model_device)\n",
        "        predictions = self.model(**input_dict).logits\n",
        "\n",
        "        try:\n",
        "            labels = predictions.argmax(dim=1)\n",
        "            loss = self.model(**input_dict, labels=labels.float())[0]\n",
        "        except TypeError:\n",
        "            raise TypeError(\n",
        "                f\"{type(self.model)} class does not take in `labels` to calculate loss. \"\n",
        "                \"One cause for this might be if you instantiatedyour model using `transformer.AutoModel` \"\n",
        "                \"(instead of `transformers.AutoModelForSequenceClassification`).\"\n",
        "            )\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # grad w.r.t to word embeddings\n",
        "        grad = emb_grads[0][0].cpu().numpy()\n",
        "\n",
        "        embedding_layer.weight.requires_grad = original_state\n",
        "        emb_hook.remove()\n",
        "        self.model.eval()\n",
        "\n",
        "        output = {\"ids\": input_dict[\"input_ids\"], \"gradient\": grad}\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def _tokenize(self, inputs):\n",
        "        \"\"\"Helper method that for `tokenize`\n",
        "        Args:\n",
        "            inputs (list[str]): list of input strings\n",
        "        Returns:\n",
        "            tokens (list[list[str]]): List of list of tokens as strings\n",
        "        \"\"\"\n",
        "        return [\n",
        "            self.tokenizer.convert_ids_to_tokens(\n",
        "                self.tokenizer([x], truncation=True)[\"input_ids\"][0]\n",
        "            )\n",
        "            for x in inputs\n",
        "        ]\n"
      ],
      "metadata": {
        "id": "VSPJyRYdHdF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_attack(model_wrapper, attack_name='A2T'):\n",
        "    \n",
        "    if attack_name == 'BAE'  :\n",
        "        transformation = WordSwapMaskedLM(method=\"bae\", max_candidates=50, min_confidence=0.0)\n",
        "\n",
        "        constraints = [RepeatModification(), StopwordModification()]\n",
        "\n",
        "        constraints.append(PartOfSpeech(allow_verb_noun_swap=True))\n",
        "        use_constraint = UniversalSentenceEncoder(\n",
        "            threshold=0.4,\n",
        "            metric=\"cosine\",\n",
        "            compare_against_original=True,\n",
        "            window_size=15,\n",
        "            skip_text_shorter_than_window=True,\n",
        "        )\n",
        "        constraints.append(use_constraint)\n",
        "        goal_function = TargetedRegression(model_wrapper)\n",
        "\n",
        "        search_method = GreedyWordSwapWIR(wir_method=\"delete\")\n",
        "        print('BAE attack is running.....')\n",
        "        return Attack(goal_function, constraints, transformation, search_method)\n",
        "            \n",
        "    elif attack_name == 'A2T' :\n",
        "        constraints = [RepeatModification(), StopwordModification()]\n",
        "        input_column_modification = InputColumnModification(\n",
        "            [\"premise\", \"hypothesis\"], {\"premise\"}\n",
        "        )\n",
        "        constraints.append(input_column_modification)\n",
        "        constraints.append(PartOfSpeech(allow_verb_noun_swap=False))\n",
        "        constraints.append(MaxModificationRate(max_rate=0.1, min_threshold=4))\n",
        "        sent_encoder = BERT(\n",
        "            model_name=\"stsb-distilbert-base\", threshold=0.60, metric=\"cosine\"\n",
        "        )\n",
        "        constraints.append(sent_encoder)\n",
        "\n",
        "        transformation = transformation = WordSwapMaskedLM(\n",
        "            method=\"bae\", max_candidates=20, min_confidence=0.0, batch_size=32\n",
        "        )\n",
        "\n",
        "        goal_function = TargetedRegression(model_wrapper, model_batch_size=32)\n",
        "\n",
        "        search_method = GreedyWordSwapWIR(wir_method=\"gradient\")\n",
        "        print('A2T attack is running.....')\n",
        "        return Attack(goal_function, constraints, transformation, search_method)\n",
        "\n",
        "    elif attack_name == 'Text-Fooler':\n",
        "        transformation = WordSwapEmbedding(max_candidates=50)\n",
        "\n",
        "        stopwords = set(\n",
        "            [\"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"ain\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"am\", \"among\", \"amongst\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"aren\", \"aren't\", \"around\", \"as\", \"at\", \"back\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"both\", \"but\", \"by\", \"can\", \"cannot\", \"could\", \"couldn\", \"couldn't\", \"d\", \"didn\", \"didn't\", \"doesn\", \"doesn't\", \"don\", \"don't\", \"down\", \"due\", \"during\", \"either\", \"else\", \"elsewhere\", \"empty\", \"enough\", \"even\", \"ever\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"first\", \"for\", \"former\", \"formerly\", \"from\", \"hadn\", \"hadn't\", \"hasn\", \"hasn't\", \"haven\", \"haven't\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"i\", \"if\", \"in\", \"indeed\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"just\", \"latter\", \"latterly\", \"least\", \"ll\", \"may\", \"me\", \"meanwhile\", \"mightn\", \"mightn't\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"must\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"namely\", \"needn\", \"needn't\", \"neither\", \"never\", \"nevertheless\", \"next\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"o\", \"of\", \"off\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"per\", \"please\", \"s\", \"same\", \"shan\", \"shan't\", \"she\", \"she's\", \"should've\", \"shouldn\", \"shouldn't\", \"somehow\", \"something\", \"sometime\", \"somewhere\", \"such\", \"t\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"this\", \"those\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"too\", \"toward\", \"towards\", \"under\", \"unless\", \"until\", \"up\", \"upon\", \"used\", \"ve\", \"was\", \"wasn\", \"wasn't\", \"we\", \"were\", \"weren\", \"weren't\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"with\", \"within\", \"without\", \"won\", \"won't\", \"would\", \"wouldn\", \"wouldn't\", \"y\", \"yet\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]\n",
        "        )\n",
        "\n",
        "        constraints = [RepeatModification(), StopwordModification(stopwords=stopwords)]\n",
        "\n",
        "        input_column_modification = InputColumnModification(\n",
        "            [\"premise\", \"hypothesis\"], {\"premise\"}\n",
        "        )\n",
        "        constraints.append(input_column_modification)\n",
        "        constraints.append(WordEmbeddingDistance(min_cos_sim=0.2))\n",
        "        constraints.append(PartOfSpeech(allow_verb_noun_swap=True))\n",
        "\n",
        "        use_constraint = UniversalSentenceEncoder(\n",
        "            threshold=0.40,\n",
        "            metric=\"angular\",\n",
        "            compare_against_original=False,\n",
        "            window_size=15,\n",
        "            skip_text_shorter_than_window=True,\n",
        "        )\n",
        "        constraints.append(use_constraint)\n",
        "\n",
        "        goal_function = TargetedRegression(model_wrapper)\n",
        "\n",
        "        search_method = GreedyWordSwapWIR(wir_method=\"delete\")\n",
        "        print('Text-Fooler attack is running.....')\n",
        "        return Attack(goal_function, constraints, transformation, search_method)\n",
        "\n",
        "    elif attack_name == 'CLARE':\n",
        "        shared_masked_lm = transformers.AutoModelForCausalLM.from_pretrained(\"distilroberta-base\")\n",
        "        shared_tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
        "        transformation = CompositeTransformation(\n",
        "            [\n",
        "                WordSwapMaskedLM(\n",
        "                    method=\"bae\",\n",
        "                    masked_language_model=shared_masked_lm,\n",
        "                    tokenizer=shared_tokenizer,\n",
        "                    max_candidates=50,\n",
        "                    min_confidence=5e-4,\n",
        "                ),\n",
        "                WordInsertionMaskedLM(\n",
        "                    masked_language_model=shared_masked_lm,\n",
        "                    tokenizer=shared_tokenizer,\n",
        "                    max_candidates=50,\n",
        "                    min_confidence=0.0,\n",
        "                ),\n",
        "                WordMergeMaskedLM(\n",
        "                    masked_language_model=shared_masked_lm,\n",
        "                    tokenizer=shared_tokenizer,\n",
        "                    max_candidates=50,\n",
        "                    min_confidence=5e-3,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        constraints = [RepeatModification(), StopwordModification()]\n",
        "\n",
        "        use_constraint = UniversalSentenceEncoder(\n",
        "            threshold=0.7,\n",
        "            metric=\"cosine\",\n",
        "            compare_against_original=True,\n",
        "            window_size=15,\n",
        "            skip_text_shorter_than_window=True,\n",
        "        )\n",
        "        constraints.append(use_constraint)\n",
        "\n",
        "        goal_function = TargetedRegression(model_wrapper)\n",
        "\n",
        "        search_method = GreedySearch()\n",
        "        print('CLARE attack is running.....')\n",
        "        return Attack(goal_function, constraints, transformation, search_method)\n",
        "\n",
        "    elif attack_name == \"Bert-attack\":\n",
        "        transformation = WordSwapMaskedLM(method=\"bert-attack\", max_candidates=48)\n",
        "        \n",
        "        constraints = [RepeatModification(), StopwordModification()]\n",
        "        constraints.append(MaxWordsPerturbed(max_percent=0.4))\n",
        "        use_constraint = UniversalSentenceEncoder(\n",
        "            threshold=0.2,\n",
        "            metric=\"cosine\",\n",
        "            compare_against_original=True,\n",
        "            window_size=None,\n",
        "        )\n",
        "        constraints.append(use_constraint)\n",
        "        \n",
        "        goal_function = TargetedRegression(model_wrapper)\n",
        "        \n",
        "        search_method = GreedyWordSwapWIR(wir_method=\"unk\")\n",
        "        print('Bert-attack attack is running.....')\n",
        "        return Attack(goal_function, constraints, transformation, search_method)\n",
        "    \n",
        "    elif attack_name == \"A2T-Hybrid\":\n",
        "        constraints = [RepeatModification(), StopwordModification()]\n",
        "        input_column_modification = InputColumnModification(\n",
        "            [\"premise\", \"hypothesis\"], {\"premise\"}\n",
        "        )\n",
        "        constraints.append(input_column_modification)\n",
        "        constraints.append(PartOfSpeech(allow_verb_noun_swap=False))\n",
        "        constraints.append(MaxModificationRate(max_rate=0.1, min_threshold=4))\n",
        "        sent_encoder = UniversalSentenceEncoder(\n",
        "            threshold=0.4,\n",
        "            metric=\"cosine\",\n",
        "            compare_against_original=True,\n",
        "            window_size=20,\n",
        "            skip_text_shorter_than_window=True,\n",
        "        )\n",
        "        constraints.append(sent_encoder)\n",
        "        shared_masked_lm = transformers.AutoModelForCausalLM.from_pretrained(\"distilroberta-base\")\n",
        "        shared_tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
        "\n",
        "        transformation = WordSwapMaskedLM(\n",
        "                    method=\"bae\",\n",
        "                    masked_language_model=shared_masked_lm,\n",
        "                    tokenizer=shared_tokenizer,\n",
        "                    max_candidates=20,\n",
        "                    min_confidence=5e-4,\n",
        "                )\n",
        "\n",
        "        goal_function = TargetedRegression(model_wrapper, model_batch_size=32)\n",
        "\n",
        "        search_method = GreedyWordSwapWIR(wir_method=\"gradient\")\n",
        "        print('A2T-Hybrid1 attack is running.....')\n",
        "        return Attack(goal_function, constraints, transformation, search_method)\n",
        "\n",
        "    elif attack_name == \"A2T-Hybrid_v1\":\n",
        "        constraints = [RepeatModification(), StopwordModification()]\n",
        "        input_column_modification = InputColumnModification(\n",
        "            [\"premise\", \"hypothesis\"], {\"premise\"}\n",
        "        )\n",
        "        constraints.append(input_column_modification)\n",
        "        constraints.append(PartOfSpeech(allow_verb_noun_swap=False))\n",
        "        constraints.append(MaxModificationRate(max_rate=0.15, min_threshold=4))\n",
        "        sent_encoder = UniversalSentenceEncoder(\n",
        "            threshold=0.5,\n",
        "            metric=\"cosine\",\n",
        "            compare_against_original=True,\n",
        "            window_size=15,\n",
        "            skip_text_shorter_than_window=True,\n",
        "        )\n",
        "        constraints.append(sent_encoder)\n",
        "        shared_masked_lm = transformers.AutoModelForCausalLM.from_pretrained(\"distilroberta-base\")\n",
        "        shared_tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
        "\n",
        "        transformation = WordSwapMaskedLM(\n",
        "                    method=\"bae\",\n",
        "                    masked_language_model=shared_masked_lm,\n",
        "                    tokenizer=shared_tokenizer,\n",
        "                    max_candidates=20,\n",
        "                    min_confidence=5e-4,\n",
        "                )\n",
        "\n",
        "        goal_function = TargetedRegression(model_wrapper, model_batch_size=32)\n",
        "\n",
        "        search_method = GreedyWordSwapWIR(wir_method=\"unk\")\n",
        "        print('A2T-Hybrid_v1 attack is running.....')\n",
        "        return Attack(goal_function, constraints, transformation, search_method)\n",
        "\n",
        "    elif attack_name == \"A2T-Hybrid_v2\":\n",
        "        constraints = [RepeatModification(), StopwordModification()]\n",
        "        input_column_modification = InputColumnModification(\n",
        "            [\"premise\", \"hypothesis\"], {\"premise\"}\n",
        "        )\n",
        "        constraints.append(input_column_modification)\n",
        "        constraints.append(PartOfSpeech(allow_verb_noun_swap=False))\n",
        "        constraints.append(MaxModificationRate(max_rate=0.1, min_threshold=4))\n",
        "        sent_encoder = BERT(\n",
        "            model_name=\"stsb-distilbert-base\", threshold=0.40, metric=\"cosine\"\n",
        "        )\n",
        "        constraints.append(sent_encoder)\n",
        "        shared_masked_lm = transformers.AutoModelForCausalLM.from_pretrained(\"distilroberta-base\")\n",
        "        shared_tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
        "        transformation = WordSwapMaskedLM(\n",
        "                    method=\"bae\",\n",
        "                    masked_language_model=shared_masked_lm,\n",
        "                    tokenizer=shared_tokenizer,\n",
        "                    max_candidates=20,\n",
        "                    min_confidence=5e-4,\n",
        "                )\n",
        "        goal_function = TargetedRegression(model_wrapper, model_batch_size=32)\n",
        "        search_method = GreedyWordSwapWIR(wir_method=\"gradient\")\n",
        "        print('A2T-Hybrid2 attack is running.....')\n",
        "        return Attack(goal_function, constraints, transformation, search_method)\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Only, 'BAE', 'A2T','Bert-attack', 'CLARE' and 'Text-Fooler' attack is implemented here. The name is case sensitive :)\")"
      ],
      "metadata": {
        "id": "Wd-7e3oJDZWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "yaxzK1pj29XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_wrapper = HuggingFaceWrapper(model, tokenizer)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
        "model_wrapper.to(device)\n",
        "\n",
        "attack = create_attack(model_wrapper, attack_name='A2T')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F68JC31MDftM",
        "outputId": "f1a032be-474d-4278-f0fd-99db6a5534df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"old_models/stsb-distilbert-base/0_Transformer\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertModel.\n",
            "\n",
            "All the weights of DistilBertModel were initialized from the model checkpoint at /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n",
            "loading configuration file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"old_models/stsb-distilbert-base/0_Transformer\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Didn't find file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/added_tokens.json. We won't load it.\n",
            "loading file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/vocab.txt\n",
            "loading file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/tokenizer.json\n",
            "loading file None\n",
            "loading file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/special_tokens_map.json\n",
            "loading file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/tokenizer_config.json\n",
            "loading configuration file /root/.cache/torch/sentence_transformers/sentence-transformers_stsb-distilbert-base/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"old_models/stsb-distilbert-base/0_Transformer\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "textattack: No entry found for goal function <class '__main__.TargetedRegression'>.\n",
            "textattack: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class '__main__.TargetedRegression'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2T attack is running.....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = attack.attack(response, score)\n",
        "print(score)\n",
        "print(result.__str__(color_method='ansi'))\n",
        "# print(model_wrapper(response))\n",
        "# model_wrapper(result.perturbed_text())"
      ],
      "metadata": {
        "id": "aDRhiO_1IfP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'You are helping an event planner with an important event that involves coordinating several teams working together to setup the hired equipment, deliver the event, and tidy up afterwards. To ensure the event runs smoothly, you have been asked to prepare for anything that could go wrong. What types of problems, both internal and external to your team, could come up that would affect how well the event goes? List as many specific factors as you can'\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "-DvWaPLvX3o2",
        "outputId": "c30595d1-a9dc-40d5-932a-16eca3dd50ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are helping an event planner with an important event that involves coordinating several teams working together to setup the hired equipment, deliver the event, and tidy up afterwards. To ensure the event runs smoothly, you have been asked to prepare for anything that could go wrong. What types of problems, both internal and external to your team, could come up that would affect how well the event goes? List as many specific factors as you can'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_df = pd.DataFrame()\n",
        "df = test_set[['transcript', 'content_rating']][test_set[ 'content_rating']<3]\n",
        "for idx, row in tqdm(df.iterrows()):\n",
        "    result = attack.attack(row['transcript'], row['content_rating'])\n",
        "    attack_df = attack_df.append({'transcript': row['transcript']\n",
        "                                  , 'content_rating':row['content_rating']\n",
        "                                  , 'Adversarial':result.perturbed_text()\n",
        "                                  , 'dump' : result.str_lines()[0]}, ignore_index=True)\n",
        "    result.original_text(), result.perturbed_text()\n",
        "    print(row['content_rating'])\n",
        "    print(result.__str__(color_method='ansi'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0NlIa41VYGq",
        "outputId": "67a0c2ec-eca8-4abd-8c48-fd324b5e0ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "1it [00:11, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57fe6a8450> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec4df1d0>\n",
            "1.0\n",
            "\u001b[91m0 (103%)\u001b[0m --> \u001b[91m0 (251%)\u001b[0m\n",
            "\n",
            "We \u001b[91mneed\u001b[0m to \u001b[91mfocus\u001b[0m \u001b[91mfirstly\u001b[0m on delegating \u001b[91mtasks\u001b[0m and \u001b[91mpriorities\u001b[0m. We \u001b[91mneed\u001b[0m someone to focus on. Does the \u001b[91mequipment\u001b[0m arrive? Is the hall empty? Are people arriving early? And where do we stage them? If our room is not available? \u001b[91mSecondly\u001b[0m, we need to plan for. People's \u001b[91mproblems\u001b[0m if there's a situation or an escalation, how do we remove a person from the situation? How do we deescalate the \u001b[91msituation\u001b[0m? We \u001b[91mneed\u001b[0m to work with the \u001b[91mmanagement\u001b[0m of the \u001b[91mvenue\u001b[0m to \u001b[91mfind\u001b[0m out \u001b[91mexactly\u001b[0m what they \u001b[91moffer\u001b[0m and if there is any restrictions or unavailable items. How do we prepare for that? Or how do we handle that if, say, their room is not available after the last party? What do we do? Who do we talk to? We need to have those resources on hand. The other thing we need to prioritize is the specific expectations and requests of the facilitators. What is it you really need for us? What is the number one focus on what we need? Who do we follow up with afterward? Both for \u001b[91mbilling\u001b[0m and \u001b[91msatisfaction\u001b[0m, we need to have a \u001b[91mbackup\u001b[0m vendor if something doesn't come through. \n",
            "\n",
            "We \u001b[91mseem\u001b[0m to \u001b[91mdepend\u001b[0m \u001b[91mmainly\u001b[0m on delegating \u001b[91mproblems\u001b[0m and \u001b[91mquestions\u001b[0m. We \u001b[91mlose\u001b[0m someone to focus on. Does the \u001b[91mmusic\u001b[0m arrive? Is the hall empty? Are people arriving early? And where do we stage them? If our room is not available? \u001b[91mobviously\u001b[0m, we need to plan for. People's \u001b[91mdilemma\u001b[0m if there's a situation or an escalation, how do we remove a person from the situation? How do we deescalate the \u001b[91mbudget\u001b[0m? We \u001b[91mtend\u001b[0m to work with the \u001b[91mproducers\u001b[0m of the \u001b[91mseason\u001b[0m to \u001b[91mcarry\u001b[0m out \u001b[91monly\u001b[0m what they \u001b[91mcan\u001b[0m and if there is any restrictions or unavailable items. How do we prepare for that? Or how do we handle that if, say, their room is not available after the last party? What do we do? Who do we talk to? We need to have those resources on hand. The other thing we need to prioritize is the specific expectations and requests of the facilitators. What is it you really need for us? What is the number one focus on what we need? Who do we follow up with afterward? Both for \u001b[91mexcitement\u001b[0m and \u001b[91mfear\u001b[0m, we need to have a \u001b[91mticket\u001b[0m vendor if something doesn't come through. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:20, 10.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (99%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "If I were coordinating an event that was very complex, involves many team members, I would prepare in many different ways to make sure everything ran smoothly. I would have extras of every material thing I would need, so depending on what the event is, but let's say it's a banquet, extra linens, extra candles, extra drinks, I would have a team meeting at the beginning of the event at the beginning of call time for the event I would speak to each team member individually. Make sure that they're on board and that they feel a part of the mission. That would make sure to check in throughout the entire shift. That everyone's doing what they should be doing, but also that they feel appreciated and that we care about them being here. I would prepare by. Assuring that everything that needs to be there will be there if it's food. If it's a guest list, it depends, but I would just make sure many times. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:27,  8.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (191%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Some of the problems that you could encounter here are, for example, if a member of staff didn't turn up. How we would deal with that? So having standby staff available or where management helped out more? When they probably wouldn't have done something, so just working as a team and we could have something like something going on with any kind of food. So just having those backup plans just in case something goes wrong. Which is making sure that yes OK, for all eventualities, that we do have a plan in place should something go wrong, so having. A potential backup supplier or a member of staff that would potentially wouldn't need just making sure that actually maybe we're having more stuff than not too many staff. So there's there's a lot of different factors. Involve. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:35,  8.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (208%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "One of the main things that could go wrong is if you don't have enough staff to help set up. So you need to always make sure to hire more staff than you need. This is something you do not want to cut corners with at all at all. You need to have enough staff. Also, inclement weather you need to be checking the weather reports, and if there's even a chance of rain or things like that, you need to be prepared for bad weather. You need to double check with the delivery teams you got to make sure they are paid beforehand or have deposits. You need to make sure all of that because you need your stuff delivered and you have to double check that you have enough people to help you break down the setup afterwards. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:56, 12.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (188%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "I think this is a recording. Yeah, OK, so I think it's important for us to point out that if I was preparing for this, I would want to be asking the internal teams exactly who they see it going wrong because that's how I identified the broadest range of problems will need to prepare to, but under the assumption that I need to answer this question now, the things need to think of first. That is, you need to liaise with the higher equipment people make the be available. Make sure it's not available. What can be done about it? Possibly even set the contingency higher so it wasn't available? You could speak to this person. Delivering the event could be simple. Depends on the resources you've got in place. Obviously the event could not offer planned people not be able to attend. There could be technical issues, for example, the venue could have something wrong with it, and these are all things you need to meet to get again with continues, and you're probably identify those by speaking to the externals again. Tighten up that is one that is less problematic insofar as it is less likely to affect. The delivery of events happened. They could lead to unforeseen costs. This was the whole thing. Could have an unseen costs in it that could lead to some sort of penalty. Perhaps a fairly venue in a suitable position. So what you have to do is you have to admit to get that have a plan in place. What the contingency is basically and you identify them by speaking to the teams you've got on the plan. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [01:03, 11.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (187%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So in a situation like this, the most obvious thing that could potentially go wrong would be that the hired equipment does not work. So to put a plan of action in place for this is I would make sure that I use the equipment the night before to make sure that all eventualities are. Set up for and if possible and within budget that we have replacement equipment that we could use. I can imagine that things like weather and the amount of people that turn up for this event would be an issue. We need to take into consideration. And I think it's just a case of having all these things. Put down so that we have a backup plan.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [01:19, 12.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (196%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So in terms of what can go wrong? In planning an event. Firstly, on an internal basis. sickness has to be accounted for. Particularly at COVID at the moment could people get COVID and are they going to be off for? Two weeks or even longer. So you need to ensure there's enough cover and and plan for that and be. Very organized and have a solid plan of action in order to mitigate that. Also. On a more external basis.  I'm sure we will be relying on various different companies that to provide. Feared all sorts of different things, so. I think maintaining those relationships and keeping in contact and make sure that they're up to date and we know where everything's at with those companies to ensure that everyone pulls their way and and the products that we need from them are going to be received. So I think maintaining relationships there is a key aspect.  In terms of what else could go wrong and how we could plan. I think having a strategy on. The people that are going to come to the event so invitations have gone out. People of our SVP had all these sort of things should be on top of well in advance of the event, so that on the actual day. It should run smoothly and it's all very organized and. It's the success in the end. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [01:29, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (205%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "When planning for an event, you have to look at. Things that can go wrong. Some examples would be. Food not delivered on time then. Let's say depending on your guest demographic, there could be kids running around knocking things down. You could even have problematic. Adults trying to disrupt the event. Then any any props that you have for the event you have to make sure they're well secured. I'm not a safety hazard. And then you have to make sure that. In the event of a fire or a. Something like that you have the evacuation plan set up straight so that. You're well prepared, you know to avoid any. Injuries. Do your guests or to yourself or anybody as part of the event. Then it's always best to have. Doctor. Product that even in the case. Of an emergency. Other things that could go wrong. You know quality issues with food. Drinks and depending on the event. You know what kind of food is served and things like that, so yeah, this is just a few examples. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [01:32,  8.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (199%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Things affecting something going wrong with an event planner. The people couldn't show up the catering. People wouldn't show up so you would need a backup. The bride might be late or the cake might not show up. Or perhaps the cake might fall over and get destroyed and then you would have to create another. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [01:44, 10.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (201%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Can I believe I am I'm gonna be organising a wedding helping to organise a wedding and things that could go wrong or the actual like the catering might go wrong. We might not have organised enough food for the amount of people that are going to come. We need to allow for people that actually turn up extra, so hopefully there's some extra food and all to organize things like the DJ or the OR disco. Whatever is the having or the music entertainment. Need to make sure that turns up if it doesn't have. Got contingency in place in case of that happening. Also if the event is actually double booked we need to try and think of something else that's someone else we can use. We need to organise and making sure that everything is there at all decorated. The people that own charge of that turn up that when it's all done that we've all got a special source of. We've got like a timetable in place for how we're going to clean things up. We need to have timetable for everything really. Or time the food's going to get served and how we're going to do it all. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [01:51,  8.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec33f7d0> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57fe3069d0>\n",
            "1.0\n",
            "\u001b[91m0 (101%)\u001b[0m --> \u001b[91m0 (254%)\u001b[0m\n",
            "\n",
            "I would say that the \u001b[91mbest\u001b[0m way that we \u001b[91mcould\u001b[0m \u001b[91mensure\u001b[0m that an \u001b[91mevent\u001b[0m like this runs \u001b[91msmoothly\u001b[0m is a lot of planning and \u001b[91mpreparation\u001b[0m. Expecting for things like \u001b[91mweather\u001b[0m or \u001b[91mlack\u001b[0m of maybe things like. I don't know extension \u001b[91mcords\u001b[0m for electronic devices. Internal and external to team. If somebody didn't show up, would we have other people ready to go in their absence? And if? Let's see if somebody got injured. Is there a contingency plan to replace that person? Or if somebody had to take them to the hospital? Tribid, but I \u001b[91mguess\u001b[0m \u001b[91manything\u001b[0m that could go wrong might go wrong. So just a first \u001b[91maid\u001b[0m. Things like that. What to do again with inclement weather? There is a tent, but just a lot of pre planning. That's what I would say. \n",
            "\n",
            "I would say that the \u001b[91mother\u001b[0m way that we \u001b[91mmight\u001b[0m \u001b[91mthink\u001b[0m that an \u001b[91moutbreak\u001b[0m like this runs \u001b[91mwell\u001b[0m is a lot of planning and \u001b[91mthinking\u001b[0m. Expecting for things like \u001b[91mstress\u001b[0m or \u001b[91mmaybe\u001b[0m of maybe things like. I don't know extension \u001b[91mequipment\u001b[0m for electronic devices. Internal and external to team. If somebody didn't show up, would we have other people ready to go in their absence? And if? Let's see if somebody got injured. Is there a contingency plan to replace that person? Or if somebody had to take them to the hospital? Tribid, but I \u001b[91mthink\u001b[0m \u001b[91mstuff\u001b[0m that could go wrong might go wrong. So just a first \u001b[91mmeeting\u001b[0m. Things like that. What to do again with inclement weather? There is a tent, but just a lot of pre planning. That's what I would say. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [01:56,  7.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (103%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Right first of all. Made to make sure we have all the appropriate staff in place. With regards to this event, if we're short staffed in any way. We need to hire people to do their jobs. Secondly, we need to make sure that all the equipment that we need for this project. Arrive safely and in time. It's imperative. With regards to this job. That everything runs smoothly. For our company's benefit. We must also make sure. That we leave absolutely nothing behind and everything is tidy. If it's not. It has a bad reputation on our company. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [02:01,  7.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57fe0d1d90> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ff2f8f50>\n",
            "1.0\n",
            "\u001b[91m0 (101%)\u001b[0m --> \u001b[91m0 (254%)\u001b[0m\n",
            "\n",
            "So one of the major \u001b[91mthings\u001b[0m that I can \u001b[91mthink\u001b[0m of that would \u001b[91maffect\u001b[0m both our guests and our own internal staff at this event would be \u001b[91mCOVID\u001b[0m. We need to \u001b[91mconsider\u001b[0m \u001b[91mwhether\u001b[0m people are not going to make our event. Can we recover any monetary \u001b[91mexpenses\u001b[0m if we're short on staff? Do we have people that can cover more than one idea? Are we serving alcohol or event? And in that case, do we have to create \u001b[91mlicenses\u001b[0m? Do we have \u001b[91msecurity\u001b[0m and do we have checks in place to make sure that we're only serving? People that should be. Depending on the type of event, whether it's a lunch, a dinner, or a dance. That'll set the tone for what kind of attitude that we have to have going into it, but in general, if it's an older crowd, we're not going to need as heavy security then as we do with younger. So there's so many things, there's super specific to the type of events that it is, but with a few basics out of the way, we can ensure that it runs smoothly.  \n",
            "\n",
            "So one of the major \u001b[91mconcerns\u001b[0m that I can \u001b[91mbe\u001b[0m of that would \u001b[91mworry\u001b[0m both our guests and our own internal staff at this event would be \u001b[91mpolitics\u001b[0m. We need to \u001b[91mcontrol\u001b[0m \u001b[91mbecause\u001b[0m people are not going to make our event. Can we recover any monetary \u001b[91mlosses\u001b[0m if we're short on staff? Do we have people that can cover more than one idea? Are we serving alcohol or event? And in that case, do we have to create \u001b[91mproblems\u001b[0m? Do we have \u001b[91mproblems\u001b[0m and do we have checks in place to make sure that we're only serving? People that should be. Depending on the type of event, whether it's a lunch, a dinner, or a dance. That'll set the tone for what kind of attitude that we have to have going into it, but in general, if it's an older crowd, we're not going to need as heavy security then as we do with younger. So there's so many things, there's super specific to the type of events that it is, but with a few basics out of the way, we can ensure that it runs smoothly.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [02:04,  5.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "\u001b[91m0 (-3%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "If I was in that situation. Now there's another bad planner I've taken in my sketchpad text. Some nods. The pair what what papers like and listen to them. And try to say. Pause what type test like. Have decorations. Sarcastic. Mystical team, whatever. That's what. Watch the watch. Usually pigs and their interests in general so. That's that's all I'm trying to say. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [02:13,  6.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (193%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "OK, so the main thing which I could think of that could go wrong with the several teams working together has to be the the communication aspect because. It's very easy for messages to be misconstrued or not understood. So the the collaboration between the. The teams which are working together could be a struggle unless everyone understands each other and works together efficiently. Other than that, also the because there's hired equipment for for an event, everyone needs to be aware of how that equipment is used, so I could see problems occurring if there wasn't the proper training protocols in place to train the. The members of the team to be able to use this equipment properly. And of course, that could cause problems with the actual event if. The the equipment is used in the wrong way or something goes wrong or malfunctions with the equipment due to poor training. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [02:26,  8.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (104%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "I'd have to make sure that I had a full understanding of the type of event and all the details the event planner had arranged with whoever is hiring us to do this event. So a schedule of equipment that was required, a scheduled timetable, a full agreement of what was required for us to provide the people, I'd have to have an idea of the budget that also have been set up so I could coordinate a enough staff to actually take care of either running the event. Setting up the equipment and doing the tidy up afterwards, I need to have a contingency as well. Both of staff and of money in case anything goes wrong, such as equipment not being delivered on time, incorrect equipment being delivered on to the location staff not turning up all staff to make sure that we coordinate with the event itself. Things such as health and safety fire, that kind of thing. So I know where to evacuate my staff and actual people with doing as well and even know the timings that have been confirmed. And it went. We have to be out and also any other arrangers have to make with the event planner. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [02:39,  9.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So yes, I would split it into UM. Into three different sections, so I'd have anything to do with the post event, so that will be organized and suppliers organized, supplies how they would get there, any sort of access for trade routes, trade suppliers, rather, how they would get to the when we get to the site and anything on initial setup. So if you need to security. It just depends how large slot event is really UM, and then I'd have a middle section while the the event was in place for how the teams would work together during the event. How they would cooperate work together if there was any crossover between teams that reached team had a specific skill set that they would use source that to how they would work most effectively, and then there would be a final list of how the teams would work to sort of conclude the event. The events over the the people have left and what have you. Is there a clean up? Do the supplies do part of the clean themselves? \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [02:52, 10.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (102%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "When you have an event to be planned and there's a lot of people involved, the main thing to do is coordination. It's all about communication and making sure you're all on the same page, and so the first thing that needs to be done is. Making sure that to avoid the biggest problems, we're all on the same page. We all have the same itinerary. We all have the same schedule and really, you know you can't handle everything right? So you just do your best. You have your start and you're finished and where you come in in between. There is how well you're going to perform in this case. We all need to know what time you know as far as the setup. What time does that start? What time is that expected to finish and have a buffer delivering the event tidying up? Same thing, and so the goal for us should be how do we communicate through each one of those processes? Let's not just tell people what to do, it's giving them direction and then following up with them, helping them along the way, making sure that they understand this is their job. Here's their directive, and here's the support that they're going to get to make sure that they accomplish their goal. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [02:59,  9.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (97%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "I would prepare by first of all, making sure that we had walkie talkies in case there was any issues with phones or with them. Cell service at the location and I would make sure that the people that were renting equipment from are on speed dial that we know their names and their numbers very quickly. I would make sure that my team had lots of people that could do different tasks so that if one person had to. Bail out that someone else could take their place and for weather I would try and think ahead and plan for a backup space. Or maybe a tent or something like that and. Make sure that everyone has a backup food and water in case anything goes wrong with food. Depending on the kind of event it is, and yeah, those are a few of the things I would do. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [03:01,  7.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "\u001b[91m0 (-6%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "I hope you're getting these videos, I don't. I don't know what's going on. There doesn't seem to be sending. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [03:12,  8.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (98%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "In order for the event to go smoothly, communication is going to be the most optimal and the highest priority, so we're going to have to focus on communication and making sure that communication happens virtually instantaneously. We need to a cell phone app or some type of app that will allow us to be able to check things off, as each of the items are completed for the event so that the event can go off without a hitch. Ultimately, we're going to need a series of. Goals and we're going to need teams that would be developed around those goals and team leaders to make sure that those goals are reached and that quality is assured all the way into the end. We're also going to need to evaluate as we go, which I would be looking for a project manager to make sure that that person speaks on the moment in the moment with each of the team leaders to make sure that all of the events in the team that the teams are set to do would go off without a hitch, and that the event would go off well as well also. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r22it [03:16,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57fe3334d0> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec6cdf10>\n",
            "1.0\n",
            "\u001b[91m0 (102%)\u001b[0m --> \u001b[91m0 (254%)\u001b[0m\n",
            "\n",
            "In \u001b[91mregards\u001b[0m to. Event planning \u001b[91msituation\u001b[0m. And \u001b[91mplanning\u001b[0m the event. I \u001b[91mwould\u001b[0m \u001b[91mfirst\u001b[0m \u001b[91mopt\u001b[0m for backup equipment. Backup staff in the \u001b[91mcase\u001b[0m that equipment doesn't work right or staff can't show up on the day of. I wouldn't \u001b[91mensure\u001b[0m. I had enough staff to tidy up afterwards and deliver the event. In the sense that. I would \u001b[91mopt\u001b[0m for more staff than less. And. Probably work for floor myself if I could while I was at the event by the hand.  Both \u001b[91mdirect\u001b[0m and planning ways that I feel like this could be navigated. \n",
            "\n",
            "In \u001b[91maddition\u001b[0m to. Event planning \u001b[91mstaff\u001b[0m. And \u001b[91mrunning\u001b[0m the event. I \u001b[91mmight\u001b[0m \u001b[91mnot\u001b[0m \u001b[91mwork\u001b[0m for backup equipment. Backup staff in the \u001b[91mfear\u001b[0m that equipment doesn't work right or staff can't show up on the day of. I wouldn't \u001b[91mfail\u001b[0m. I had enough staff to tidy up afterwards and deliver the event. In the sense that. I would \u001b[91mfight\u001b[0m for more staff than less. And. Probably work for floor myself if I could while I was at the event by the hand.  Both \u001b[91mprofessional\u001b[0m and planning ways that I feel like this could be navigated. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r23it [03:21,  6.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "OK, we need to know about the time the venue is available and open to accept deliveries. Delivery at times for the higher equipment to arrive, we need each team to have assignment of the duties they need to complete and when in order other issues we might come across are teams arriving at the right times or members of the teams not arriving in. Or calling in sick at short notice. Do we have the instructions and the knowledge required to assemble the equipment as that being provided beforehand? \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [03:30,  7.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (101%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Additionally, we would want to make sure that the. The technology and the the hide equipment has been set up correctly and is compliant with health and safety, so making sure the attendees aren't going to trip over the employees aren't the trip over. Also making sure that the agenda is shared with attendees ahead of the event. So that people know what to expect, have adequate time to plan before they turn up, and are aware of what time the event's going to finish. Also making sure that there are the right number of people to stay around at the end of the event to tidy away. And and also, I suppose communication throughout the event as well. So if there's several teams working together, then having some kind of system in place, whether it's a WhatsApp group or a headset or walkie talkies so that people are. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [03:41,  8.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (198%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Can you helping an event planner with an important event that involves coordinating several teams working together to set up the hide equipment to live the event and tidy up afterwards to ensure the event of smoothly you've been asked to prepare for anything that could go wrong? What types of problems, both internal and external to your team could come up that affect how well the event goes? List as many factors as you can, right? So hide equipment, there could be equipment faults, electrical faults, general wear and tear. It's good to have some backups on site just in case. Delivered the event so that sounds like it could be through with preparation. You need people there with the required expertise. You might need people on hand in case there are sicknesses. And you know, general things that can go wrong with people. And tidy up afterwards. So tighten up. Make sure you have the right equipment. Again, cleaning chemicals bin bags. What else could go wrong? Power cut? Can't take a generator, that's ridiculous. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [03:52,  9.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (99%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So having worked in the past on some different types of events in a variety of venues I can see there's a number of issues that can go wrong, particularly when there's higher equipment. One of the main things that is most important to mitigate against some of these issues is to ensure that there's a lot of forward planning to ensure that any kind of risks are managed and are mitigated against. So, for example, ensuring that the planning process that you make sure that all of the technical specifications. Are really specific and clear to avoid any incompatibility issues. That's a big issue. Another one is is just staff not having an awareness, so just making sure that staff are appropriately trained for the equipment that may be in place, making sure that you've got a full inventory log. Make sure that nothing doesn't. Equipment doesn't turn up or similar that you know that you know that you're getting what you need. Also, making sure that your clients or your presenters know what they're going to need in order to be able to deliver that event. So that it can be compatible is really important. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [03:59,  8.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (98%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "All right so. Is very essential that when someone is planning for. Very important events possibly has to double check that team. Ensure that everything is going as well as planned. If possible, one has to be very physical, physically present in the planning events. Check out all equipments that were supplied to make sure that they are working perfectly. Also, one has to prepare for a backup plan because it's very essential, you know. In case if there's a fault, if there's if maybe one of the team members and can make it probably. Also you have to also prepare for that. Also, the way there has to be preparation for bad weather. Also they have to be prepared. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r28it [04:11,  9.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (199%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "The problems that I would anticipate and prepare for are miscommunications when you're working with a large group of different people. Each person has a different communication style, so you need to know that there might be some miscommunication. That might happen. So just preparing for that and. Also, people have different working styles. Some some individuals may not be as reliable as others, so I'm going to prepare for that. People being late or people not showing up at all. I have to prepare for that and I also have two prepare for us being short staffed for short stuff. What's going to happen? I have to also come up with a way of performing the tasks that we have to do so it's decorating for an event. So I have to figure out how what each person is going to do, how they're going to do it, and the time that will allocate for that so that we know how to do it so that everything runs smoothly. It's. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r29it [04:21,  9.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (193%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So I think the person foremost in terms of actually setting up the equipment. One of the most important things is sort of ensuring that all the well. Whichever teams or staff members are involved in using the equipment or. Adequately trained in actually operating the equipment and sort of if any issues come about when attempting to use the equipment, they're able to troubleshoot or go to somebody that would be able to help them. Basically fix any issues promptly. Then yeah, also, everyone just needs to know what they're doing in terms of delivering the event so people have to stick to timelines, guidelines, deliver the information appropriately, and keep the audience engaged and in terms of tidying up, this also needs to be done in a prompt fashion, ensuring that the equipment is not damaged and is transported from A to B in an adequate timeframe. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [04:24,  7.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "\u001b[91m0 (-4%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Basically I've been ahead. To prepare anything. Back up, go running. Why the change are working together and basically you make sure that you can use Tyler. Cleaning Charlie around there's no obstruction, use it. While and whilst on the floor so anybody could select a file with no wires. Life wise I'm going around. Make sure everything's in order in place. And basically basically concerned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r31it [04:34,  8.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (103%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So look through the event, set up delivery and tidy up. The first thing to do is get the teams together. Make sure everyone's there and they all know what they're doing and setup is important and need to get the equipment together and everyone needs to know what they're doing with it. So sufficient training is very important. Depending on the equipment. The man has to be there on time, has to be distributed to the correct locations. And the teams need to know what they're doing with their. If there's any equipment, light broken or waiting on it. The day could be quite delayed. We've got to deliver the. Event as well. As far as delivery goes, it just rains probably a bit more standing around, making sure everything carries on working and the teams and individuals know what to do with the people and tidying up people hate this and always want to go home. It could be not enough bins. It could be that stuff can't be packed away. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r32it [04:43,  8.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (192%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Right specific factors that could affect the event going well include whether torrential downpours. Gale force winds. Trees coming down etc. Logistics, transportation, ensuring that every person is. In the right place, at the right time, because it involves several teams working together, the equipment arriving at the right time, so logistics is a is a key key thing here. So checking traffic reports, checking for any road diversions that are put in place in advance to ensure that people get to the right place at the right time. The obvious one should have put first COVID. How many people will be out and unavailable due to COVID restrictions. Have you got contingency for backing up? If you have over a certain percentage of staff that aren't available to be there and equally have you got other suppliers? Available if there is a COVID related. Choose with. With with supplying items or supplying staff that need to be in particular places at the time. Other ideas include the idea. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r33it [04:49,  7.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57fe9916d0> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f58312ec090>\n",
            "1.0\n",
            "\u001b[91m0 (103%)\u001b[0m --> \u001b[91m0 (256%)\u001b[0m\n",
            "\n",
            "Well, it \u001b[91mdepends\u001b[0m on many \u001b[91mfactors\u001b[0m. If the event is \u001b[91mindoors\u001b[0m or \u001b[91moutdoors\u001b[0m, that would be one \u001b[91mfactor\u001b[0m that would be very \u001b[91mimportant\u001b[0m. If the event was \u001b[91mindoors\u001b[0m, we'd have to have a \u001b[91mbuilding\u001b[0m \u001b[91mrental\u001b[0m. We'd have to make sure that the fire code was not \u001b[91mviolated\u001b[0m. With too many people in there, we have to make sure that the sound system works. The lighting works. We have to make sure that the event, whatever it is, whether it's a bar Midsummer or winning or something else, had enough food and enough staff and some security. The same thing with \u001b[91moutdoors\u001b[0m. You have to make sure that all those factors were met, but we also have to make \u001b[91msure\u001b[0m there was a tented case of inclement weather and postponement day, just in case the weather was so bad that we had to move the date to some other time on the calendar. So that would those would be the main things securing a venue. Security paying the venue, lighting, sound, food, some sort of wait, staff. Can't think of anything else but those would be the main factors that we have to do in order to have a successful event of any kind, whether it's \u001b[91mindoors\u001b[0m or outdoors. That's all I can think of. \n",
            "\n",
            "Well, it \u001b[91mdepend\u001b[0m on many \u001b[91missues\u001b[0m. If the event is \u001b[91mrain\u001b[0m or \u001b[91mcold\u001b[0m, that would be one \u001b[91mproblem\u001b[0m that would be very \u001b[91mdangerous\u001b[0m. If the event was \u001b[91mwinter\u001b[0m, we'd have to have a \u001b[91mriot\u001b[0m \u001b[91mcode\u001b[0m. We'd have to make sure that the fire code was not \u001b[91maffected\u001b[0m. With too many people in there, we have to make sure that the sound system works. The lighting works. We have to make sure that the event, whatever it is, whether it's a bar Midsummer or winning or something else, had enough food and enough staff and some security. The same thing with \u001b[91mweather\u001b[0m. You have to make sure that all those factors were met, but we also have to make \u001b[91mconfident\u001b[0m there was a tented case of inclement weather and postponement day, just in case the weather was so bad that we had to move the date to some other time on the calendar. So that would those would be the main things securing a venue. Security paying the venue, lighting, sound, food, some sort of wait, staff. Can't think of anything else but those would be the main factors that we have to do in order to have a successful event of any kind, whether it's \u001b[91mnorth\u001b[0m or outdoors. That's all I can think of. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r34it [04:57,  7.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57fe9a9a50> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec134310>\n",
            "1.0\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m0 (253%)\u001b[0m\n",
            "\n",
            "You are \u001b[91mhelping\u001b[0m an event \u001b[91mplanner\u001b[0m with an important event that \u001b[91minvolves\u001b[0m coordinating several teams working together to set up the hired equipment, deliver the event and \u001b[91mtidy\u001b[0m up \u001b[91mafterwards\u001b[0m to ensure the event goes \u001b[91msmoothly\u001b[0m. You have been \u001b[91masked\u001b[0m to prepare for \u001b[91manything\u001b[0m that could go wrong. What types of problems, both internal and external to your team could you come up with that could affect how well the event goes? List has many specific factors. If you as you can well, I \u001b[91mwould\u001b[0m \u001b[91mgo\u001b[0m with the \u001b[91mchecklist\u001b[0m and a couple of different \u001b[91maccountability\u001b[0m \u001b[91mpartners\u001b[0m just to make sure that all of the different. All of the different preferred, I'm sorry all of the different things that we need to have happen get done. \n",
            "\n",
            "You are \u001b[91mexperiencing\u001b[0m an event \u001b[91mhappen\u001b[0m with an important event that \u001b[91mwas\u001b[0m coordinating several teams working together to set up the hired equipment, deliver the event and \u001b[91mlock\u001b[0m up \u001b[91mpersonnel\u001b[0m to ensure the event goes \u001b[91mpoorly\u001b[0m. You have been \u001b[91mforced\u001b[0m to prepare for \u001b[91mproblems\u001b[0m that could go wrong. What types of problems, both internal and external to your team could you come up with that could affect how well the event goes? List has many specific factors. If you as you can well, I \u001b[91mdo\u001b[0m \u001b[91mwork\u001b[0m with the \u001b[91mstaff\u001b[0m and a couple of different \u001b[91mbusiness\u001b[0m \u001b[91mrelationships\u001b[0m just to make sure that all of the different. All of the different preferred, I'm sorry all of the different things that we need to have happen get done. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r35it [05:05,  7.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (102%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "OK, so a lot can go wrong with event planning. You gotta make sure you hire the right people. The best people you can find, but you've got to assume that some people aren't going to show up. You've got a book, the venue. Let everyone know when they're supposed to be there. Let everyone know what their job is. You're definitely. Gonna have people who don't want to clean up afterwards, but you're gonna have to assign all these jobs beforehand. You gotta make sure you have the equipment on time. You gotta make sure you have food. All the teams set up all the room setup. Wi-Fi for any work you gotta. You know, just make sure everyone has everything they need, but assume that some people aren't gonna show up. Some things are gonna go wrong, you've gotta just. Plan for you know, plan for the best, but be prepared for the worst. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "36it [05:06,  8.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (189%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "The potential problems you could have is that supplies didn't turn up the equipment that they supply is unusable. How to save someone non factors like the pandemic as such could come into effect. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_df.to_csv('/content/A2T_attack_df_763_+1.5.csv')"
      ],
      "metadata": {
        "id": "ZyfiRildOFYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack = create_attack(model_wrapper, attack_name='A2T-Hybrid_v1')\n",
        "\n",
        "df = test_set[['transcript', 'content_rating']][test_set[ 'content_rating']<3]\n",
        "for idx, row in tqdm(df.iterrows()):\n",
        "    result = attack.attack(row['transcript'], row['content_rating'])\n",
        "    attack_df = attack_df.append({'transcript': row['transcript']\n",
        "                                  , 'content_rating':row['content_rating']\n",
        "                                  , 'Adversarial':result.perturbed_text()\n",
        "                                  , 'dump' : result.str_lines()[0]}, ignore_index=True)\n",
        "    result.original_text(), result.perturbed_text()\n",
        "    print(row['content_rating'])\n",
        "    print(result.__str__(color_method='ansi'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAXdZlzNWtsl",
        "outputId": "9681de69-c5e2-4e06-93ac-baa02d0ef7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n",
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "All model checkpoint weights were used when initializing RobertaForCausalLM.\n",
            "\n",
            "All the weights of RobertaForCausalLM were initialized from the model checkpoint at distilroberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForCausalLM for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/distilroberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/23e0f7484fc8a320856b168861166b48c2976bb4e0861602422e1b0c3fe5bf61.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/distilroberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c7e8020011da613ff5a9175ddad64cd47238a9525db975eb50ecb965e9f7302f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/distilroberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/b6a9ca6504e67903474c3fdf82ba249882406e61c2176a9d4dc9c3691c663767.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/distilroberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilroberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilroberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "textattack: No entry found for goal function <class '__main__.TargetedRegression'>.\n",
            "textattack: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class '__main__.TargetedRegression'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2T-Hybrid_v1 attack is running.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:18, 18.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (103%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "We need to focus firstly on delegating tasks and priorities. We need someone to focus on. Does the equipment arrive? Is the hall empty? Are people arriving early? And where do we stage them? If our room is not available? Secondly, we need to plan for. People's problems if there's a situation or an escalation, how do we remove a person from the situation? How do we deescalate the situation? We need to work with the management of the venue to find out exactly what they offer and if there is any restrictions or unavailable items. How do we prepare for that? Or how do we handle that if, say, their room is not available after the last party? What do we do? Who do we talk to? We need to have those resources on hand. The other thing we need to prioritize is the specific expectations and requests of the facilitators. What is it you really need for us? What is the number one focus on what we need? Who do we follow up with afterward? Both for billing and satisfaction, we need to have a backup vendor if something doesn't come through. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:28, 13.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57d23abcd0> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57d22886d0>\n",
            "1.0\n",
            "\u001b[91m0 (99%)\u001b[0m --> \u001b[91m0 (250%)\u001b[0m\n",
            "\n",
            "If I were \u001b[91mcoordinating\u001b[0m an event that was very complex, involves \u001b[91mmany\u001b[0m team \u001b[91mmembers\u001b[0m, \u001b[91mI\u001b[0m \u001b[91mwould\u001b[0m \u001b[91mprepare\u001b[0m in \u001b[91mmany\u001b[0m different ways to make \u001b[91msure\u001b[0m everything ran smoothly. \u001b[91mI\u001b[0m \u001b[91mwould\u001b[0m have extras of \u001b[91mevery\u001b[0m material thing \u001b[91mI\u001b[0m would need, so depending on what the event is, but let's say it's a banquet, extra linens, extra candles, extra drinks, \u001b[91mI\u001b[0m \u001b[91mwould\u001b[0m have a team meeting at the beginning of the event at the beginning of call time for the event \u001b[91mI\u001b[0m would speak to each team member individually. \u001b[91mMake\u001b[0m sure that they're on board and that they feel a part of the mission. That would make sure to check in throughout the entire shift. That everyone's doing what they should be doing, but also that they feel appreciated and that we care about them being here. \u001b[91mI\u001b[0m would prepare by. Assuring that everything that needs to be there will be there if it's food. If it's a guest list, it depends, but I would just make sure many times. \n",
            "\n",
            "If I were \u001b[91mattending\u001b[0m an event that was very complex, involves \u001b[91mcomplex\u001b[0m team \u001b[91mdynamics\u001b[0m, \u001b[91mthey\u001b[0m \u001b[91mmight\u001b[0m \u001b[91mreact\u001b[0m in \u001b[91mmultiple\u001b[0m different ways to make \u001b[91mcertain\u001b[0m everything ran smoothly. \u001b[91mIt\u001b[0m \u001b[91mmight\u001b[0m have extras of \u001b[91many\u001b[0m material thing \u001b[91mit\u001b[0m would need, so depending on what the event is, but let's say it's a banquet, extra linens, extra candles, extra drinks, \u001b[91mit\u001b[0m \u001b[91mmight\u001b[0m have a team meeting at the beginning of the event at the beginning of call time for the event \u001b[91mwho\u001b[0m would speak to each team member individually. \u001b[91mMaking\u001b[0m sure that they're on board and that they feel a part of the mission. That would make sure to check in throughout the entire shift. That everyone's doing what they should be doing, but also that they feel appreciated and that we care about them being here. \u001b[91mIt\u001b[0m would prepare by. Assuring that everything that needs to be there will be there if it's food. If it's a guest list, it depends, but I would just make sure many times. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:39, 12.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (191%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Some of the problems that you could encounter here are, for example, if a member of staff didn't turn up. How we would deal with that? So having standby staff available or where management helped out more? When they probably wouldn't have done something, so just working as a team and we could have something like something going on with any kind of food. So just having those backup plans just in case something goes wrong. Which is making sure that yes OK, for all eventualities, that we do have a plan in place should something go wrong, so having. A potential backup supplier or a member of staff that would potentially wouldn't need just making sure that actually maybe we're having more stuff than not too many staff. So there's there's a lot of different factors. Involve. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:50, 11.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (208%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "One of the main things that could go wrong is if you don't have enough staff to help set up. So you need to always make sure to hire more staff than you need. This is something you do not want to cut corners with at all at all. You need to have enough staff. Also, inclement weather you need to be checking the weather reports, and if there's even a chance of rain or things like that, you need to be prepared for bad weather. You need to double check with the delivery teams you got to make sure they are paid beforehand or have deposits. You need to make sure all of that because you need your stuff delivered and you have to double check that you have enough people to help you break down the setup afterwards. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [01:16, 16.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (188%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "I think this is a recording. Yeah, OK, so I think it's important for us to point out that if I was preparing for this, I would want to be asking the internal teams exactly who they see it going wrong because that's how I identified the broadest range of problems will need to prepare to, but under the assumption that I need to answer this question now, the things need to think of first. That is, you need to liaise with the higher equipment people make the be available. Make sure it's not available. What can be done about it? Possibly even set the contingency higher so it wasn't available? You could speak to this person. Delivering the event could be simple. Depends on the resources you've got in place. Obviously the event could not offer planned people not be able to attend. There could be technical issues, for example, the venue could have something wrong with it, and these are all things you need to meet to get again with continues, and you're probably identify those by speaking to the externals again. Tighten up that is one that is less problematic insofar as it is less likely to affect. The delivery of events happened. They could lead to unforeseen costs. This was the whole thing. Could have an unseen costs in it that could lead to some sort of penalty. Perhaps a fairly venue in a suitable position. So what you have to do is you have to admit to get that have a plan in place. What the contingency is basically and you identify them by speaking to the teams you've got on the plan. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [01:30, 16.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (187%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So in a situation like this, the most obvious thing that could potentially go wrong would be that the hired equipment does not work. So to put a plan of action in place for this is I would make sure that I use the equipment the night before to make sure that all eventualities are. Set up for and if possible and within budget that we have replacement equipment that we could use. I can imagine that things like weather and the amount of people that turn up for this event would be an issue. We need to take into consideration. And I think it's just a case of having all these things. Put down so that we have a backup plan.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [01:54, 18.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (196%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So in terms of what can go wrong? In planning an event. Firstly, on an internal basis. sickness has to be accounted for. Particularly at COVID at the moment could people get COVID and are they going to be off for? Two weeks or even longer. So you need to ensure there's enough cover and and plan for that and be. Very organized and have a solid plan of action in order to mitigate that. Also. On a more external basis.  I'm sure we will be relying on various different companies that to provide. Feared all sorts of different things, so. I think maintaining those relationships and keeping in contact and make sure that they're up to date and we know where everything's at with those companies to ensure that everyone pulls their way and and the products that we need from them are going to be received. So I think maintaining relationships there is a key aspect.  In terms of what else could go wrong and how we could plan. I think having a strategy on. The people that are going to come to the event so invitations have gone out. People of our SVP had all these sort of things should be on top of well in advance of the event, so that on the actual day. It should run smoothly and it's all very organized and. It's the success in the end. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [02:11, 17.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (205%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "When planning for an event, you have to look at. Things that can go wrong. Some examples would be. Food not delivered on time then. Let's say depending on your guest demographic, there could be kids running around knocking things down. You could even have problematic. Adults trying to disrupt the event. Then any any props that you have for the event you have to make sure they're well secured. I'm not a safety hazard. And then you have to make sure that. In the event of a fire or a. Something like that you have the evacuation plan set up straight so that. You're well prepared, you know to avoid any. Injuries. Do your guests or to yourself or anybody as part of the event. Then it's always best to have. Doctor. Product that even in the case. Of an emergency. Other things that could go wrong. You know quality issues with food. Drinks and depending on the event. You know what kind of food is served and things like that, so yeah, this is just a few examples. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [02:15, 13.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (199%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Things affecting something going wrong with an event planner. The people couldn't show up the catering. People wouldn't show up so you would need a backup. The bride might be late or the cake might not show up. Or perhaps the cake might fall over and get destroyed and then you would have to create another. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [02:32, 14.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (201%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Can I believe I am I'm gonna be organising a wedding helping to organise a wedding and things that could go wrong or the actual like the catering might go wrong. We might not have organised enough food for the amount of people that are going to come. We need to allow for people that actually turn up extra, so hopefully there's some extra food and all to organize things like the DJ or the OR disco. Whatever is the having or the music entertainment. Need to make sure that turns up if it doesn't have. Got contingency in place in case of that happening. Also if the event is actually double booked we need to try and think of something else that's someone else we can use. We need to organise and making sure that everything is there at all decorated. The people that own charge of that turn up that when it's all done that we've all got a special source of. We've got like a timetable in place for how we're going to clean things up. We need to have timetable for everything really. Or time the food's going to get served and how we're going to do it all. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [02:39, 12.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec313790> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57e6517690>\n",
            "1.0\n",
            "\u001b[91m0 (101%)\u001b[0m --> \u001b[91m0 (251%)\u001b[0m\n",
            "\n",
            "I \u001b[91mwould\u001b[0m say that the \u001b[91mbest\u001b[0m way that we could \u001b[91mensure\u001b[0m that an event like this runs smoothly is a lot of planning and preparation. \u001b[91mExpecting\u001b[0m for \u001b[91mthings\u001b[0m like weather or \u001b[91mlack\u001b[0m of maybe things like. I don't know extension cords for electronic devices. Internal and external to team. If somebody didn't show up, \u001b[91mwould\u001b[0m we have other people \u001b[91mready\u001b[0m to go in their absence? And if? \u001b[91mLet's\u001b[0m \u001b[91msee\u001b[0m if somebody got injured. Is there a contingency plan to replace that person? Or if somebody had to take them to the hospital? Tribid, but I guess \u001b[91manything\u001b[0m that could go wrong might go wrong. So just a first aid. Things like that. What to do again with inclement weather? There is a tent, but just a lot of pre planning. That's what I would say. \n",
            "\n",
            "I \u001b[91mmight\u001b[0m say that the \u001b[91mcheapest\u001b[0m way that we could \u001b[91minsure\u001b[0m that an event like this runs smoothly is a lot of planning and preparation. \u001b[91mWeather\u001b[0m for \u001b[91mweather\u001b[0m like weather or \u001b[91mstuff\u001b[0m of maybe things like. I don't know extension cords for electronic devices. Internal and external to team. If somebody didn't show up, \u001b[91mmight\u001b[0m we have other people \u001b[91mable\u001b[0m to go in their absence? And if? \u001b[91mOr\u001b[0m \u001b[91mimagine\u001b[0m if somebody got injured. Is there a contingency plan to replace that person? Or if somebody had to take them to the hospital? Tribid, but I guess \u001b[91mthings\u001b[0m that could go wrong might go wrong. So just a first aid. Things like that. What to do again with inclement weather? There is a tent, but just a lot of pre planning. That's what I would say. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [02:46, 10.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (103%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Right first of all. Made to make sure we have all the appropriate staff in place. With regards to this event, if we're short staffed in any way. We need to hire people to do their jobs. Secondly, we need to make sure that all the equipment that we need for this project. Arrive safely and in time. It's imperative. With regards to this job. That everything runs smoothly. For our company's benefit. We must also make sure. That we leave absolutely nothing behind and everything is tidy. If it's not. It has a bad reputation on our company. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [02:53,  9.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57c7f80690> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec04e950>\n",
            "1.0\n",
            "\u001b[91m0 (101%)\u001b[0m --> \u001b[91m0 (255%)\u001b[0m\n",
            "\n",
            "So \u001b[91mone\u001b[0m of the major things that I can think of that would affect both our guests and our own internal staff at this event \u001b[91mwould\u001b[0m be COVID. \u001b[91mWe\u001b[0m need to \u001b[91mconsider\u001b[0m \u001b[91mwhether\u001b[0m people are not going to make our event. Can we recover any monetary expenses if we're short on staff? Do we have people that can cover more than one idea? Are we serving alcohol or event? And in that case, do we have to create \u001b[91mlicenses\u001b[0m? Do we have security and do we have checks in place to make sure that we're only serving? People that should be. Depending on the type of event, whether it's a lunch, a dinner, or a dance. That'll set the tone for what kind of attitude that we have to have going into it, but in general, if it's an older crowd, we're not going to need as heavy security then as we do with younger. So there's so many things, there's super specific to the type of events that it is, but with a few basics out of the way, we can ensure that it runs smoothly.  \n",
            "\n",
            "So \u001b[91mtwo\u001b[0m of the major things that I can think of that would affect both our guests and our own internal staff at this event \u001b[91mmight\u001b[0m be COVID. \u001b[91mI\u001b[0m need to \u001b[91mstress\u001b[0m \u001b[91mbecause\u001b[0m people are not going to make our event. Can we recover any monetary expenses if we're short on staff? Do we have people that can cover more than one idea? Are we serving alcohol or event? And in that case, do we have to create \u001b[91mchaos\u001b[0m? Do we have security and do we have checks in place to make sure that we're only serving? People that should be. Depending on the type of event, whether it's a lunch, a dinner, or a dance. That'll set the tone for what kind of attitude that we have to have going into it, but in general, if it's an older crowd, we're not going to need as heavy security then as we do with younger. So there's so many things, there's super specific to the type of events that it is, but with a few basics out of the way, we can ensure that it runs smoothly.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [02:58,  8.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "\u001b[91m0 (-3%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "If I was in that situation. Now there's another bad planner I've taken in my sketchpad text. Some nods. The pair what what papers like and listen to them. And try to say. Pause what type test like. Have decorations. Sarcastic. Mystical team, whatever. That's what. Watch the watch. Usually pigs and their interests in general so. That's that's all I'm trying to say. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [03:11,  9.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (193%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "OK, so the main thing which I could think of that could go wrong with the several teams working together has to be the the communication aspect because. It's very easy for messages to be misconstrued or not understood. So the the collaboration between the. The teams which are working together could be a struggle unless everyone understands each other and works together efficiently. Other than that, also the because there's hired equipment for for an event, everyone needs to be aware of how that equipment is used, so I could see problems occurring if there wasn't the proper training protocols in place to train the. The members of the team to be able to use this equipment properly. And of course, that could cause problems with the actual event if. The the equipment is used in the wrong way or something goes wrong or malfunctions with the equipment due to poor training. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [03:22,  9.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57d237a790> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57d2298850>\n",
            "1.0\n",
            "\u001b[91m0 (104%)\u001b[0m --> \u001b[91m0 (251%)\u001b[0m\n",
            "\n",
            "I'd have to make sure that I had a \u001b[91mfull\u001b[0m \u001b[91munderstanding\u001b[0m of the \u001b[91mtype\u001b[0m of event and all the details the event \u001b[91mplanner\u001b[0m had arranged with whoever is hiring us to do this event. \u001b[91mSo\u001b[0m a schedule of equipment that was required, a scheduled timetable, a \u001b[91mfull\u001b[0m \u001b[91magreement\u001b[0m of what was required for us to provide the people, \u001b[91mI'd\u001b[0m have to have an \u001b[91midea\u001b[0m of the budget that also have been \u001b[91mset\u001b[0m up so I could coordinate a enough staff to actually take care of either running the event. Setting up the equipment and doing the tidy up afterwards, \u001b[91mI\u001b[0m need to have a contingency as well. Both of staff and of money in case \u001b[91manything\u001b[0m goes wrong, such as \u001b[91mequipment\u001b[0m not being delivered on time, incorrect equipment being \u001b[91mdelivered\u001b[0m on to the location \u001b[91mstaff\u001b[0m not turning up all staff to make sure that we coordinate with the event itself. Things such as health and safety fire, that kind of thing. So I know where to evacuate my staff and actual people with doing as well and even know the timings that have been confirmed. And it went. We have to be out and also any other arrangers have to make with the event planner. \n",
            "\n",
            "I'd have to make sure that I had a \u001b[91mrough\u001b[0m \u001b[91mbreakdown\u001b[0m of the \u001b[91mtiming\u001b[0m of event and all the details the event \u001b[91morganizers\u001b[0m had arranged with whoever is hiring us to do this event. \u001b[91mNot\u001b[0m a schedule of equipment that was required, a scheduled timetable, a \u001b[91mrough\u001b[0m \u001b[91mrundown\u001b[0m of what was required for us to provide the people, \u001b[91mpeople\u001b[0m have to have an \u001b[91maudit\u001b[0m of the budget that also have been \u001b[91mscrewed\u001b[0m up so I could coordinate a enough staff to actually take care of either running the event. Setting up the equipment and doing the tidy up afterwards, \u001b[91mthey\u001b[0m need to have a contingency as well. Both of staff and of money in case \u001b[91mthings\u001b[0m goes wrong, such as \u001b[91mtents\u001b[0m not being delivered on time, incorrect equipment being \u001b[91mput\u001b[0m on to the location \u001b[91mOR\u001b[0m not turning up all staff to make sure that we coordinate with the event itself. Things such as health and safety fire, that kind of thing. So I know where to evacuate my staff and actual people with doing as well and even know the timings that have been confirmed. And it went. We have to be out and also any other arrangers have to make with the event planner. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [03:31,  9.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec0b1450> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec7252d0>\n",
            "1.0\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m0 (251%)\u001b[0m\n",
            "\n",
            "So yes, \u001b[91mI\u001b[0m \u001b[91mwould\u001b[0m split it into UM. \u001b[91mInto\u001b[0m \u001b[91mthree\u001b[0m different sections, so \u001b[91mI'd\u001b[0m have anything to do with the post event, so that will be organized and suppliers organized, supplies how they would get there, any sort of \u001b[91maccess\u001b[0m for trade routes, trade suppliers, rather, how they would get to the when we get to the \u001b[91msite\u001b[0m and anything on initial setup. So if you need to security. It just depends how large slot event is really UM, and then \u001b[91mI'd\u001b[0m have a middle section while the the event was in \u001b[91mplace\u001b[0m for how the teams would work together during the event. How they would cooperate work \u001b[91mtogether\u001b[0m if there was any crossover between teams that reached team had a specific skill set that they would use source that to how they would work most effectively, and then there \u001b[91mwould\u001b[0m be a \u001b[91mfinal\u001b[0m \u001b[91mlist\u001b[0m of how the teams would work to sort of conclude the event. The events over the the people have left and what have you. Is there a clean up? Do the supplies do part of the clean themselves? \n",
            "\n",
            "So yes, \u001b[91mthey\u001b[0m \u001b[91mmight\u001b[0m split it into UM. \u001b[91mMaybe\u001b[0m \u001b[91mtwo\u001b[0m different sections, so \u001b[91mNOT\u001b[0m have anything to do with the post event, so that will be organized and suppliers organized, supplies how they would get there, any sort of \u001b[91mcoordination\u001b[0m for trade routes, trade suppliers, rather, how they would get to the when we get to the \u001b[91msummit\u001b[0m and anything on initial setup. So if you need to security. It just depends how large slot event is really UM, and then \u001b[91mNOT\u001b[0m have a middle section while the the event was in \u001b[91mDC\u001b[0m for how the teams would work together during the event. How they would cooperate work \u001b[91mthen\u001b[0m if there was any crossover between teams that reached team had a specific skill set that they would use source that to how they would work most effectively, and then there \u001b[91mmight\u001b[0m be a \u001b[91mpartial\u001b[0m \u001b[91mbreakdown\u001b[0m of how the teams would work to sort of conclude the event. The events over the the people have left and what have you. Is there a clean up? Do the supplies do part of the clean themselves? \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [03:48, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57ec25ef90> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57e664c590>\n",
            "1.0\n",
            "\u001b[91m0 (102%)\u001b[0m --> \u001b[91m0 (252%)\u001b[0m\n",
            "\n",
            "When you have an event to be \u001b[91mplanned\u001b[0m and there's a \u001b[91mlot\u001b[0m of people \u001b[91minvolved\u001b[0m, the main thing to do is coordination. It's all about communication and making sure you're all on the same \u001b[91mpage\u001b[0m, and so the \u001b[91mfirst\u001b[0m thing that \u001b[91mneeds\u001b[0m to be done is. \u001b[91mMaking\u001b[0m sure that to \u001b[91mavoid\u001b[0m the \u001b[91mbiggest\u001b[0m problems, we're all on the same \u001b[91mpage\u001b[0m. \u001b[91mWe\u001b[0m all have the same itinerary. \u001b[91mWe\u001b[0m all have the same schedule and really, you \u001b[91mknow\u001b[0m you can't handle everything \u001b[91mright\u001b[0m? \u001b[91mSo\u001b[0m you just do your best. You have your \u001b[91mstart\u001b[0m and you're \u001b[91mfinished\u001b[0m and where you come in in between. There is how \u001b[91mwell\u001b[0m you're \u001b[91mgoing\u001b[0m to \u001b[91mperform\u001b[0m in this \u001b[91mcase\u001b[0m. We all need to \u001b[91mknow\u001b[0m what time you know as far as the \u001b[91msetup\u001b[0m. What time does that start? What time is that expected to finish and have a buffer delivering the event tidying up? Same thing, and so the goal for us should be how do we communicate through each one of those \u001b[91mprocesses\u001b[0m? Let's not just tell people what to do, it's giving them \u001b[91mdirection\u001b[0m and then following up with them, helping them along the way, making sure that they understand this is their job. Here's their \u001b[91mdirective\u001b[0m, and here's the support that they're going to get to make \u001b[91msure\u001b[0m that they accomplish their goal. \n",
            "\n",
            "When you have an event to be \u001b[91mcancelled\u001b[0m and there's a \u001b[91mglut\u001b[0m of people \u001b[91mcompeting\u001b[0m, the main thing to do is coordination. It's all about communication and making sure you're all on the same \u001b[91mteam\u001b[0m, and so the \u001b[91mhardest\u001b[0m thing that \u001b[91mgets\u001b[0m to be done is. \u001b[91mmaking\u001b[0m sure that to \u001b[91manticipate\u001b[0m the \u001b[91mlogistical\u001b[0m problems, we're all on the same \u001b[91mboat\u001b[0m. \u001b[91mYou\u001b[0m all have the same itinerary. \u001b[91mYou\u001b[0m all have the same schedule and really, you \u001b[91mfigure\u001b[0m you can't handle everything \u001b[91mproperly\u001b[0m? \u001b[91mSometimes\u001b[0m you just do your best. You have your \u001b[91mschedule\u001b[0m and you're \u001b[91mtired\u001b[0m and where you come in in between. There is how \u001b[91mbadly\u001b[0m you're \u001b[91msubjected\u001b[0m to \u001b[91mweather\u001b[0m in this \u001b[91mrace\u001b[0m. We all need to \u001b[91manticipate\u001b[0m what time you know as far as the \u001b[91mweather\u001b[0m. What time does that start? What time is that expected to finish and have a buffer delivering the event tidying up? Same thing, and so the goal for us should be how do we communicate through each one of those \u001b[91mdelays\u001b[0m? Let's not just tell people what to do, it's giving them \u001b[91msupport\u001b[0m and then following up with them, helping them along the way, making sure that they understand this is their job. Here's their \u001b[91mplaybook\u001b[0m, and here's the support that they're going to get to make \u001b[91mcertain\u001b[0m that they accomplish their goal. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [07:11, 69.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (97%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "I would prepare by first of all, making sure that we had walkie talkies in case there was any issues with phones or with them. Cell service at the location and I would make sure that the people that were renting equipment from are on speed dial that we know their names and their numbers very quickly. I would make sure that my team had lots of people that could do different tasks so that if one person had to. Bail out that someone else could take their place and for weather I would try and think ahead and plan for a backup space. Or maybe a tent or something like that and. Make sure that everyone has a backup food and water in case anything goes wrong with food. Depending on the kind of event it is, and yeah, those are a few of the things I would do. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [07:13, 49.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "\u001b[91m0 (-6%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "I hope you're getting these videos, I don't. I don't know what's going on. There doesn't seem to be sending. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [07:29, 39.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (98%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "In order for the event to go smoothly, communication is going to be the most optimal and the highest priority, so we're going to have to focus on communication and making sure that communication happens virtually instantaneously. We need to a cell phone app or some type of app that will allow us to be able to check things off, as each of the items are completed for the event so that the event can go off without a hitch. Ultimately, we're going to need a series of. Goals and we're going to need teams that would be developed around those goals and team leaders to make sure that those goals are reached and that quality is assured all the way into the end. We're also going to need to evaluate as we go, which I would be looking for a project manager to make sure that that person speaks on the moment in the moment with each of the team leaders to make sure that all of the events in the team that the teams are set to do would go off without a hitch, and that the event would go off well as well also. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r22it [07:35, 29.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57e66660d0> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57e650acd0>\n",
            "1.0\n",
            "\u001b[91m0 (102%)\u001b[0m --> \u001b[91m0 (290%)\u001b[0m\n",
            "\n",
            "In \u001b[91mregards\u001b[0m to. Event \u001b[91mplanning\u001b[0m \u001b[91msituation\u001b[0m. And planning the event. \u001b[91mI\u001b[0m \u001b[91mwould\u001b[0m \u001b[91mfirst\u001b[0m opt for backup equipment. Backup staff in the \u001b[91mcase\u001b[0m that equipment doesn't work right or staff \u001b[91mcan't\u001b[0m show up on the day of. \u001b[91mI\u001b[0m wouldn't \u001b[91mensure\u001b[0m. I had enough staff to tidy up afterwards and deliver the event. In the sense that. \u001b[91mI\u001b[0m would opt for more staff than less. And. Probably work for floor myself if I could while I was at the event by the hand.  Both \u001b[91mdirect\u001b[0m and planning ways that I feel like this could be navigated. \n",
            "\n",
            "In \u001b[91maddition\u001b[0m to. Event \u001b[91mstaffing\u001b[0m \u001b[91missues\u001b[0m. And planning the event. \u001b[91mYou\u001b[0m \u001b[91mmight\u001b[0m \u001b[91mnot\u001b[0m opt for backup equipment. Backup staff in the \u001b[91mbelief\u001b[0m that equipment doesn't work right or staff \u001b[91mcant\u001b[0m show up on the day of. \u001b[91mIt\u001b[0m wouldn't \u001b[91mrain\u001b[0m. I had enough staff to tidy up afterwards and deliver the event. In the sense that. \u001b[91mIt\u001b[0m would opt for more staff than less. And. Probably work for floor myself if I could while I was at the event by the hand.  Both \u001b[91mlogistical\u001b[0m and planning ways that I feel like this could be navigated. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r23it [07:43, 22.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "OK, we need to know about the time the venue is available and open to accept deliveries. Delivery at times for the higher equipment to arrive, we need each team to have assignment of the duties they need to complete and when in order other issues we might come across are teams arriving at the right times or members of the teams not arriving in. Or calling in sick at short notice. Do we have the instructions and the knowledge required to assemble the equipment as that being provided beforehand? \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [07:55, 19.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (101%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Additionally, we would want to make sure that the. The technology and the the hide equipment has been set up correctly and is compliant with health and safety, so making sure the attendees aren't going to trip over the employees aren't the trip over. Also making sure that the agenda is shared with attendees ahead of the event. So that people know what to expect, have adequate time to plan before they turn up, and are aware of what time the event's going to finish. Also making sure that there are the right number of people to stay around at the end of the event to tidy away. And and also, I suppose communication throughout the event as well. So if there's several teams working together, then having some kind of system in place, whether it's a WhatsApp group or a headset or walkie talkies so that people are. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [08:10, 18.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (198%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Can you helping an event planner with an important event that involves coordinating several teams working together to set up the hide equipment to live the event and tidy up afterwards to ensure the event of smoothly you've been asked to prepare for anything that could go wrong? What types of problems, both internal and external to your team could come up that affect how well the event goes? List as many factors as you can, right? So hide equipment, there could be equipment faults, electrical faults, general wear and tear. It's good to have some backups on site just in case. Delivered the event so that sounds like it could be through with preparation. You need people there with the required expertise. You might need people on hand in case there are sicknesses. And you know, general things that can go wrong with people. And tidy up afterwards. So tighten up. Make sure you have the right equipment. Again, cleaning chemicals bin bags. What else could go wrong? Power cut? Can't take a generator, that's ridiculous. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [08:25, 17.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57d2357d50> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57e6267e10>\n",
            "1.0\n",
            "\u001b[91m0 (99%)\u001b[0m --> \u001b[91m0 (253%)\u001b[0m\n",
            "\n",
            "So having \u001b[91mworked\u001b[0m in the past on some different types of events in a \u001b[91mvariety\u001b[0m of \u001b[91mvenues\u001b[0m \u001b[91mI\u001b[0m can \u001b[91msee\u001b[0m \u001b[91mthere's\u001b[0m a \u001b[91mnumber\u001b[0m of \u001b[91missues\u001b[0m that can \u001b[91mgo\u001b[0m wrong, \u001b[91mparticularly\u001b[0m when there's higher equipment. \u001b[91mOne\u001b[0m of the \u001b[91mmain\u001b[0m things that is most important to \u001b[91mmitigate\u001b[0m against some of these issues is to \u001b[91mensure\u001b[0m that \u001b[91mthere's\u001b[0m a lot of \u001b[91mforward\u001b[0m planning to \u001b[91mensure\u001b[0m that any kind of risks are managed and are \u001b[91mmitigated\u001b[0m against. So, for example, \u001b[91mensuring\u001b[0m that the planning process that you make \u001b[91msure\u001b[0m that all of the technical \u001b[91mspecifications\u001b[0m. \u001b[91mAre\u001b[0m really \u001b[91mspecific\u001b[0m and \u001b[91mclear\u001b[0m to avoid any \u001b[91mincompatibility\u001b[0m issues. \u001b[91mThat's\u001b[0m a big issue. Another one is is just staff not having an awareness, so just making sure that staff are \u001b[91mappropriately\u001b[0m trained for the equipment that may be in place, making sure that you've got a full \u001b[91minventory\u001b[0m log. Make sure that nothing doesn't. Equipment doesn't turn up or similar that you know that you know that you're getting what you need. Also, making sure that your clients or your presenters know what they're going to need in order to be able to deliver that event. So that it can be \u001b[91mcompatible\u001b[0m is really important. \n",
            "\n",
            "So having \u001b[91mhappened\u001b[0m in the past on some different types of events in a \u001b[91mhost\u001b[0m of \u001b[91mcircumstances\u001b[0m \u001b[91mthey\u001b[0m can \u001b[91mforesee\u001b[0m \u001b[91mare\u001b[0m a \u001b[91mseries\u001b[0m of \u001b[91mvariables\u001b[0m that can \u001b[91mbecome\u001b[0m wrong, \u001b[91mespecially\u001b[0m when there's higher equipment. \u001b[91mTwo\u001b[0m of the \u001b[91mbig\u001b[0m things that is most important to \u001b[91mworking\u001b[0m against some of these issues is to \u001b[91mmanage\u001b[0m that \u001b[91mrequires\u001b[0m a lot of \u001b[91madvance\u001b[0m planning to \u001b[91mmake\u001b[0m that any kind of risks are managed and are \u001b[91mworked\u001b[0m against. So, for example, \u001b[91mbeing\u001b[0m that the planning process that you make \u001b[91msuch\u001b[0m that all of the technical \u001b[91missues\u001b[0m. \u001b[91mGetting\u001b[0m really \u001b[91mcalm\u001b[0m and \u001b[91mable\u001b[0m to avoid any \u001b[91mliability\u001b[0m issues. \u001b[91mIs\u001b[0m a big issue. Another one is is just staff not having an awareness, so just making sure that staff are \u001b[91msufficiently\u001b[0m trained for the equipment that may be in place, making sure that you've got a full \u001b[91mflight\u001b[0m log. Make sure that nothing doesn't. Equipment doesn't turn up or similar that you know that you know that you're getting what you need. Also, making sure that your clients or your presenters know what they're going to need in order to be able to deliver that event. So that it can be \u001b[91mmanageable\u001b[0m is really important. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [08:34, 14.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57d2233690> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f57fe374450>\n",
            "1.0\n",
            "\u001b[91m0 (98%)\u001b[0m --> \u001b[91m0 (252%)\u001b[0m\n",
            "\n",
            "All \u001b[91mright\u001b[0m so. Is very \u001b[91messential\u001b[0m that when someone is planning for. \u001b[91mVery\u001b[0m \u001b[91mimportant\u001b[0m events possibly has to \u001b[91mdouble\u001b[0m \u001b[91mcheck\u001b[0m that team. \u001b[91mEnsure\u001b[0m that everything is going as well as planned. If possible, \u001b[91mone\u001b[0m has to be very physical, physically present in the \u001b[91mplanning\u001b[0m events. \u001b[91mCheck\u001b[0m out all \u001b[91mequipments\u001b[0m that were supplied to make sure that they are working perfectly. Also, one has to prepare for a \u001b[91mbackup\u001b[0m plan because it's very essential, you know. In \u001b[91mcase\u001b[0m if \u001b[91mthere's\u001b[0m a fault, if there's if maybe one of the team members and can make it probably. Also you have to also prepare for that. Also, the \u001b[91mway\u001b[0m there has to be preparation for bad weather. Also they have to be prepared. \n",
            "\n",
            "All \u001b[91mlikelihood\u001b[0m so. Is very \u001b[91mstressful\u001b[0m that when someone is planning for. \u001b[91mSometimes\u001b[0m \u001b[91mdangerous\u001b[0m events possibly has to \u001b[91mill\u001b[0m \u001b[91meffect\u001b[0m that team. \u001b[91mBeing\u001b[0m that everything is going as well as planned. If possible, \u001b[91mpeople\u001b[0m has to be very physical, physically present in the \u001b[91memergency\u001b[0m events. \u001b[91mTaking\u001b[0m out all \u001b[91mmonitors\u001b[0m that were supplied to make sure that they are working perfectly. Also, one has to prepare for a \u001b[91mcatastrophe\u001b[0m plan because it's very essential, you know. In \u001b[91maddition\u001b[0m if \u001b[91mhas\u001b[0m a fault, if there's if maybe one of the team members and can make it probably. Also you have to also prepare for that. Also, the \u001b[91mdanger\u001b[0m there has to be preparation for bad weather. Also they have to be prepared. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r28it [08:48, 14.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (199%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "The problems that I would anticipate and prepare for are miscommunications when you're working with a large group of different people. Each person has a different communication style, so you need to know that there might be some miscommunication. That might happen. So just preparing for that and. Also, people have different working styles. Some some individuals may not be as reliable as others, so I'm going to prepare for that. People being late or people not showing up at all. I have to prepare for that and I also have two prepare for us being short staffed for short stuff. What's going to happen? I have to also come up with a way of performing the tasks that we have to do so it's decorating for an event. So I have to figure out how what each person is going to do, how they're going to do it, and the time that will allocate for that so that we know how to do it so that everything runs smoothly. It's. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r29it [09:02, 14.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "\u001b[91m0 (193%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So I think the person foremost in terms of actually setting up the equipment. One of the most important things is sort of ensuring that all the well. Whichever teams or staff members are involved in using the equipment or. Adequately trained in actually operating the equipment and sort of if any issues come about when attempting to use the equipment, they're able to troubleshoot or go to somebody that would be able to help them. Basically fix any issues promptly. Then yeah, also, everyone just needs to know what they're doing in terms of delivering the event so people have to stick to timelines, guidelines, deliver the information appropriately, and keep the audience engaged and in terms of tidying up, this also needs to be done in a prompt fashion, ensuring that the equipment is not damaged and is transported from A to B in an adequate timeframe. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [09:07, 11.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "\u001b[91m0 (-4%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Basically I've been ahead. To prepare anything. Back up, go running. Why the change are working together and basically you make sure that you can use Tyler. Cleaning Charlie around there's no obstruction, use it. While and whilst on the floor so anybody could select a file with no wires. Life wise I'm going around. Make sure everything's in order in place. And basically basically concerned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r31it [21:56, 238.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "\u001b[91m0 (103%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "So look through the event, set up delivery and tidy up. The first thing to do is get the teams together. Make sure everyone's there and they all know what they're doing and setup is important and need to get the equipment together and everyone needs to know what they're doing with it. So sufficient training is very important. Depending on the equipment. The man has to be there on time, has to be distributed to the correct locations. And the teams need to know what they're doing with their. If there's any equipment, light broken or waiting on it. The day could be quite delayed. We've got to deliver the. Event as well. As far as delivery goes, it just rains probably a bit more standing around, making sure everything carries on working and the teams and individuals know what to do with the people and tidying up people hate this and always want to go home. It could be not enough bins. It could be that stuff can't be packed away. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack = create_attack(model_wrapper, attack_name='BAE')\n",
        "\n",
        "df = test_set[['transcript', 'content_rating']][test_set[ 'content_rating']<2][:5]\n",
        "for idx, row in tqdm(df.iterrows()):\n",
        "    result = attack.attack(row['transcript'], row['content_rating'])\n",
        "    # attack_df = attack_df.append({'transcript': row['transcript']\n",
        "    #                               , 'content_rating':row['content_rating']\n",
        "    #                               # , 'domain_name':row['domain_name']\n",
        "    #                               , 'Adversarial':result.perturbed_text()\n",
        "    #                               # ,'intent_name': row['intent_name']\n",
        "    #                               , 'dump' : result.str_lines()[0]}, ignore_index=True)\n",
        "    # result.original_text(), result.perturbed_text()\n",
        "    print(row['content_rating'])\n",
        "    print(result.__str__(color_method='ansi'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEGPot_WD1n2",
        "outputId": "c9657a74-5f88-4314-e028-68fb325c1804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "textattack: No entry found for goal function <class '__main__.UntargetedClassification'>.\n",
            "textattack: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class '__main__.UntargetedClassification'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BAE attack is running.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:12, 12.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f133c417550> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f13464e9450>\n",
            "1.0\n",
            "\u001b[91m0 (115%)\u001b[0m --> \u001b[91m0 (254%)\u001b[0m\n",
            "\n",
            "I think with this type of \u001b[91mtask\u001b[0m it's always important to. So \u001b[91mdelegate\u001b[0m. What do you want? What do you want people to do? So in your teams, maybe have somebody that's like the head person. And there are people that are underneath them so. If is that the work and needs help, they can go to maybe the manager and that manager can come to you. So it's like a hierarchy and that usually helps things go smoothly and also right down the \u001b[91mtasks\u001b[0m that you want each. Each department to do and then they can always \u001b[91mtick\u001b[0m that off. But As for external to make \u001b[91msure\u001b[0m that you're prepared for every eventuality. Maybe hiring extra staff just in case. I have staff on standby in \u001b[91mcase\u001b[0m there's some people don't turn up. \n",
            "\n",
            "I think with this type of \u001b[91mproblem\u001b[0m it's always important to. So \u001b[91mmr\u001b[0m. What do you want? What do you want people to do? So in your teams, maybe have somebody that's like the head person. And there are people that are underneath them so. If is that the work and needs help, they can go to maybe the manager and that manager can come to you. So it's like a hierarchy and that usually helps things go smoothly and also right down the \u001b[91mtrain\u001b[0m that you want each. Each department to do and then they can always \u001b[91mput\u001b[0m that off. But As for external to make \u001b[91menough\u001b[0m that you're prepared for every eventuality. Maybe hiring extra staff just in case. I have staff on standby in \u001b[91mlondon\u001b[0m there's some people don't turn up. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:18,  8.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f133c417d50> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f13465aa050>\n",
            "1.0\n",
            "\u001b[91m0 (112%)\u001b[0m --> \u001b[91m0 (266%)\u001b[0m\n",
            "\n",
            "If the event is planned for outdoors and there should always be something on the side just in case to be able to go \u001b[91mindoors\u001b[0m. \u001b[91mIn\u001b[0m \u001b[91mcase\u001b[0m of the weather not cooperating for that, and I would say always had extra event assistance for set up for take down for \u001b[91mcleanup\u001b[0m. In any event that someone can't show up that day to help out. \u001b[91mAlways\u001b[0m have an extra on hand is a great idea in any type of event that you're planning. Check, recheck all of your lists. Make sure you have everything. Call and verify that all the deliveries are scheduled for certain time. Verify the time and follow up with that. If you have to. The date of the event or day before the event just to make sure that everything is covered. And you have backups if necessary. \n",
            "\n",
            "If the event is planned for outdoors and there should always be something on the side just in case to be able to go \u001b[91mindoor\u001b[0m. \u001b[91mas\u001b[0m \u001b[91mexample\u001b[0m of the weather not cooperating for that, and I would say always had extra event assistance for set up for take down for \u001b[91mcars\u001b[0m. In any event that someone can't show up that day to help out. \u001b[91mcould\u001b[0m have an extra on hand is a great idea in any type of event that you're planning. Check, recheck all of your lists. Make sure you have everything. Call and verify that all the deliveries are scheduled for certain time. Verify the time and follow up with that. If you have to. The date of the event or day before the event just to make sure that everything is covered. And you have backups if necessary. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:24,  7.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f133d7a50d0> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f134668bcd0>\n",
            "1.0\n",
            "\u001b[91m0 (124%)\u001b[0m --> \u001b[91m0 (250%)\u001b[0m\n",
            "\n",
            "It would have to be a \u001b[91mthorough\u001b[0m risk \u001b[91massessment\u001b[0m for like health and safety and stuff like that. I would when it comes to setting things up. Umm? \u001b[91mTidy\u001b[0m up after her. \u001b[91mSet\u001b[0m the height equipment. What I would do is I would. Not being sexist, \u001b[91mI\u001b[0m would probably get guys who are well built to build physical stuff rather than. Guys who are not as well built or women just to avoid any. Need to fill out, you know, like an accident form or anything like that. That's how I'd put different teams together based on their physical capability. \n",
            "\n",
            "It would have to be a \u001b[91mfinancial\u001b[0m risk \u001b[91minvolved\u001b[0m for like health and safety and stuff like that. I would when it comes to setting things up. Umm? \u001b[91mworking\u001b[0m up after her. \u001b[91mforget\u001b[0m the height equipment. What I would do is I would. Not being sexist, \u001b[91mit\u001b[0m would probably get guys who are well built to build physical stuff rather than. Guys who are not as well built or women just to avoid any. Need to fill out, you know, like an accident form or anything like that. That's how I'd put different teams together based on their physical capability. \n",
            "1.0\n",
            "\u001b[91m0 (255%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "All right, that's such an event. You could have many many factors. But I think the most important factor would have to be the. That you have spare devices in place, especially when you know. Especially with how unpredictable technologies. So we want to have a spare device just in case any of the devices just suddenly malfunctioning stopped working. You know you have a spare anything to have a spare laptop in case you know the main laptop that you're using just suddenly starts acting up, you need to have spare keyboards, mice, whetever, kind of devices that we need during the event, and we want to make sure that also. That safety is taken into consideration, so we want to work with the least amount of cables we want. We don't want people tripping around long. Folding over and. You know having any accidents you can't really afford that so. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:31,  6.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f1346425f90> <textattack.goal_function_results.classification_goal_function_result.ClassificationGoalFunctionResult object at 0x7f1346bd47d0>\n",
            "1.0\n",
            "\u001b[91m0 (145%)\u001b[0m --> \u001b[91m0 (250%)\u001b[0m\n",
            "\n",
            "So yes, \u001b[91mI\u001b[0m \u001b[91mwould\u001b[0m split it into UM. Into three different sections, so I'd have anything to do with the post event, so that will be organized and suppliers organized, supplies how they would get there, any sort of access for trade routes, trade suppliers, rather, how they would get to the when we get to the site and anything on initial setup. So if you need to security. It just depends how large slot event is really UM, and then I'd have a middle \u001b[91msection\u001b[0m while the the event was in place for how the teams would work together during the event. How they would cooperate work together if there was any crossover between teams that reached team had a specific skill set that they would use source that to how they would work most effectively, and then there would be a final list of how the teams would work to sort of conclude the event. The events over the the people have left and what have you. Is there a clean up? Do the supplies do part of the clean themselves? \n",
            "\n",
            "So yes, \u001b[91mit\u001b[0m \u001b[91mmight\u001b[0m split it into UM. Into three different sections, so I'd have anything to do with the post event, so that will be organized and suppliers organized, supplies how they would get there, any sort of access for trade routes, trade suppliers, rather, how they would get to the when we get to the site and anything on initial setup. So if you need to security. It just depends how large slot event is really UM, and then I'd have a middle \u001b[91margument\u001b[0m while the the event was in place for how the teams would work together during the event. How they would cooperate work together if there was any crossover between teams that reached team had a specific skill set that they would use source that to how they would work most effectively, and then there would be a final list of how the teams would work to sort of conclude the event. The events over the the people have left and what have you. Is there a clean up? Do the supplies do part of the clean themselves? \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response, score = test_set[['transcript', 'content_rating']].values[0]\n",
        "print(response)\n",
        "print(score)\n",
        "print(model_wrapper(response))\n",
        "# response = 'The first thing that came into my mind was like this is an outdoor or indoor event and whether the weather may have been influence on possible problems, so that would certainly have to be taken into account. Umm? And what kind of equipment are we using for the event and? What was the risk of not receiving the equipment in time for the event? Who is what type of people are going to attend the event? Do we need to make any specific? Arrangements for their needs. And yeah, these were the main things that came into mind.'\n",
        "model_wrapper(result.perturbed_text())"
      ],
      "metadata": {
        "id": "Qe4-dmTbZKFX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "6a938a3c-1e52-4132-a4e2-983609abf0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The types of problems and that could come up that would affect how well the event goes or for example and the hired equipment doesn't arrive. Or perhaps it arrives with parts missing. And. The setup of that equipment. Perhaps there is a lack of technical knowledge within the team that is setting that up, or there's a problem. Perhaps the equipment isn't what was expected in the delivery of the event because we're coordinating several teams who are working together. There could be problems at coordinating those and an agreement between who does what and who is responsible for what. And similarly, that could affect the tidy up afterwards. And there could also be problems with the collection of the hired equipment at the end. Perhaps then you policies around recycling and rubbish disposal that hadn't been considered. And so, yeah, a plethora of problems that could come up and that would affect the event. \n",
            "3.0\n",
            "tensor([[3.0061]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-eff6978210ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# response = 'The first thing that came into my mind was like this is an outdoor or indoor event and whether the weather may have been influence on possible problems, so that would certainly have to be taken into account. Umm? And what kind of equipment are we using for the event and? What was the risk of not receiving the equipment in time for the event? Who is what type of people are going to attend the event? Do we need to make any specific? Arrangements for their needs. And yeah, these were the main things that came into mind.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturbed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'perturbed_text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/SNGP_BERT_Pytorch/dataset/clinc_oos/test.csv')\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B15FfJPtGu_-",
        "outputId": "aee50df7-653f-420d-e03f-e595e5e65df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   text  intent  domain intent_name  \\\n",
              "0      how would you say fly in italian      84       5   translate   \n",
              "1    what 's the spanish word for pasta      84       5   translate   \n",
              "2   how would they say butter in zambia      84       5   translate   \n",
              "3        how do you say fast in spanish      84       5   translate   \n",
              "4  what 's the word for trees in norway      84       5   translate   \n",
              "\n",
              "  domain_name  \n",
              "0      travel  \n",
              "1      travel  \n",
              "2      travel  \n",
              "3      travel  \n",
              "4      travel  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5eb5cf0f-e7a4-4368-be09-1d3157304d8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "      <th>domain</th>\n",
              "      <th>intent_name</th>\n",
              "      <th>domain_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how would you say fly in italian</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>translate</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what 's the spanish word for pasta</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>translate</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how would they say butter in zambia</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>translate</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how do you say fast in spanish</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>translate</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what 's the word for trees in norway</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>translate</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5eb5cf0f-e7a4-4368-be09-1d3157304d8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5eb5cf0f-e7a4-4368-be09-1d3157304d8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5eb5cf0f-e7a4-4368-be09-1d3157304d8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = response, score = test_set[['transcript', 'content_rating']]\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "npEA9gQKITm9",
        "outputId": "86de12c8-fa26-418b-998a-7625e9420f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          transcript  content_rating\n",
              "0  So having worked in the past on some different...             1.0\n",
              "1  Things that could go wrong. Stuff gets sick. P...             4.0\n",
              "2  OK, the things that could go wrong. First of a...             5.0\n",
              "3  The specific times of programs that we could e...             3.0\n",
              "4  There are so many factors that could come up a...             3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e248a354-aee8-4da2-82de-3c55aaddd5bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript</th>\n",
              "      <th>content_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So having worked in the past on some different...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Things that could go wrong. Stuff gets sick. P...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OK, the things that could go wrong. First of a...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The specific times of programs that we could e...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>There are so many factors that could come up a...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e248a354-aee8-4da2-82de-3c55aaddd5bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e248a354-aee8-4da2-82de-3c55aaddd5bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e248a354-aee8-4da2-82de-3c55aaddd5bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_wrapper(['how are you'])"
      ],
      "metadata": {
        "id": "tOg0LPzPJSrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = test_df\n",
        "# df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "attack_df = pd.DataFrame()\n",
        "# attack = Attack(goal_function, constraints, transformation, search_method)\n",
        "for idx, row in tqdm(df.iterrows()):\n",
        "    result = attack.attack(row['transcript'], int(row['content_rating']))\n",
        "    attack_df = attack_df.append({'transcript': row['transcript']\n",
        "                                  , 'content_rating':row['content_rating']\n",
        "                                  # , 'domain_name':row['domain_name']\n",
        "                                  , 'Adversarial':result.perturbed_text()\n",
        "                                  # ,'intent_name': row['intent_name']\n",
        "                                  , 'dump' : result.str_lines()[0]}, ignore_index=True)\n",
        "    result.original_text(), result.perturbed_text()\n",
        "    print(result)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMOhOGMxEE0x",
        "outputId": "6a6067a6-bd07-441b-ffff-d652954bbf3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:00, 31.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So having worked in the past on some different types of events in a variety of venues I can see there's a number of issues that can go wrong, particularly when there's higher equipment. One of the main things that is most important to mitigate against some of these issues is to ensure that there's a lot of forward planning to ensure that any kind of risks are managed and are mitigated against. So, for example, ensuring that the planning process that you make sure that all of the technical specifications. Are really specific and clear to avoid any incompatibility issues. That's a big issue. Another one is is just staff not having an awareness, so just making sure that staff are appropriately trained for the equipment that may be in place, making sure that you've got a full inventory log. Make sure that nothing doesn't. Equipment doesn't turn up or similar that you know that you know that you're getting what you need. Also, making sure that your clients or your presenters know what they're going to need in order to be able to deliver that event. So that it can be compatible is really important. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Things that could go wrong. Stuff gets sick. Put work schedule behind. They eventually get cancelled. Inclement weather. Teams could pull out. Prices could change. And change. The clients might want changes last minute. And. If you're so coordinating. It could go wrong.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, the things that could go wrong. First of all, staff might turn up so that would mean anybody to set the equipment up properly. Umm? The the higher the equipment might not turn up the drivers for the hired equipment might not turn up to deliver it. And to deliver the event. Certain aspects, such as equipment. And the venue that might be a problem at the venue. And tidying up afterwards, and there might not be any equipment to tidy up afterwards. Again, there might not be any staff. And what else could go wrong? But you could have problems with electricity, the hired equipment. It might be difficult to set up, might not be instructions. There could be an accident at the event with no insurance. And the the staff might not have the knowledge to deliver the event and.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "The specific times of programs that we could encounter both externally and internally with regards to my team that would affect how well the arzan goals or things such as absence in the team. Teams and complete. If there are people missing and they would hurt. Odd delivery of the event. It would also result in responsibilities being delivered poorly. Of course, there's also an issue if everyone is present. If there is a lack of effort in the delivery of the event, then it would affect how well it goes. As the event is being conducted. Between multiple teams, a lack of communication between teams could cause dysfunction and lead to the event also not acquiring well, whereas vice versa will happen if the computer communication is open and flowing between the teams, they will lead to the success of the event. Externally, the issues with the equipment could also cause delays and delays could have a knock on effect in the delivery of the event. Which would. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "There are so many factors that could come up and interfere with the event on the first are some internal issues, whether that's staff changes right before the event changes in the catering, changes in staff, quitting staff, having emergencies, and that they can't come to the event, so those are a few that come to mind and then. Externally, and the clients needs could change. There could be weather challenges or issues at the at the venue, like if the venue is accidentally double booked, so there are so many different factors that could arise externally and internally that we have to prepare for as the event planner, but hopefully with these in mind the event will run smoothly and coherently. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Problems could be that some of the team might not show up, so it means that we wouldn't have enough staff to make sure the event was set up correctly and the equipment may not be delivered on time. Which obviously means that we were able to set up correctly for the event and bad weather, such as really bad winds or rain could affect us being able to set up the equipment correctly, which means the event will be able to go ahead.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So I think. The most important thing to do would be to do a whole risk assessment. But to make sure that all of the risks are in check. Uh. I suppose the first step would be to make sure that all the hard equipment was there. Uh. If that's something you need to consider first. And then beyond this. Read me the whole thing to Terry up afterwards. And for the event itself, we need professionals on set. To. Who can use the equipment hired? And that need to be some kind of chat so everyone could coordinate their thoughts of this several times working together. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [00:00, 37.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So in terms of all the things that could go wrong, we could think about our team members. Of course, everyone is briefed and has been allocated a role on the event day, but it could happen that somebody is sick or absent. So we need to have extra people available in terms of the higher equipment we need to make sure that arrives on time that the right people are there to put those pieces of equipment together and to monitor it throughout the event. Otherwise, if something breaks down, we will have a problem in terms of the person and the people delivering the presentations at the event they could be delayed and there could be some travel issues. Train or underground cancellations. Indeed, the audience could be affected by the same thing, so we need to consider. Whether it might be cancelled last minute? Early in terms of tidying up, we need to make sure we have a team of people who are available to recycle everything and make sure everything is done correctly and on time. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "In terms of the question. Issues could possibly arise. Some of the equipment does not arrive on schedule. Some of the equipment ordered is malfunctioning once it's set up. Then we on to the personnel side. Not all of the teams arrive on time. They're delayed. Some of the personnel may not be may not be present. Then there's the venue itself that there could be access problems to certain areas. And in addition to that. There could be power issues. Let's say let's say not all power is available as scheduled. Those are the ones that come to mind immediately. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "All right, so thinking about various factors that could impact how well this event goes. First, I'm thinking about internal factors. If someone got sick, if someone on the team can got got sick, they would not be able to show up. So we need to make sure we have backup plans in place and that we have a contingency plan. Make sure that we have duplicates of information. Make sure that everyone on the team knows where any files are and any sort of files that might need to be accessed regarding the events. Needing to make sure that we have well coordinated information, if the Internet goes down, what are we going to do? Are we going to make sure that we have a backup plan there externally? Let's say if the hotel or the event planner if the event planner is sick, or if there's a hotel issues or if they lose equipment, what are we going to do? Do we have plans in place to make sure that we're thinking through about alright? If the Internet is down, what is our alternative? Can we make sure that all of the downloaded information is done beforehand? That were not necessarily having to access the Internet to do a presentation. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I think that the main things that could go wrong in events planning are linked to a lack of organization and communication. I think that any of the companies involved in providing things for the event could be subject to letting the event down and could prove problematic. I also think in terms of what they're delivering that what they deliver. Might not be in line with expectation for the event, so there could also be problems there. And I also think in terms of the clean up process that that would also require good organization because it could go wrong if people think that they're finishing at the end and that it hasn't been put into their contracts that they need to actually make sure the job is finished and stay after the event and till the venue is actually tidied away. So I think it would be important. To make those terms very clear to all the people involved and to organise it office. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Can you helping an event planner with an important event that involves coordinating several teams working together to set up the hide equipment to live the event and tidy up afterwards to ensure the event of smoothly you've been asked to prepare for anything that could go wrong? What types of problems, both internal and external to your team could come up that affect how well the event goes? List as many factors as you can, right? So hide equipment, there could be equipment faults, electrical faults, general wear and tear. It's good to have some backups on site just in case. Delivered the event so that sounds like it could be through with preparation. You need people there with the required expertise. You might need people on hand in case there are sicknesses. And you know, general things that can go wrong with people. And tidy up afterwards. So tighten up. Make sure you have the right equipment. Again, cleaning chemicals bin bags. What else could go wrong? Power cut? Can't take a generator, that's ridiculous. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Things that could go wrong, lack of availability of people, whether environmental factors. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, I think what I would do in the with this event is I would have two teams. One would be the primary team that would be responsible for. The basics setting up the equipment that's delivered and doing the clean up the auxiliary team would sort of be filling in for anything that could possibly go wrong. If a piece of equipment not delivered, they would go out and you know procure it locally, they would just jump in wherever if tools are needed to set up the equipment, they could help out. They could help out on the the cleaning they could pick up things that weren't delivered. If there were any issues such as that. OK. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Things that could go wrong in this scenario include liaising with various other people and other teams in order to get equipment and to get the things that we need for the event. Delivered to us in time and logistically things could go wrong, so the logistics of other people of ourselves in terms of receiving the equipment and things that we need for the event. And there could be incorrect communication within the team and and with external parties, which causes confusion or overlapping or somethings to be missed. Other things go wrong could include. And not having contingency planning for anything that might. Happen that we don't expect. So for example, if the event was outdoors and the weather was naff, we might not have a contingency plan for that, or anything to back up the event. We could have cancellations, and we could have people being late and. Yeah, I think that's pretty much it. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I would imagine that the most common problems would be. Weather related for starters, probably if you have rainy windy weather in general, that could be definitely an issue that you can't anticipate or do much about, but you can at least try to. Work with ahead of time as much as you can. You could have issues with staff showing up or not. There could be issues with the amount of. Refuge trashed was created, needs to be cleaned up afterwards. There could be issues with delivering the equipment. These days, even in getting sometimes equipment to show up. Where you need it when you need it is really difficult as well, so shipping and freight can definitely be an issue. So yeah, that would be it. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "When planning for an event, you have to look at. Things that can go wrong. Some examples would be. Food not delivered on time then. Let's say depending on your guest demographic, there could be kids running around knocking things down. You could even have problematic. Adults trying to disrupt the event. Then any any props that you have for the event you have to make sure they're well secured. I'm not a safety hazard. And then you have to make sure that. In the event of a fire or a. Something like that you have the evacuation plan set up straight so that. You're well prepared, you know to avoid any. Injuries. Do your guests or to yourself or anybody as part of the event. Then it's always best to have. Doctor. Product that even in the case. Of an emergency. Other things that could go wrong. You know quality issues with food. Drinks and depending on the event. You know what kind of food is served and things like that, so yeah, this is just a few examples. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25it [00:00, 45.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So the factors that I've listed are things that could go wrong, internal and external to the team are as follows. So first of all, teams actually not knowing what they're responsible for. So you need a list of responsibilities, and for each person involved, or each team involved and the delivery of the items. What time do they need deliver in? Are there on time? Are the items correct? How much time do we need to actually set them up? Do we have enough time for that? People who responsible for set up the equipment actually know how to do it, and the insured to do it. And what happens if the items can't be set up correctly or the the equipment doesn't work. Have we left enough time for any contingencies? Is actually delivering the event, who's responsible for what? Is everything taken care of and then tidy up again? Do we have the time? Do we have the equipment needed and the people? \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so. The first thing I'm thinking is, does everybody know what they got to do? So there's gonna be clear. Task list that everybody knows exactly who does what and when. We know exactly what equipment has got to come and all teams are very clear about exactly what they can do without that. Obviously any lack of understanding of task management would mean. That things could go wrong. Obviously there's gotta be some contingency around. What if things don't turn up as planned, so therefore I'm going to think about what we would do in those eventualities and have some sort of contingency available if certain things don't happen. So we'd have to go through exactly the different stages and the different teams and what the tasks are. Other things will be if we've got some staffing issues, especially with COVID, so I'd look at some backup staffing. And be very clear exactly. It's just about really being clear about who does what and having what each of those tasks. If it doesn't happen, what do we do if? \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so in helping plan this event I believe that to make sure it runs smoothly and to repair for anything that could go wrong, I made a short list of problems both internal and external that could come up that would affect how well the event goes. First of all, would be simply lighting, make sure there's adequate light in the conference room where the event will be held. Make sure the sound is. It is set up so that we don't get all kinds of echoes or outside noise. Make sure the power is good and we don't have any problems with electricity or power. Believe it or not, make sure that there's adequate parking for the attendees. And last but not least, something I can't really control much as the weather, but if the weather happens to be particularly bad that day, we would be able to postpone the event until the next day or few days later, and those would be the things that I would try to make sure are in order.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I think with this type of task it's always important to. So delegate. What do you want? What do you want people to do? So in your teams, maybe have somebody that's like the head person. And there are people that are underneath them so. If is that the work and needs help, they can go to maybe the manager and that manager can come to you. So it's like a hierarchy and that usually helps things go smoothly and also right down the tasks that you want each. Each department to do and then they can always tick that off. But As for external to make sure that you're prepared for every eventuality. Maybe hiring extra staff just in case. I have staff on standby in case there's some people don't turn up. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I would first of all check that the venue is expecting me prior to the day I would check whether there is a Pacific team of staff and make sure I ring them in advance to check their coming in. I would give them written instructions of what the staff were required to do on the day. I would check the venue facilities to look for whether I needed paper or equipment or projectors. I would personally. Have things like projectors worked, nothing more embarrassing than going to do a presentation and the equipment doesn't work. I would also check to see whether there is any food available. And who is responsible for that? And when the timing of that is going to be and give everyone a list of the timing of the day, including any delegates that are arriving to come to the venue. Uh, I would ensure that the, uh. I had sufficient staff available to cover, but I could ring in case somebody didn't turn up. What's that it really? \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, we need to know about the time the venue is available and open to accept deliveries. Delivery at times for the higher equipment to arrive, we need each team to have assignment of the duties they need to complete and when in order other issues we might come across are teams arriving at the right times or members of the teams not arriving in. Or calling in sick at short notice. Do we have the instructions and the knowledge required to assemble the equipment as that being provided beforehand? \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I think the main thing that could go wrong is poor communication. This would cause all kinds of problems. Things going in the wrong place. People turning up at the wrong time. Who knows what else. So it's really important that you have good communication, so the other things that could go wrong are staff of poor training. So not knowing how to actually set things up and tidy up. Sub problems that move the spending or certainly in times like the pandemic staff illness, meaning you have to then get an agency staff where you'd have all kinds of issues with lack of training. And again that you're spending. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so the question says you're helping an event planner. The reporting that that involves coordinating several teams working together to set up the hired equipment, deliver the event and tidy up afterwards. Insure the event runs smoothly. You've been asked to prepare for anything that could go wrong. What types of problems, both internal and external, to your team could come up that could affect how well the vent goes as many factors as you can definitely weather is a big factor. Malfunctioning equipment could go wrong, let's say. There's wind, let's say staffing doesn't show up. The equipment is late on arrival, equipment doesn't show up at all. Maybe another factor could be staff which is inexperienced and using the equipment as well. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So a couple of things that could go wrong is since there's a lot of teams working together, I think there could be a conflict between the different teams also. Again, since there are a lot of teams involved that could also. There could also be issues with timing like some teams could be late. Some teams could be early or teams that need to work together could not be there at the same time for whatever kind of reason or delay. Also, because if they're going to be using different kinds of equipment, there could be issues with the equipment themselves. So either something's not working properly or something is forgotten, or you know, just something is doesn't show up that it needs to. And I guess also just in general timings, like if everyone needs to be there at a specific time and then also be involved with like the cleanup process if the event is somehow late or if the people of the event show up late or stay late. There could also be issues with you know organizing the people who need to be there for like clean up and everything like that could be affected. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So in order to ensure that everything ran smoothly, I would organize meetings and discuss any potential problems and think of alternative ways to deal with that contingency plans, and I think many problems could go wrong. Anything that you could think of could probably go wrong, so I just have contingency plans in place, and that's how I'd handle it. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "36it [00:00, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So some things that could go wrong is items like equipment not showing up on time when it's needed in order to set everything up. Also, just in general people not showing up, we're supposed to show up, people could end up bailing out in the last minute, being sick, getting hurt. You know anything, really. What else turning up afterwards, making sure you have the right equipment for that, making sure that there's people who understand as much. Of what's going on is you do, meaning getting the message around for the full plan for the day, making sure everyone is well aware. Internally, there could be disagreements on the way things should be set up. Sometimes people want things to look a certain way, and they already put that picture in their heads, so they just kind of go with it. Stuff along those lines. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so things that could go wrong could be communication between the different teams, whether that be a technical issue or personality thing, or just that somebody understood meant something wrong. So somebody might have said it was them one thing and somebody else said it was something else. Something else that could go wrong might be the equipment might not turn up, or there might be something missing. You might not be able to follow the instructions, or they might be missing, so you're struggling to put it all together. There may be issues with people not wanting to do the tidying up afterwards because they feel it's not their job to. To be clearing up, you could have that people might not turn up for the event. You know members of staff just don't show up and then you haven't got enough people to cover it. Could be people that don't get on with other people working very well as a team and you have to deal with any sort of conflict. That way the weather may also be a problem. There's lots of things that could go wrong. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Don't say you need to be sure that people are going to show up on time, and that means you're employees, but also the contractors as well, and you need to be sure that the venue is ready for you that everything is prepared in advance. If that's required and you need to make sure that everything is going to arrive in the right order, and particularly if one piece of work is reliance on a different piece of work, you need to make sure that that happens in the right order that you kind of deal with any problems in that. God. You also need to kind of keep your eye out for any unforeseen events. Keep your eye on the weather as well, because the weather can often mess up pretty much any event, and afterwards you need to make sure that you have got feedback on how everything went and make sure you clean up properly and thoroughly, but really find out. What went well? What could be improved on and then make sure that everyone is aware of that so that you can make sure that every single event do becomes better each and every time you deliver it. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I feel like they'd be many different problems that could happen as a result of you know, working with the event planner, and to put on this event, the first thing I thought of was the hired equipment that might already have broken and might be delayed, and so we might not be able to use those resources. That would be good to have a backup. And I was thinking if some of the different teams some of their team members might be sick or unable. And to you know, do their roles on the day and that would be a significant problem not having their capacity to actually set up the equipment or run the event as thinking depending on where the event is. If there is like a weather problem that could cancel the event and the other thing I thought of would be health and safety, so making sure that the equipment is safe to use and people know how to use it and also. Making sure that the teams are available to stay around afterwards and for tidying up rather than just leaving. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I think first of all it would be really important to check with the higher companies that the equipment is still ready for hire and it hasn't been booked out somewhere else. And also check that all the staff while equipped. And well qualified in using the equipment. Which we're hiring out and. As we won't want any breakages or anything like that and also have a checklist of all the different pieces of equipment that we are, how you're in to make sure everything does turn up? If it was all to be delivered at once, it would be easy to maybe miss miss something. That appear important later on. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Hi, I think the things that could go wrong would be mainly to do with staff. So whether we have staff absences or staff not completing their tasks on time according to the schedule. On top of that, there might be external factors that affect the event, such as things like technological faults or the guests not attending or arriving too early or arriving too late. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Well, the first thing that comes to mind is that. That some teams will be late to set up the hired equipment late to deliver the equipment. So I would make sure that we have a firm time hours ahead of time that they can come and set up. I would want to make sure that everybody has all their ducks in the row that the the equipment is secured and is is confirmed a way ahead of time. I would want to know. Exactly if there is a guarantee on or fine if they don't come up with the equipment. I would make sure you have a coordinator to make sure that everything runs smoothly and so you're not really stressed about it, and the coordinator would probably want to have a couple teammates to ensure that the vet is going to go well all the way overall. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Externally to the team, you can obviously always have issues with technology, as we've learned throughout the pandemic. Not something that Council and should be important to have back up on that. And things like not talk if you're using monitors or projectors, that kind of thing and Wi-Fi crashing all of those things need to be considered. And if you have any external speakers coming in. For the event and obviously really important that they show up on time that they've been well briefed, and if none of those things happen or they don't show up at all, or there's a reason that they do have to back out, then that can be be an issue. And internally with the team you might end up having people that are sick. You might not have the resourcing, therefore it's good to have him back up with that. Ensure that the whole team is prepared for that and knows how to do various different roles. It's always is different things. People do forget equipment and stuff, so that's that's another important thing to remember and that that could happen. Maybe showing up is another one or two other people showing up to the event.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Alright, so a few things that I think could go wrong is maybe one of the teams is running late or doesn't show up at all. I know sometimes when I'm on site we have specific teams that come in and they come in in the same van so. You know we have to prepare for the possibility that one team may run late May run extremely late, and what we would do if that happens. Depending on which team it is of. Of course it depends on what we will do. Another thing, it could be a maybe we run out of tools or we don't have the right tools. What are we going to do then? We should have a plan for that. Let's see also like if it's an outdoor event, what if it starts to rain or something are we? Are we prepared for that? You know, maybe we have umbrellas, ponchos or something. If it's an outdoor event and. Yeah, just making sure that everyone follows safety protocol and how to supplement. Other people or teams in the event that they are late or don't show up or even get hurt so. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so in terms of internal issues that could be around the staff members involved, so if they are absent or perhaps running away then that would obviously impact the amount of work. See that could be done if there's not enough bodies to do the work. As with the people who are, there are being others, lack of skills and experience, perhaps not able to do the task required to the relevant standard. And then also issues around the equipment being used. If it's not you arrived on time. It's not working, nobody can set it up, and those would also be internal issues and external issues could be around the guests who are going to be at this event and you know are they running late? Are they able to make it? And then of course like plan changes so if everything's needed to be moved up by half an hour what impact will that have on the the planning and the running of the event and other external one? Would be the weather. So if this was an outdoor event and it started raining, that could have you know a huge impact on the events being run and. Yeah, could be a massive issue. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Hello right, so things that could go wrong so it's a big event. So you got the weather that could be on, not on your side. Hired equipment might not arrive, not be delivered to the event on time. Might be late it might be damaged. There might be something up after the event. There could be an incident at the event which causes you extra time tidying up things. Could have been trashed so you want the event to run smoothly. You could have staff that don't turn up. You could have stuffed that poorly, or there's an outbreak of COVID. And you want to make sure the event goes well. You could have more people come than you expected or not enough people that came as you expected. You could have teams that don't work together. Do you need to make sure that you call up and get the equipment delivered on time working efficiently and it doesn't need to be repaired and that everything is in order ready to go for when the event goes so that it does run smoothly and things don't go wrong. I mean, obviously things go wrong, but I suppose you need good problem solving skills in order to be able to coordinate them. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "46it [00:01, 48.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Well, one thing that could go wrong is technological difficulties. Difficulties for using any sort of technological equipment, so to ensure nothing goes wrong with that. Test it, test it again, test it again. Make sure that. The equipment is working fine. Do some live run throughs to make sure the equipment is working fine. Also, when you do kind of live run throughs like this, you find out there are things that you didn't expect that could go wrong. So I try to recreate the event as much as possible. Come. As far as delivering the event. Obviously, make sure you have an itinerary that identifies what events are going to happen at what time, and also account for any. Delays that could happen. Sometimes events you know or part of the event take longer than than other parts, so try to arrange the schedule in a way that prioritizes the important things, and the less important things allow for those to not happen if possible. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Hi, I think the first thing I'd want to do is create a plan so we know what needs to be done when it needs to be done and which members of the team will be carrying out of those tasks. We're looking at the staff team in terms of what their strengths are, what they are particularly good at, and how well they work together so that we make sure that we maximize our resources and get the best results. We also need to look at any. Weaknesses are development issues where members of staff could learn from other people but also want to plan the venue. Make sure that we have a backup. Then maybe we rehearse the event so we know what we're doing, that we take account of any weather. For example, if it's an outdoor event, we liaise with caterers, make sure that we meet what the customers require. Also run have a run through so that we can spot any potential. Problems and address them before the actual event and make sure that we have the best possible outcome. Thank you. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So some of the problems that I anticipate might need to be factored in are in terms of staffing. So whether staff actually turn up. Also, because we're operating with several teams, there would need to be consideration as to whether those teams need to communicate, whether they've already got that established relationship. Whether they understand actually the way that the overall event is going to be operating and where they individually sit within that, but also how their sub team sits within that. Also, in terms of the equipment that's been hired, so does the equipment arrive on time? Is it set up properly? Is it working adequately? And also is it able to be sort of deconstructed at the end of the day so that the rest of the tidying up process can happen? And ensure that obviously that all runs smoothly in terms of the tidying up afterwards. If there's delays. So if the event doesn't run to schedule, I'll staffing group still able. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Hi, I'm so if I'm working with an event planner. Several teams hide equipment, stuff like that. What kind of things could go wrong so you could have staff calling in sick? You could have problems with the venue. Which it needs kind of check up on before you arrive and check that everything is as it says it is. Issues with the hired equipment. Depending what it is, if it's like electrical or mechanical, making sure that you've got somebody there that can fix it if it's. If it goes wrong. Issues with the teams and communication between the teams that could affect how well the event goes.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Helping an event plan with important event that involves coordinating several teams to ensure the event runs smoothly but prefer anything go wrong. What types of problems will the general election to your team came up with would affect how well the event goes. Factors would include UM weather could be if something for the for the event didn't show up like food catering. Options I guess like what's Plan B for that. The people that are playing the event or are hosting the event or unhappy. I think there's a lot of different things. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I guess the main thing would be. Having different teams. Service back up to the other ones, so like. Uhm? If there's a. You know if there's food catered? And it's you know catering team. I mean, I guess you can't really have the. I don't know. Yeah, it's just gonna assume that things aren't going to, you know, build in time, build an extra time for things to. I say. If something goes wrong, it doesn't throw out the whole schedule, so build in some. Some cushion time, I suppose trying to have as many team members know. Other teams roles as best as possible in case some teams late someone doesn't show up. I mean, you didn't give me a lot of specifics out of bucket. I supposed to give you any. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so some of the problems that I can think of that could go wrong is all the staff may be there ready to sort out the equipment, but the equipment doesn't arrive in time and the maybe parts of the equipment that's missing or broken and so we'll need a replacement for the whole thing to work. Some of the team may arrive late, but when it's you know I don't know how many pairs of hands are within this team, but it may require 10, but there's only I don't know eight that turn up, so I'm at the end of it. There may be too much mess to clean up and there may. We may need more time to be able to get that cleaned up. Things may get broken at the event. There may be disagreements within the team. They may not be aware of disposing of all the rubbish. Think that's all I can really think of I. But yeah, that's what I've come up with in regards to this. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, things that could be going wrong. I could get sick or somebody else on the team could get sick and entire teams could come down sick like with COVID so you wouldn't have the staff that you needed there to do the things you needed to do. You'd have to get some more staff from somewhere, or they could be cancellations. The event itself could be completely cancelled at the time or when you were busy getting things ready or individual. People could cancel on the way to the event so it could be that you didn't have the speakers that you needed, or that people that you needed to be at the event, or some of the people. Some of the guests could cancel if lots of them cancelled, that could be a problem. You could have an issue with some of the staff not turning up that you needed for the event, so some of the equipment or some of the things that you'd hired or the food they could be transport problems on the day so people couldn't attend. You could have something wrong with the venue, so the venue venue had to cancel or their water got cut off. They had power cut something like that. Uh. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So I guess depending on the event, there's variety of things that could go wrong. Staff shortages or staff sickness may have a really detrimental effect on the event. Equipment failure would be a huge problem if that's essential for the event. Management sickness so if management are unwell or unable to come see event then the event may be mismanaged and be a bit of a disaster. External factors such as maybe if it's an outdoor event, the weather being poor. And customers not attending even even though they've bought a ticket, may impact on the event. Trying to think what else? It's difficult to say exactly without knowing more about the context, so. Yeah, probably mainly around staffing and equipment. Probably the biggest factors. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Things that could go wrong on the event could be if it's potentially an outdoor event. Things like weather conditions that might affect or or or have an impact on how the event goes. Staff availability. If there's any kind of last minute. Cancellation staff is sick. And ensuring that there's backup stuff for that. Suppliers for the event if they're delayed or unable to deliver required. Of supplies that could be an issue. If it's a ticketed event, ensuring that tickets are are sold and the appropriate number of tickets, any health and safety issues. So if it's kind of moving of goods you know injury from that. Any last minute changes that might need to be catered for if there's special guests and ensuring that they're still able to attend and making sure that communication is. Is across all parties. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "57it [00:01, 49.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "There are a lot of different things can go wrong between the teams you know. Renting equipment as opposed to operating equipment or having people that you pay to be expert in that equipment. In very different situation, when you're renting equipment, you have to have people that know all the equipment and and have an understanding of different models and brands and kind of troubleshoot each of them at one of those things. And that's you know that's the technical aspect of it, that that's only a part of it. And you know, sound reproduction. There's a million little things can go wrong with that. You basically need a whole team of people just doing that. And if you're building a stage. You know then, that gets extremely complicated. It's really just. It's really a matter of. Making sure that the technical team has as much time as they can possibly get because you know the input might go wrong to the speakers. Speaker might not work. The speaker might blow in the middle of the event stage, might my semi collapsed now, but might not be set up correctly. Cleaning up all these things, I mean just assembling all this stuff is huge issue. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "When planning a fence. It's important to consider that there are multiple external elements that can affect the performance of said event. This includes any hide equipment that our team has stated that we require. All the vendors. Can have delays. Equipment can be broken or dead on arrival or not as. Requested so we need to have a backup. Or a Plan B in their friend of equipment failure, or. Delays in the. Plans timing of the event. The coordination of several teams also has an element of risk. As multiple as you combine multiple people, the risk does increase. And this is unforeseeable, but. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Some of the things that could go wrong is there could be a lack of staff, maybe from illness, a lack of availability or isolation such as COVID. Other items could be equipment might not be working and unable to be replaced or. There may be insufficient power supplies.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So an employee's car could break down, and vendors car could break down. Or, you know they could get like family. Something that came up that caused them to. Miss. Their chef we have under staffed. Understaffing certain vendor couldn't show up the head like the food or the food could go bad. Preparations wouldn't be there. Keynote speaker people could get COVID. There could be an outbreak of COVID at the event. There could be an infestation of. Squirrels in the rafters. That come out and start eating everyone's face. Umm? The Event Center could get. Bombed, someone could bomb it. Someone could call in a bomb threat. Everyone could get too drunk. Lots of things. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So I am in charge of helping an event planner with an important event that involves coordinating several teams working together to set up, deliver and tidy afterwards an event to ensure that this runs smoothly. I am supposed to be preparing things that could go wrong and some problems that could go wrong for before is maybe somebody gets sick and we have to figure out how we're going to. Do what we're going to do with two less hands with four less hands, etcetera. Maybe somebody has a family emergency. Maybe somebody just can't make it in for whatever reason. Any of those reasons we need to account for and we need to make sure that we have enough people and enough will to do the task that we needed. When we deliver the equipment for the event, perhaps it might get bumped up in the ride over might fall out of the truck when we're setting it up. All that stuff could happen, so for that we just need to make sure that we have the resources to find the equipment either in our warehouse or another spot. If something bad like that were to happen. And lastly, when we're tidying up. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "There could be a problem with communication and coordination between the teams. It could be a problem with the hired equipment and communication with the company hiring it. There could be a problem with the delivery of the event itself. Well maybe it would overrun. It could also be external problems such as weather.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Some problems that might affect the event include. Teams not working well alongside each other. The height equipment being faulty or not arriving. An issue with the event so. Something like weather natural disaster. The people who the events before changing their minds about things. UM? So internal. Issues within the team's issues with the equipment. And. External issues with the people running the event.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so the type of problems that I think maybe could arise could be that the height equipment is. Uhm? Maybe some of it arrives late, maybe parts of missing, so I'd make sure that members of the team are liaising with. People were hiring the equipment from to make sure that we follow up on that and that all arrives in good time. Possibly. Members of the team. A late, maybe as well, so I'd make sure that everyone is all coordinating together and that we've got a good plan of action and I've set step by step of how how the event should run. And. Yeah, and and just just communicate. Amongst everyone. And yeah, that that. That's all I can think of, to be honest. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "And so the things that I would prepare to go wrong. Are kind of teams not doing what they said they were gonna do or not delivering on time. Suppliers being late, having the wrong equipment. Over there's loads timings not going to plan people not being in this right place as where they should be. And. And people getting stuck in traffic. The right information not being provided technical difficulties with it and setting up things not being compatible with the venue. And I'm glad, yeah. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "The main problems that I can think of for this event would be just the coordination between all of the different teams and making sure that they work smoothly together and making sure that the communication is good between the teams as they may have different tasks that they are each individually working on, but that need to come together as one event. This could be the staff of the event who are actually delivering this. This could be the catering if there is catering provisions this could be to do with the venue or the. Seating or furniture or anything that's been provided for this could be a sound system. If there is any music or any speeches or or talking happening at this event, and it could also be issues with staffing levels. If there are anyone who is ill, particularly if they have been working on one individual thing and perhaps others in the team, do not know how to. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So if there is an event coming up, let me see and I'm the event planner. I do believe that delivery dates could go wrong. Supplies could be short, they could get the amount of stock wrong. People could phone in sick that I've hired from my team. COVID could be a thing. Once again that's been a thorn in the side of event planners. So yeah, making sure everyone has done their PCR test depending on which country we're in at the time. Yeah, working out logistics to make sure everything runs smoothly. Uh. I really, really need to pay attention to people management as well. To my team, get on, well, they'll have somebody who. I can rely on when I'm not there to get their job done, etcetera etcetera many, many things. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "68it [00:01, 49.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "The fact is that you would need to consider would be locations for all of the different people and teams involved. The communication between each of the teams, how and where would you communicate to ensure the best seamless experience. The equipment being hired externally, and any other externally supplied extras. Very, very important. A pre planned meeting to make sure everybody involved all the teams know exactly what should and shouldn't happen. And again, very much in mind any fails that could occur. Any potential problems? Make sure you've planned for those as well as well. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "The equipment could break down. There could be problems with the transport, the roads could be busy, there could be accidents, it could be delays with traffic and the delivery. People could become ill. There could be childcare issues. There may be too many people on holiday. We get HR may not have done their jobs properly and holiday bookings. My coincide with each other may not be enough staff to man the event. Within the venue. There could be issues such as fire hazards. Accident hazards trip hazards that need to be rectified. Lighting may breakdown. Electrics may not work. Staff within the actual event may be understood. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "As far as things that could go wrong for an event, I would say. There could be. Not enough food. Not enough drinks. There could be some people that aren't getting along so they start to cause problems. There could be issues with the little people that are allowed to get in. The people that it's for. You want to make sure that. Everybody that's there is everybody that's supposed to be there. Umm? You want to make sure everybody knows their role. That's planning the event as far as cleaning or preparing. Or working during the event. And. Overall, make sure that everything is going to plan.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "For an event, it really depends on the kind of event, if it's a. Convention where there's a lot of other people. The typical problems that you'd run into is getting supplies and equipment to the venue and then to the specific. Booth location if it's a. Company specific event you could run into problems of communication. You could run into problems of supply. You could run into problems of staffing. If it's a smaller event, you can also run into scheduling issues since you don't have the. Like purchasing power of a larger company for company specific events, the problems usually get resolved around networking through different teams who are also collaborating towards a successful party or what have you. And then there is. Larger events where it's really important to communicate with the venue first and then make sure everybody's on the same page. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Well, I think the most important part of this whole process would be organization. And how many companies are used? I think. One of the biggest things that could go wrong given the fact that everything has to be on site at the same time. And has to be available at the same time is to minimize the number of companies that are used to provide the equipment and to provide the services for the event. So. In theory it would be great if we could provide one vendor who would provide the overwhelming majority of the equipment and the services that we would be required for the event, but if not, it would be great if the vendors had already had in that pre-existing relationship so that all of the equipment and everything would go together already. So that if they had a pre-existing relationship, everything could already work seamlessly together and it would just be a matter of checking off all of the boxes. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Problems that come up could include if the event is outdoors, and inclement weather that we don't plan for anticipate for. Being the fact that I'm in charge of running according several teams, there could be an issue with something you know on those teams being improperly staffed or falling through, and you know some of their managerial duties, et cetera. You know, I'm sure that the charge of overseeing several of those teams that includes a large supply workers there could be an issue on the guests and which wouldn't be in our control, but it would be in control. How we react to it and salvage the event there could. The you know, compensatory issues from. If, for example, if I recall recently, I had to this actually a real situation. I had to hustle our team to work more than twice as fast, to break, to break down a dinner for like College of Charleston President because they took an hour longer eating than we anticipated. So we had to shave all focus an hour of our breakdown time in order to accommodate the guests. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So some of the things that could go wrong probably would include things like hide equipment not turning up on the day when it's supposed to. Maybe the equipment itself not working or being fit for purpose. It's going to involve coordinating a number of different teams. It's effective as the others and don't work as well. There's possibly even people could be off sick so people could be missing. And. I think that could also be the potential for the venue and. Equipment to be not as expected, so not as. Not as it was described, so maybe not really be fit for purpose, but could also be impacted by the weather and whether or not things are going to be delayed or held up or impacted by that. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "One of the main things that could go wrong is if you don't have enough staff to help set up. So you need to always make sure to hire more staff than you need. This is something you do not want to cut corners with at all at all. You need to have enough staff. Also, inclement weather you need to be checking the weather reports, and if there's even a chance of rain or things like that, you need to be prepared for bad weather. You need to double check with the delivery teams you got to make sure they are paid beforehand or have deposits. You need to make sure all of that because you need your stuff delivered and you have to double check that you have enough people to help you break down the setup afterwards. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "People might forget what job they're doing or what role they're doing. The equipment might not turn up. You might not go to tidy up quick enough. Umm? People might not turn up to the event or people might not enjoy the event. Umm? The team might be too tired or overworked.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "The problems that I would anticipate and prepare for are miscommunications when you're working with a large group of different people. Each person has a different communication style, so you need to know that there might be some miscommunication. That might happen. So just preparing for that and. Also, people have different working styles. Some some individuals may not be as reliable as others, so I'm going to prepare for that. People being late or people not showing up at all. I have to prepare for that and I also have two prepare for us being short staffed for short stuff. What's going to happen? I have to also come up with a way of performing the tasks that we have to do so it's decorating for an event. So I have to figure out how what each person is going to do, how they're going to do it, and the time that will allocate for that so that we know how to do it so that everything runs smoothly. It's. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I'm so I'm going to help the event planner and I'm going to list the things that could go wrong internally and externally. And so manly, and I think that what could go wrong is that the Hyder equipment doesn't come in time, and this happens a lot of events and things don't turn up and things are alert and things just go missing, so that could go wrong. You know, companies aren't very reliable sometimes and then also with equipment as well being electronics mainly and they couldn't work. They might not work, so we need maybe backups and things like lights and that could go wrong. People could drop them, they could smash anything like that and also with the tidying up afterwards would be careful with the equipment of these hired so we need to like make sure it's going all right and go smoothly. And so yeah, they're the majority of things when you just to make sure there's backups. And people are on board of everything and yeah. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "78it [00:01, 48.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I'm not sure if I'm doing this correctly. I've seen different things upload. But as I mentioned before, that could go wrong. Is certain event staff that you've hired for the event they don't show up, or either they show up late? Or either maybe the food isn't up to par or the entertainment isn't up to par. Umm? People may not have RSVP to the event, so therefore you're not prepared for that many guests and you don't have seating or enough accommodations for them. The entertainment may not be as great as you thought it was going to be, and people are bored. And it's just lacking. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Hello so in terms of planning for this event, the important thing is to ensure that the preparation is thorough and also there are contingency measures in place so that we can respond to any unexpected problems as they occur and be able to quickly respond and ensure that the event is successful and runs as smoothly as possible. So in terms of sort of key, coordination and planning of this, and as well as identifying this sort of key equipment and external supplies and suppliers that we're going to require for the event, we also need to ensure that we've got some contingency measures in place and alternative suppliers. In case anyone does not provide the equipment as required. The time for the event and also that we've got equipment and alternative supplies. Place ready to quickly. Come in and take place of anything that goes. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Things that could go wrong, or that the team internally may not turn up because they have COVID or they didn't get the memo to say what time or they had a better offer. So there are many problems that hiring staff could could have, especially these days in uncertain times. Externally the event may not happen because of logistics supplies and things may not arrive on time. Stocks might be in short supply. Could be strikes and lacking of availability, which seems to be causing a problem. This might mean that the internal event is severely tampered, so internally could be staff issues and externally it could be transport and logistics and lack of supplies which could be a problem.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I think it's important when faced with this problem, to make sure that we map out all of the different things that need to happen and then decide in what order this should happen. So to ensure that we don't have things that are out of order and require rework or additional effort to be done on the day. So I think you know if there are things like we need to get formats down and stuff like that. That has to be step one. If there are people that are coming to serve the food, food should probably arrive first. Food should be set up, the server should be instructed. All things should be addressed and then a plan. Of course if anything goes wrong. So that's what I would expect to happen on the day, thanks. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Arsenal. An event planner. A lot of things could go wrong. Specifically, organization of all the staff making sure that there's someone who is in charge who can delegate different tasks and also making sure that the people that we have hired are there on time and know exactly what they need to do. A lot of things could go wrong, and both internal and external, whether it's organization amongst the in-house staff or. Pulverization coordination amongst the people that we've hired and the best thing to do is to make sure leaders have been assigned and that they know exactly what their role is and how to delegate all the specific tasks needed to make sure that the. The vent goes well. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "We need to decide whether or not the event is taking place indoors or outdoors. If outdoors, we need to consider whether the weather could interrupt our plans. Indoors gives us better options. We need to consider that those people attending the event may not turn up. So what's our? What's the? What do we need to do if somebody doesn't turn up one of the exhibitors at the event and turn up, who do we replace them with? Have we sent out the invitations correctly with the accurate timings of what time we're expecting people to arrive by and what time we expect the event to close? Do we have the insurance in place for the event? Failure to do so may mean we might not be able to proceed with the event. When we are getting stuff out and tidying away, do the people know where the stuff needs to go back to because it might not be the people that put the stuff out in the morning, so making sure we get everything back to its normal place will be a challenge if not organised carefully. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So the primary problem that I can see is that first of all everything one doesn't show up. It's always a bit of a risk that people just bow out. Second of all, people could have a hard time understanding the equipment, so they might not be familiar with that type of of product, so they would have a hard time actually doing the event because I didn't know how the equipment work, or at least how to set it up. Well, there could be problems around who's in charge people being unsure as to who's doing what, lack of organization and. All of those are problems that could happen. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So there might be problems with the team not knowing what each person is supposed to be doing, not having enough direction. There might be problems with the equipment and. If there might be missing some equipment, or the equipment might not fit into the area, or some equipment might be damaged. Problems at the event. With people not being directed properly. Not knowing where to go, there might be injuries or illnesses that need to be dealt with. There might be communication problems in amongst the team as to how the event needs to be run. Umm? There might be an unexpected workload either. Before, during or after the event. Umm?  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Sickness. Equipment failure. And. Lack of staffing. And electricity power failure. Uhm? Accident on set. And lots of equipment. Issues during the event. And. Forgetting stuff that was like when you were tidying up at the end. And that is all I can think of. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Things affecting something going wrong with an event planner. The people couldn't show up the catering. People wouldn't show up so you would need a backup. The bride might be late or the cake might not show up. Or perhaps the cake might fall over and get destroyed and then you would have to create another. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r83it [00:01, 48.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Right, I would say there are other things that could go wrong with this. Firstly, people who were meant to turn up on site on the day either don't turn up at all or they're late. Additionally, equipment that you plan to come along will be delivered, doesn't turn up, or if it turns up it doesn't work. Delays in things arriving delays in people arriving on site systems might not work either, such as Internet, electricity, other things such as that. In other words, a failure of equipment, people and systems, or delays in any of the which. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So I would make sure to coordinate in a way where you know I'll try to anticipate you know several different types of problems. I know that there would be both internal and external problems that would come up with an event. You know. I imagine there's stuff like weather that could show you know weather issues that could make an event kind of flop. I know that externally people could be late, both my own team, but also people coming to an event people could be late because of traffic because of weather. They could be logistical issues having to do with food. There could be issues having to do with internal things like you know people on my own team not being able, not being able to show up. Maybe we have some type of logistical issue that has to do with something dumb like you know the we didn't pay our utility bills or we don't have a certain set of items in order to cater to people properly. I mean you name it but yeah. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Hi, I'm assisting an event planner and there are many internal external factors that can. Hinder and. Go wrong with the day of the big event. Obviously weather is a big factor. You can't help it, but you can hope for the best and just have everything is crossed. Staffing levels is another big factor. You can just do all you can to ensure that. People in the day. Will be there. I've also had it bar staff is a good one. If you've got a big event like a wedding. We also really make sure that if it's sort of wedding that you know that's going to be really busy for drinks that you do all you can to assist with washing glasses, making sure there's plenty of ice, making sure that you do a quick turnaround of bottles or making sure that the soft drinks are available for everyone or getting out wine for toasting. And they're all little things that just keep freeing up people and keep everyone happy on the day. And obviously keep the. The company looking good in your event planner looking really good with. The person that she's planning the event for. It is supporting role. There are lots of obviously other things that. You can do this prior to the event. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "87it [00:20,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [FAILED]\n",
            "\n",
            "So I would look at the various companies websites. To ensure that they have the specification required for our requirements. Set up some sort of. Excel spreadsheets. Giving the various key features of the different manufacturers equipment and ranking them by price. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so things could go wrong. The people working together might not like each other, but I could get to an argument and there could be like a good leader. A person might not show up on time to the event. People might not have the right cell phone numbers. They might not understand what time they need to be there. They might screw up the date. They might not understand who's obligation is to do different types of jobs. People might not understand kind of what the purpose of the event is. People might not understand whose job is to clean up things. There might be other kind of messes that people don't anticipate. Break something or someone spill something. Or there could be bad weather like rains or snows or something like that. Different teams might not understand who's going to clean them up. There's lots of unanticipated things that could go wrong. Kind of need to have a good leader and a good plan in advance. Figure out what's going on. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I am an event planner. I have been tasked to make sure that the staff do their jobs correctly and in the right time. I have narrowed a few things down that would affect the workflow and stability of the event. One worker efficiency, the effectiveness of how well the event will go, including me depend on how effectively the staff carry out their functions. There could be a technical malfunctions so we could be so we need to be. Prepare an all fronts free. Whether you can't always predict bad weather and you should always have rain proof equipment. If it's an outdoor gig. Coronavirus is also a major concern in the present day. We are focused on protecting the public, so we need Wellness check centers in multiple areas of the event. We need to make sure that. There is good entertainment and sufficient beverages for the people that will be visiting or they will feel unwell. There also needs to be enough bathrooms. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Problems with staff not turning up. Issues with furniture table coverings, seats. Problems with suppliers. And.  \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I don't think I've done it properly, sorry. Just in briefs on again, so weather permitting, any issues while winds make sure the tables and chairs are indoors. PPE at the door for people who don't turn up with masks and double vaccinating. Passport as well, that would be helpful for people coming in the door. And to make sure we've got enough staff covering these areas so that we can try and remain outdoors as best we can for the circulated. So people don't get any concerns in regard to the current virus that's going about. So those kind of issues. What else? Staffing staffing is always an issue, so making sure there's enough people covering each area and have maybe team leaders to step up in certain. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "As there are various teams working together, an obvious problem is communications, both within the teams but between the teams. If they don't communicate well, things fall through the cracks. People may think one team's handling something and they may think the other teams handling it, for example, so clear boundaries, instructions, rules, communication needs to be within the teams and between the teams. Also, things that can go wrong. Things being cancelled at the last minute, making sure that there's contingency plans. So if, for example, a caterer falls through you have a backup or if the cleaning team can't make it, you have a backup. These are all things that need to be thought about, but also making sure everything is prepared in time, making sure everyone has enough time to do their jobs, but also have breaks to be able to. Calm down and be able to achieve to their highest potential. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I think the main things to plan for that could go wrong would be and staff availability. If people are sick or not available on the day or let us down and similarly to test the equipment is all working and to have contingencies around that to have Technical Support available in case things start to go wrong. So both internal and external. Clearly it's an important event and it involves coordinating several teams that both of those things say that you know this is high profile and has the potential for things to go wrong. I think the coordinating of teams is not as straightforward as it sounds because we. Presumably in the organization have a number of internal teams that would be involved in delivering an event like this. And making sure that they they all work together. So I think setting expectations. And making sure everybody knows what their expectations of them are for the event is going to be really important. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [00:20,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I mean, this is a pretty vague question really, isn't it? What's the event to start with? So. I mean, you could have you know you've got hiring equipment. There could be a breakdown supply chain problem accident on the motorway, you don't get any of your equipment. Perhaps it's been a Miss order, some equipments missing, you know to account for that, find a way to get an alternative. Suppose it delivery the event well. If one of your speakers doesn't turn up somebody's missing or. You know, not enough tables for guests that sort of thing, making sure that you've got enough and everything is organized correctly, tidying up afterwards. I mean, there's not really that much can go wrong there, just making sure you've got enough equipment and stuff to get rid of everything. Making sure everyone is prepared, I suppose is the highest thing to think about, but I mean without knowing the event that's a very difficult question to answer. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Possible problems that could go wrong are is the equipment is late. The equipment doesn't work. People don't show up to load the equipment or tidy it up. There could be rain. There could be a power outage. There could be the wrong equipment delivered. And there could be a tornado or other natural disaster. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So you could have problems with colleagues turning up accidents. They could be the highered equipment could not get delivered or partially delivered. It could be a lack of experience with team members who are able to set up the equipment. They could be a power outage during the setup. On delivery you could have parking issues for attendees. There could be rain, so you'd have to think about the canopies, whether it's outside or inside. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "I think I recorded it, but I think I pressed the button and it rerecorded, so I guess I'll just say it again, but. When you're working with a lot of people that could potentially cause a problem, so there's several teams of people, so there might be people procrastinating. They might not give their full effort. There might be any sort of conflict that might arise, things like that. Things with the equipment. The equipment minor should not show up. It might be broken. It might be falsy. There might be potential risk for wires and things like that that need to be accounted for when the event is being delivered. I guess that any number of things could go wrong. When people are sort of drunk and things like that, so just looking after that and tell you maybe the event overruns and you don't have enough time to tidy it. And that's all I can think of. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Right so. With this event, coordination and ensuring event runs smoothly. I could see a lot of problems. I could see our event. I could see the teams that we contact not being cooperative I could see. Maybe the equipment that we. Get is not delivered in time like this thing. Maybe there's an issue with the equipment. Maybe the other teams are not working. Maybe the other teams will not work with those very well maybe? Yeah. Maybe unwillingness on our teams part to work with the other teams so it could just be a general laziness. The weather could be a factor because maybe if it's bad weather, a lot of the equipment could get messed up. Maybe the cost of the equipment is something that a lot of the teams might not be comfortable with. And obviously, if the event has to get postponed or something, that would cause a big wrinkle in the plants. So there could be weather that's a problem. There could be just laziness. That's a problem cost. There are many, many different factors. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "Right? I wrote it on my phone, so if I keep looking down that's why but I am. People could relate, meaning things could remain schedule, so everything's gonna be. Behind which could result in something not happening on the right time. Higher equipment could be faulty or not upright. People might. You might not have enough money to fund it, resulting in things going wrong or things not showing up. And not not not enough people might show up, and food could be labeled wrong. So people with allergies might eat them and have allergic reaction. People might not know what they're doing. That could be another one, and they could just guess and then someone could. Be faulty and resulting in go wrong again and not enough staff hired. No security on the door so anyone could just come to the event and call us hassle cause. Mischief and just ruin the whole event in general. And there might not be enough space for everything that is needed to happen. The music might be too. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "So there are plenty of things that could go wrong during a event where you have to coordinate with several other people and several other vendors to make sure that goes smoothly. So the first thing that I can think of is what if the support staff calls out? What if some of the brand ambassadors get sick? Well, the first thing that I could think of is making sure to work with a brand ambassador agency rather than. The contracting individual ambassadors. That way you have the support system of the agency to call in other people as needed. Other things that we should definitely prepare for our any issues with utilities. Issues with electricity specifically. Backup generators are so important for really any event you really don't know what's going to happen. A disposable plates rather than plates that have to go into the kitchen and get washed, just making sure that you have double s of everything. You have numbers for everyone who would be able to. Bail you out as needed. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so it's in this scenario I'm helping an event planner with an important event that involves coordinating several teams working together to set up the hired equipment, deliver the event and tidy up afterwards. So I'm to ensure that events run smoothly and have been asked to prepare for anything that could go wrong. So what types of problems internal external could come up that would affect how the event goes? I think definitely. Whether someone doesn't show up, for example, whether. Someone gets sick or injured, has to leave. When the equipment is faulty or we have issues setting it up it, you know it doesn't. You know has a missing piece or something. Then like. You know, if we have some some expertise that's needed that we don't have, whether it comes to the equipment. Maybe something goes wrong during the event and it gets much messier messier than we expected, and it takes longer. And yeah, just internal communication problems or personnel. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "OK, so. Problems I could experience internally are the teams aren't talking among themselves, so. Teammate for example, don't know what Team B are doing, so miscommunication errors internally externally. If I've hired any equipment. Or entertainment, that entertainment could cancel on me or not be clear where they need to go and what they need to do. If I'm doing catering, which if it was a. Event I would have done, I need to make sure that. Everyone's aware of allergies and things like that that could go wrong. The staff aren't aware of that. \n",
            "0 (100%) --> [SKIPPED]\n",
            "\n",
            "There are quite a few things that could go wrong. The cars or the car could break down. People could be arguing amongst themselves. The fact that we might not have the information required to make the event run smoothly. There could be power cuts which we wouldn't know about. There could be adverse weather conditions could be sickness amongst the staff, accidents could happen. We may not have valid insurance. We might need permits and they may not be authorized in time, and the clients might have expectations which are beyond our capabilities as a team. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3ohy-6qhHOAU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}